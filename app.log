INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawl_and_insert_data" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
INFO:werkzeug:[33mPress CTRL+C to quit[0m
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawl_and_insert_data" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 524-771-621
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:12:38 KST)" (scheduled at 2025-01-14 16:12:38.458910+09:00)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:12:43 KST)" (scheduled at 2025-01-14 16:12:43.457574+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:12:58 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:werkzeug: * Detected change in 'C:\\Users\\soldesk\\AppData\\Roaming\\Python\\Python310\\site-packages\\apscheduler\\executors\\base.py', reloading
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:13:03 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:13:18 KST)" (scheduled at 2025-01-14 16:12:58.458910+09:00)
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawl_and_insert_data" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 524-771-621
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:13:18 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:13:38 KST)" (scheduled at 2025-01-14 16:13:18.458910+09:00)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:13:20 KST)" (scheduled at 2025-01-14 16:13:20.208753+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:13:38 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:13:40 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:13:58 KST)" (scheduled at 2025-01-14 16:13:38.458910+09:00)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:14:00 KST)" (scheduled at 2025-01-14 16:13:40.208753+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:13:58 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:14:00 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:14:18 KST)" (scheduled at 2025-01-14 16:13:58.458910+09:00)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:14:20 KST)" (scheduled at 2025-01-14 16:14:00.208753+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:14:18 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:14:20 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:14:38 KST)" (scheduled at 2025-01-14 16:14:18.458910+09:00)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:14:40 KST)" (scheduled at 2025-01-14 16:14:20.208753+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:14:38 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:14:40 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:14:58 KST)" (scheduled at 2025-01-14 16:14:38.458910+09:00)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:15:00 KST)" (scheduled at 2025-01-14 16:14:40.208753+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:15:00 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:14:58 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:15:18 KST)" (scheduled at 2025-01-14 16:14:58.458910+09:00)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:15:20 KST)" (scheduled at 2025-01-14 16:15:00.208753+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:15:18 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:15:20 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:15:38 KST)" (scheduled at 2025-01-14 16:15:18.458910+09:00)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:15:40 KST)" (scheduled at 2025-01-14 16:15:20.208753+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:15:38 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:15:40 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:15:58 KST)" (scheduled at 2025-01-14 16:15:38.458910+09:00)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:16:00 KST)" (scheduled at 2025-01-14 16:15:40.208753+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:15:58 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:16:00 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:16:18 KST)" (scheduled at 2025-01-14 16:15:58.458910+09:00)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:16:20 KST)" (scheduled at 2025-01-14 16:16:00.208753+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:16:18 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:16:20 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:16:38 KST)" (scheduled at 2025-01-14 16:16:18.458910+09:00)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:16:40 KST)" (scheduled at 2025-01-14 16:16:20.208753+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:16:38 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:16:40 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:16:58 KST)" (scheduled at 2025-01-14 16:16:38.458910+09:00)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:17:00 KST)" (scheduled at 2025-01-14 16:16:40.208753+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:16:58 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:17:00 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:17:18 KST)" (scheduled at 2025-01-14 16:16:58.458910+09:00)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:17:20 KST)" (scheduled at 2025-01-14 16:17:00.208753+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:17:18 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:17:20 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:17:38 KST)" (scheduled at 2025-01-14 16:17:18.458910+09:00)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:17:40 KST)" (scheduled at 2025-01-14 16:17:20.208753+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:17:38 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:17:40 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:17:58 KST)" (scheduled at 2025-01-14 16:17:38.458910+09:00)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:18:00 KST)" (scheduled at 2025-01-14 16:17:40.208753+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:17:58 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:18:00 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:18:18 KST)" (scheduled at 2025-01-14 16:17:58.458910+09:00)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:18:20 KST)" (scheduled at 2025-01-14 16:18:00.208753+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:18:18 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:18:20 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:18:38 KST)" (scheduled at 2025-01-14 16:18:18.458910+09:00)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:18:40 KST)" (scheduled at 2025-01-14 16:18:20.208753+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:18:38 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:18:40 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:werkzeug: * Detected change in 'C:\\ProgramData\\Anaconda3\\Lib\\site-packages\\flask\\sessions.py', reloading
INFO:werkzeug: * Detected change in 'C:\\ProgramData\\Anaconda3\\Lib\\site-packages\\flask\\json\\tag.py', reloading
INFO:werkzeug: * Detected change in 'C:\\ProgramData\\Anaconda3\\Lib\\site-packages\\flask\\typing.py', reloading
INFO:werkzeug: * Detected change in 'C:\\ProgramData\\Anaconda3\\Lib\\site-packages\\werkzeug\\wrappers\\__init__.py', reloading
INFO:werkzeug: * Detected change in 'C:\\ProgramData\\Anaconda3\\Lib\\site-packages\\werkzeug\\wrappers\\response.py', reloading
INFO:werkzeug: * Detected change in 'C:\\ProgramData\\Anaconda3\\Lib\\site-packages\\werkzeug\\sansio\\response.py', reloading
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawl_and_insert_data" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 524-771-621
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:18:58 KST)" (scheduled at 2025-01-14 16:18:38.458910+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:18:58 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:18:54 KST)" (scheduled at 2025-01-14 16:18:54.875978+09:00)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:19:18 KST)" (scheduled at 2025-01-14 16:18:58.458910+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:19:14 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:19:18 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:19:34 KST)" (scheduled at 2025-01-14 16:19:14.875978+09:00)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:19:38 KST)" (scheduled at 2025-01-14 16:19:18.458910+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:19:34 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:19:38 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:19:54 KST)" (scheduled at 2025-01-14 16:19:34.875978+09:00)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:19:58 KST)" (scheduled at 2025-01-14 16:19:38.458910+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:19:54 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:19:58 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:20:14 KST)" (scheduled at 2025-01-14 16:19:54.875978+09:00)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:20:18 KST)" (scheduled at 2025-01-14 16:19:58.458910+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:20:14 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:20:18 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:20:34 KST)" (scheduled at 2025-01-14 16:20:14.875978+09:00)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:20:38 KST)" (scheduled at 2025-01-14 16:20:18.458910+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:20:38 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:20:34 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:20:54 KST)" (scheduled at 2025-01-14 16:20:34.875978+09:00)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:20:58 KST)" (scheduled at 2025-01-14 16:20:38.458910+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:20:58 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:20:54 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:21:14 KST)" (scheduled at 2025-01-14 16:20:54.875978+09:00)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:21:18 KST)" (scheduled at 2025-01-14 16:20:58.458910+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:21:14 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:21:18 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:21:34 KST)" (scheduled at 2025-01-14 16:21:14.875978+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:21:34 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:21:38 KST)" (scheduled at 2025-01-14 16:21:18.458910+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:21:38 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:21:54 KST)" (scheduled at 2025-01-14 16:21:34.875978+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:21:54 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:21:58 KST)" (scheduled at 2025-01-14 16:21:38.458910+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:21:58 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:22:14 KST)" (scheduled at 2025-01-14 16:21:54.875978+09:00)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:22:18 KST)" (scheduled at 2025-01-14 16:21:58.458910+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:22:14 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:22:18 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:22:34 KST)" (scheduled at 2025-01-14 16:22:14.875978+09:00)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:22:38 KST)" (scheduled at 2025-01-14 16:22:18.458910+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:22:34 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:22:38 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:werkzeug: * Detected change in 'C:\\kd\\ws_java\\team4_v2sbm3c\\src\\main\\python\\pernews.py', reloading
INFO:werkzeug: * Detected change in 'C:\\ProgramData\\Anaconda3\\Lib\\logging\\__init__.py', reloading
INFO:werkzeug: * Detected change in 'C:\\ProgramData\\Anaconda3\\Lib\\site-packages\\sqlalchemy\\sql\\__init__.py', reloading
INFO:werkzeug: * Detected change in 'C:\\ProgramData\\Anaconda3\\Lib\\site-packages\\sqlalchemy\\sql\\expression.py', reloading
INFO:werkzeug: * Detected change in 'C:\\ProgramData\\Anaconda3\\Lib\\site-packages\\sqlalchemy\\sql\\selectable.py', reloading
INFO:werkzeug: * Detected change in 'C:\\ProgramData\\Anaconda3\\Lib\\site-packages\\sqlalchemy\\sql\\roles.py', reloading
INFO:werkzeug: * Detected change in 'C:\\ProgramData\\Anaconda3\\Lib\\site-packages\\sqlalchemy\\sql\\elements.py', reloading
INFO:werkzeug: * Detected change in 'C:\\ProgramData\\Anaconda3\\Lib\\site-packages\\sqlalchemy\\sql\\annotation.py', reloading
INFO:werkzeug: * Detected change in 'C:\\ProgramData\\Anaconda3\\Lib\\site-packages\\sqlalchemy\\sql\\traversals.py', reloading
INFO:werkzeug: * Detected change in 'C:\\ProgramData\\Anaconda3\\Lib\\site-packages\\sqlalchemy\\sql\\visitors.py', reloading
INFO:werkzeug: * Detected change in 'C:\\ProgramData\\Anaconda3\\Lib\\site-packages\\sqlalchemy\\inspection.py', reloading
INFO:werkzeug: * Detected change in 'C:\\ProgramData\\Anaconda3\\Lib\\site-packages\\sqlalchemy\\util\\_collections.py', reloading
INFO:werkzeug: * Detected change in 'C:\\ProgramData\\Anaconda3\\Lib\\site-packages\\sqlalchemy\\sql\\base.py', reloading
INFO:werkzeug: * Detected change in 'C:\\ProgramData\\Anaconda3\\Lib\\site-packages\\sqlalchemy\\orm\\__init__.py', reloading
INFO:werkzeug: * Detected change in 'C:\\ProgramData\\Anaconda3\\Lib\\site-packages\\sqlalchemy\\orm\\query.py', reloading
INFO:werkzeug: * Detected change in 'C:\\ProgramData\\Anaconda3\\Lib\\site-packages\\sqlalchemy\\sql\\operators.py', reloading
INFO:werkzeug: * Detected change in 'C:\\ProgramData\\Anaconda3\\Lib\\site-packages\\sqlalchemy\\engine\\interfaces.py', reloading
INFO:werkzeug: * Detected change in 'C:\\ProgramData\\Anaconda3\\Lib\\site-packages\\sqlalchemy\\exc.py', reloading
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:22:58 KST)" (scheduled at 2025-01-14 16:22:38.458910+09:00)
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawl_and_insert_data" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 524-771-621
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:22:58 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:23:18 KST)" (scheduled at 2025-01-14 16:22:58.458910+09:00)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:22:59 KST)" (scheduled at 2025-01-14 16:22:59.955274+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:23:18 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:23:19 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:23:38 KST)" (scheduled at 2025-01-14 16:23:18.458910+09:00)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:23:39 KST)" (scheduled at 2025-01-14 16:23:19.955274+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:23:38 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:23:39 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:23:58 KST)" (scheduled at 2025-01-14 16:23:38.458910+09:00)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:23:59 KST)" (scheduled at 2025-01-14 16:23:39.955274+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:23:58 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:23:59 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:24:18 KST)" (scheduled at 2025-01-14 16:23:58.458910+09:00)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:24:19 KST)" (scheduled at 2025-01-14 16:23:59.955274+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:24:18 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:24:19 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:24:38 KST)" (scheduled at 2025-01-14 16:24:18.458910+09:00)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:24:39 KST)" (scheduled at 2025-01-14 16:24:19.955274+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:24:38 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:24:39 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:werkzeug: * Detected change in 'C:\\Users\\soldesk\\AppData\\Roaming\\Python\\Python310\\site-packages\\openai\\__init__.py', reloading
INFO:werkzeug: * Detected change in 'C:\\Users\\soldesk\\AppData\\Roaming\\Python\\Python310\\site-packages\\openai\\lib\\_old_api.py', reloading
INFO:werkzeug: * Detected change in 'C:\\Users\\soldesk\\AppData\\Roaming\\Python\\Python310\\site-packages\\openai\\_client.py', reloading
INFO:werkzeug: * Detected change in 'C:\\ProgramData\\Anaconda3\\Lib\\site-packages\\sqlalchemy\\__init__.py', reloading
INFO:werkzeug: * Detected change in 'C:\\ProgramData\\Anaconda3\\Lib\\site-packages\\sqlalchemy\\engine\\__init__.py', reloading
INFO:werkzeug: * Detected change in 'C:\\ProgramData\\Anaconda3\\Lib\\site-packages\\sqlalchemy\\engine\\create.py', reloading
INFO:werkzeug: * Detected change in 'C:\\Users\\soldesk\\AppData\\Roaming\\Python\\Python310\\site-packages\\selenium\\webdriver\\common\\by.py', reloading
INFO:werkzeug: * Detected change in 'C:\\Users\\soldesk\\AppData\\Roaming\\Python\\Python310\\site-packages\\apscheduler\\schedulers\\background.py', reloading
INFO:werkzeug: * Detected change in 'C:\\Users\\soldesk\\AppData\\Roaming\\Python\\Python310\\site-packages\\selenium\\webdriver\\remote\\webelement.py', reloading
INFO:werkzeug: * Detected change in 'C:\\Users\\soldesk\\AppData\\Roaming\\Python\\Python310\\site-packages\\apscheduler\\schedulers\\blocking.py', reloading
INFO:werkzeug: * Detected change in 'C:\\Users\\soldesk\\AppData\\Roaming\\Python\\Python310\\site-packages\\apscheduler\\schedulers\\base.py', reloading
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:24:58 KST)" (scheduled at 2025-01-14 16:24:38.458910+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:24:58 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawl_and_insert_data" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 524-771-621
INFO:werkzeug: * Detected change in 'C:\\kd\\ws_java\\team4_v2sbm3c\\src\\main\\python\\crawling.py', reloading
INFO:werkzeug: * Detected change in 'C:\\kd\\ws_java\\team4_v2sbm3c\\src\\main\\python\\crawling.py', reloading
INFO:werkzeug: * Detected change in 'C:\\kd\\ws_java\\team4_v2sbm3c\\src\\main\\python\\crawling.py', reloading
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:25:18 KST)" (scheduled at 2025-01-14 16:24:58.458910+09:00)
INFO:WDM:====== WebDriver manager ======
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:25:18 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawl_and_insert_data" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 524-771-621
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawl_and_insert_data" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
INFO:werkzeug:[33mPress CTRL+C to quit[0m
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawl_and_insert_data" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 524-771-621
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:25:43 KST)" (scheduled at 2025-01-14 16:25:43.154593+09:00)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:25:48 KST)" (scheduled at 2025-01-14 16:25:48.340187+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:26:03 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:26:08 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:26:23 KST)" (scheduled at 2025-01-14 16:26:03.154593+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:26:23 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:26:28 KST)" (scheduled at 2025-01-14 16:26:08.340187+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:26:28 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:26:43 KST)" (scheduled at 2025-01-14 16:26:23.154593+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:26:43 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:26:48 KST)" (scheduled at 2025-01-14 16:26:28.340187+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:26:48 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:27:03 KST)" (scheduled at 2025-01-14 16:26:43.154593+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:27:03 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:27:08 KST)" (scheduled at 2025-01-14 16:26:48.340187+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:27:08 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:27:23 KST)" (scheduled at 2025-01-14 16:27:03.154593+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:27:23 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:27:28 KST)" (scheduled at 2025-01-14 16:27:08.340187+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:27:28 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:27:43 KST)" (scheduled at 2025-01-14 16:27:23.154593+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:27:43 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:27:48 KST)" (scheduled at 2025-01-14 16:27:28.340187+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:27:48 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:28:03 KST)" (scheduled at 2025-01-14 16:27:43.154593+09:00)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:28:08 KST)" (scheduled at 2025-01-14 16:27:48.340187+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:28:03 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:28:08 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:28:23 KST)" (scheduled at 2025-01-14 16:28:03.154593+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:28:23 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:28:28 KST)" (scheduled at 2025-01-14 16:28:08.340187+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:28:28 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:28:43 KST)" (scheduled at 2025-01-14 16:28:23.154593+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:28:43 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:28:48 KST)" (scheduled at 2025-01-14 16:28:28.340187+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:28:48 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:29:03 KST)" (scheduled at 2025-01-14 16:28:43.154593+09:00)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:29:08 KST)" (scheduled at 2025-01-14 16:28:48.340187+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:29:08 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
WARNING:apscheduler.scheduler:Execution of job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:29:03 KST)" skipped: maximum number of running instances reached (1)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:29:28 KST)" (scheduled at 2025-01-14 16:29:08.340187+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:29:28 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:werkzeug: * Detected change in 'C:\\ProgramData\\Anaconda3\\Scripts\\pip-script.py', reloading
INFO:werkzeug: * Detected change in 'C:\\ProgramData\\Anaconda3\\Lib\\site-packages\\pip\\_vendor\\pyparsing\\core.py', reloading
INFO:werkzeug: * Detected change in 'C:\\ProgramData\\Anaconda3\\Lib\\site-packages\\pip\\_vendor\\packaging\\markers.py', reloading
WARNING:apscheduler.scheduler:Execution of job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:29:23 KST)" skipped: maximum number of running instances reached (1)
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawl_and_insert_data" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 524-771-621
WARNING:apscheduler.scheduler:Execution of job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:29:43 KST)" skipped: maximum number of running instances reached (1)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:29:51 KST)" (scheduled at 2025-01-14 16:29:51.913887+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:30:11 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
WARNING:apscheduler.scheduler:Execution of job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:30:03 KST)" skipped: maximum number of running instances reached (1)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:30:31 KST)" (scheduled at 2025-01-14 16:30:11.913887+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:30:31 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
WARNING:apscheduler.scheduler:Execution of job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:30:23 KST)" skipped: maximum number of running instances reached (1)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawl_and_insert_data" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
INFO:werkzeug:[33mPress CTRL+C to quit[0m
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawl_and_insert_data" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 524-771-621
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:30:57 KST)" (scheduled at 2025-01-14 16:30:57.598397+09:00)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:31:03 KST)" (scheduled at 2025-01-14 16:31:03.202562+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:31:17 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:31:23 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:31:37 KST)" (scheduled at 2025-01-14 16:31:17.598397+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:31:37 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:31:43 KST)" (scheduled at 2025-01-14 16:31:23.202562+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:31:43 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:31:57 KST)" (scheduled at 2025-01-14 16:31:37.598397+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:31:57 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:32:03 KST)" (scheduled at 2025-01-14 16:31:43.202562+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:32:03 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:32:17 KST)" (scheduled at 2025-01-14 16:31:57.598397+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:32:17 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:32:23 KST)" (scheduled at 2025-01-14 16:32:03.202562+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:32:23 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:32:37 KST)" (scheduled at 2025-01-14 16:32:17.598397+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:32:37 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:32:43 KST)" (scheduled at 2025-01-14 16:32:23.202562+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:32:43 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:32:57 KST)" (scheduled at 2025-01-14 16:32:37.598397+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:32:57 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:33:03 KST)" (scheduled at 2025-01-14 16:32:43.202562+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:33:03 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:33:17 KST)" (scheduled at 2025-01-14 16:32:57.598397+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:33:17 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:33:23 KST)" (scheduled at 2025-01-14 16:33:03.202562+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:33:23 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:33:37 KST)" (scheduled at 2025-01-14 16:33:17.598397+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:33:37 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:33:43 KST)" (scheduled at 2025-01-14 16:33:23.202562+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:33:43 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:33:57 KST)" (scheduled at 2025-01-14 16:33:37.598397+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:33:57 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:34:03 KST)" (scheduled at 2025-01-14 16:33:43.202562+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:34:03 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:34:17 KST)" (scheduled at 2025-01-14 16:33:57.598397+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:34:17 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:34:23 KST)" (scheduled at 2025-01-14 16:34:03.202562+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:34:23 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:34:37 KST)" (scheduled at 2025-01-14 16:34:17.598397+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:34:37 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:34:43 KST)" (scheduled at 2025-01-14 16:34:23.202562+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:34:43 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:34:57 KST)" (scheduled at 2025-01-14 16:34:37.598397+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:34:57 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:35:03 KST)" (scheduled at 2025-01-14 16:34:43.202562+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:35:03 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:werkzeug: * Detected change in 'C:\\Users\\soldesk\\AppData\\Roaming\\Python\\Python310\\site-packages\\bs4\\element.py', reloading
INFO:werkzeug: * Detected change in 'C:\\ProgramData\\Anaconda3\\Lib\\site-packages\\bs4\\element.py', reloading
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:35:17 KST)" (scheduled at 2025-01-14 16:34:57.598397+09:00)
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:35:17 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawl_and_insert_data" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 524-771-621
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:35:37 KST)" (scheduled at 2025-01-14 16:35:17.598397+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:35:37 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:35:29 KST)" (scheduled at 2025-01-14 16:35:29.175572+09:00)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawl_and_insert_data" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
INFO:werkzeug:[33mPress CTRL+C to quit[0m
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawl_and_insert_data" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
INFO:werkzeug:[33mPress CTRL+C to quit[0m
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawl_and_insert_data" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 524-771-621
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:44:38 KST)" (scheduled at 2025-01-14 16:44:38.243761+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:44:58 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:44:43 KST)" (scheduled at 2025-01-14 16:44:43.655928+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:45:03 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:45:18 KST)" (scheduled at 2025-01-14 16:44:58.243761+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:45:18 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:45:23 KST)" (scheduled at 2025-01-14 16:45:03.655928+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:45:23 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:45:38 KST)" (scheduled at 2025-01-14 16:45:18.243761+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:45:38 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:45:43 KST)" (scheduled at 2025-01-14 16:45:23.655928+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:45:43 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:45:58 KST)" (scheduled at 2025-01-14 16:45:38.243761+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:45:58 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:46:03 KST)" (scheduled at 2025-01-14 16:45:43.655928+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:46:03 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:46:18 KST)" (scheduled at 2025-01-14 16:45:58.243761+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:46:18 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:46:23 KST)" (scheduled at 2025-01-14 16:46:03.655928+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:46:23 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:46:38 KST)" (scheduled at 2025-01-14 16:46:18.243761+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:46:38 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:46:43 KST)" (scheduled at 2025-01-14 16:46:23.655928+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:46:43 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:46:58 KST)" (scheduled at 2025-01-14 16:46:38.243761+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:46:58 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:47:03 KST)" (scheduled at 2025-01-14 16:46:43.655928+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:47:03 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:47:18 KST)" (scheduled at 2025-01-14 16:46:58.243761+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:47:18 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:47:23 KST)" (scheduled at 2025-01-14 16:47:03.655928+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:47:23 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:47:38 KST)" (scheduled at 2025-01-14 16:47:18.243761+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:47:38 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:47:43 KST)" (scheduled at 2025-01-14 16:47:23.655928+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:47:43 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:47:58 KST)" (scheduled at 2025-01-14 16:47:38.243761+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:47:58 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:48:03 KST)" (scheduled at 2025-01-14 16:47:43.655928+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:48:03 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:48:18 KST)" (scheduled at 2025-01-14 16:47:58.243761+09:00)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:48:23 KST)" (scheduled at 2025-01-14 16:48:03.655928+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:48:18 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:48:23 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:48:38 KST)" (scheduled at 2025-01-14 16:48:18.243761+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:48:38 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:48:43 KST)" (scheduled at 2025-01-14 16:48:23.655928+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:48:43 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:48:58 KST)" (scheduled at 2025-01-14 16:48:38.243761+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:48:58 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:49:03 KST)" (scheduled at 2025-01-14 16:48:43.655928+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:49:03 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:49:18 KST)" (scheduled at 2025-01-14 16:48:58.243761+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:49:18 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:49:23 KST)" (scheduled at 2025-01-14 16:49:03.655928+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:49:23 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:49:38 KST)" (scheduled at 2025-01-14 16:49:18.243761+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:49:38 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:49:43 KST)" (scheduled at 2025-01-14 16:49:23.655928+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:49:43 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:49:58 KST)" (scheduled at 2025-01-14 16:49:38.243761+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:49:58 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:50:03 KST)" (scheduled at 2025-01-14 16:49:43.655928+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:50:03 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:50:18 KST)" (scheduled at 2025-01-14 16:49:58.243761+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:50:18 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:werkzeug: * Detected change in 'C:\\ProgramData\\Anaconda3\\Lib\\os.py', reloading
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:50:23 KST)" (scheduled at 2025-01-14 16:50:03.655928+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:50:23 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawl_and_insert_data" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 524-771-621
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:50:38 KST)" (scheduled at 2025-01-14 16:50:18.243761+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:50:38 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:50:34 KST)" (scheduled at 2025-01-14 16:50:34.193427+09:00)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:50:58 KST)" (scheduled at 2025-01-14 16:50:38.243761+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:50:54 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:50:58 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:werkzeug: * Detected change in 'C:\\ProgramData\\Anaconda3\\Lib\\site-packages\\sqlalchemy\\engine\\mock.py', reloading
INFO:werkzeug: * Detected change in 'C:\\ProgramData\\Anaconda3\\Lib\\site-packages\\sqlalchemy\\schema.py', reloading
INFO:werkzeug: * Detected change in 'C:\\ProgramData\\Anaconda3\\Lib\\site-packages\\sqlalchemy\\sql\\schema.py', reloading
INFO:werkzeug: * Detected change in 'C:\\ProgramData\\Anaconda3\\Lib\\site-packages\\sqlalchemy\\sql\\ddl.py', reloading
INFO:werkzeug: * Detected change in 'C:\\ProgramData\\Anaconda3\\Lib\\site-packages\\sqlalchemy\\sql\\functions.py', reloading
INFO:werkzeug: * Detected change in 'C:\\ProgramData\\Anaconda3\\Lib\\site-packages\\sqlalchemy\\sql\\lambdas.py', reloading
INFO:werkzeug: * Detected change in 'C:\\ProgramData\\Anaconda3\\Lib\\site-packages\\sqlalchemy\\types.py', reloading
INFO:werkzeug: * Detected change in 'C:\\ProgramData\\Anaconda3\\Lib\\site-packages\\sqlalchemy\\sql\\sqltypes.py', reloading
INFO:werkzeug: * Detected change in 'C:\\ProgramData\\Anaconda3\\Lib\\site-packages\\sqlalchemy\\sql\\type_api.py', reloading
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:51:18 KST)" (scheduled at 2025-01-14 16:50:58.243761+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawl_and_insert_data" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 524-771-621
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:51:18 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:51:38 KST)" (scheduled at 2025-01-14 16:51:18.243761+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:51:38 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:51:23 KST)" (scheduled at 2025-01-14 16:51:23.617375+09:00)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawl_and_insert_data" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
INFO:werkzeug:[33mPress CTRL+C to quit[0m
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawl_and_insert_data" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 524-771-621
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:53:16 KST)" (scheduled at 2025-01-14 16:53:16.935733+09:00)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:53:22 KST)" (scheduled at 2025-01-14 16:53:22.490002+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:53:36 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:53:42 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:53:56 KST)" (scheduled at 2025-01-14 16:53:36.935733+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:53:56 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:54:02 KST)" (scheduled at 2025-01-14 16:53:42.490002+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:54:02 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:54:16 KST)" (scheduled at 2025-01-14 16:53:56.935733+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:54:16 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:54:22 KST)" (scheduled at 2025-01-14 16:54:02.490002+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:54:22 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:54:36 KST)" (scheduled at 2025-01-14 16:54:16.935733+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:54:36 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:54:42 KST)" (scheduled at 2025-01-14 16:54:22.490002+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:54:42 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:54:56 KST)" (scheduled at 2025-01-14 16:54:36.935733+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:54:56 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:55:02 KST)" (scheduled at 2025-01-14 16:54:42.490002+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:55:02 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:55:16 KST)" (scheduled at 2025-01-14 16:54:56.935733+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:55:16 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:55:22 KST)" (scheduled at 2025-01-14 16:55:02.490002+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:55:22 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:55:36 KST)" (scheduled at 2025-01-14 16:55:16.935733+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:55:36 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:55:42 KST)" (scheduled at 2025-01-14 16:55:22.490002+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:55:42 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:55:56 KST)" (scheduled at 2025-01-14 16:55:36.935733+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:55:56 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:56:02 KST)" (scheduled at 2025-01-14 16:55:42.490002+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:56:02 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:56:16 KST)" (scheduled at 2025-01-14 16:55:56.935733+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:56:16 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:56:22 KST)" (scheduled at 2025-01-14 16:56:02.490002+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:56:22 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:56:36 KST)" (scheduled at 2025-01-14 16:56:16.935733+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:56:36 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:56:42 KST)" (scheduled at 2025-01-14 16:56:22.490002+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:56:42 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:56:56 KST)" (scheduled at 2025-01-14 16:56:36.935733+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:56:56 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:57:02 KST)" (scheduled at 2025-01-14 16:56:42.490002+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:57:02 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:57:16 KST)" (scheduled at 2025-01-14 16:56:56.935733+09:00)
INFO:werkzeug: * Detected change in 'C:\\kd\\ws_java\\team4_v2sbm3c\\src\\main\\python\\crawling.py', reloading
INFO:werkzeug: * Detected change in 'C:\\kd\\ws_java\\team4_v2sbm3c\\src\\main\\python\\crawling.py', reloading
INFO:werkzeug: * Restarting with watchdog (windowsapi)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:57:16 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawl_and_insert_data" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 524-771-621
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:57:36 KST)" (scheduled at 2025-01-14 16:57:16.935733+09:00)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawl_and_insert_data" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
INFO:werkzeug:[33mPress CTRL+C to quit[0m
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawl_and_insert_data" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 524-771-621
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:57:49 KST)" (scheduled at 2025-01-14 16:57:49.750703+09:00)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:57:55 KST)" (scheduled at 2025-01-14 16:57:55.547632+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:58:15 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
WARNING:apscheduler.scheduler:Execution of job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:58:09 KST)" skipped: maximum number of running instances reached (1)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:58:35 KST)" (scheduled at 2025-01-14 16:58:15.547632+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:58:35 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:58:29 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:58:49 KST)" (scheduled at 2025-01-14 16:58:29.750703+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:58:49 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:58:55 KST)" (scheduled at 2025-01-14 16:58:35.547632+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:58:55 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:59:09 KST)" (scheduled at 2025-01-14 16:58:49.750703+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:59:09 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:59:15 KST)" (scheduled at 2025-01-14 16:58:55.547632+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:59:15 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:59:29 KST)" (scheduled at 2025-01-14 16:59:09.750703+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:59:29 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:59:35 KST)" (scheduled at 2025-01-14 16:59:15.547632+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:59:35 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:59:49 KST)" (scheduled at 2025-01-14 16:59:29.750703+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:59:49 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:59:55 KST)" (scheduled at 2025-01-14 16:59:35.547632+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 16:59:55 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:00:09 KST)" (scheduled at 2025-01-14 16:59:49.750703+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:00:09 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:00:15 KST)" (scheduled at 2025-01-14 16:59:55.547632+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:00:15 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:00:29 KST)" (scheduled at 2025-01-14 17:00:09.750703+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:00:29 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:00:35 KST)" (scheduled at 2025-01-14 17:00:15.547632+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:00:35 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:00:49 KST)" (scheduled at 2025-01-14 17:00:29.750703+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:00:49 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:00:55 KST)" (scheduled at 2025-01-14 17:00:35.547632+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:00:55 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:01:09 KST)" (scheduled at 2025-01-14 17:00:49.750703+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:01:09 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:01:15 KST)" (scheduled at 2025-01-14 17:00:55.547632+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:01:15 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:01:29 KST)" (scheduled at 2025-01-14 17:01:09.750703+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:01:29 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:01:35 KST)" (scheduled at 2025-01-14 17:01:15.547632+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:01:35 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:01:49 KST)" (scheduled at 2025-01-14 17:01:29.750703+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:01:49 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:01:55 KST)" (scheduled at 2025-01-14 17:01:35.547632+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:01:55 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:02:09 KST)" (scheduled at 2025-01-14 17:01:49.750703+09:00)
INFO:werkzeug: * Detected change in 'C:\\kd\\ws_java\\team4_v2sbm3c\\src\\main\\python\\crawling.py', reloading
INFO:werkzeug: * Detected change in 'C:\\kd\\ws_java\\team4_v2sbm3c\\src\\main\\python\\crawling.py', reloading
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:02:09 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawl_and_insert_data" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 524-771-621
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:02:29 KST)" (scheduled at 2025-01-14 17:02:09.750703+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:02:29 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawl_and_insert_data" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
INFO:werkzeug:[33mPress CTRL+C to quit[0m
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawl_and_insert_data" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 524-771-621
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:02:50 KST)" (scheduled at 2025-01-14 17:02:50.800030+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:03:10 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:02:56 KST)" (scheduled at 2025-01-14 17:02:56.538863+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:03:16 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:03:30 KST)" (scheduled at 2025-01-14 17:03:10.800030+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:03:30 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:03:36 KST)" (scheduled at 2025-01-14 17:03:16.538863+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:03:36 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:03:50 KST)" (scheduled at 2025-01-14 17:03:30.800030+09:00)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:03:56 KST)" (scheduled at 2025-01-14 17:03:36.538863+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:03:50 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:03:56 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:04:10 KST)" (scheduled at 2025-01-14 17:03:50.800030+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:04:10 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:04:16 KST)" (scheduled at 2025-01-14 17:03:56.538863+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:04:16 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:04:30 KST)" (scheduled at 2025-01-14 17:04:10.800030+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:04:30 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:04:36 KST)" (scheduled at 2025-01-14 17:04:16.538863+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:04:36 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:04:50 KST)" (scheduled at 2025-01-14 17:04:30.800030+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:04:50 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:04:56 KST)" (scheduled at 2025-01-14 17:04:36.538863+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:04:56 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:05:10 KST)" (scheduled at 2025-01-14 17:04:50.800030+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:05:10 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:05:16 KST)" (scheduled at 2025-01-14 17:04:56.538863+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:05:16 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:05:30 KST)" (scheduled at 2025-01-14 17:05:10.800030+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:05:30 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:05:36 KST)" (scheduled at 2025-01-14 17:05:16.538863+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:05:36 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:05:50 KST)" (scheduled at 2025-01-14 17:05:30.800030+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:05:50 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:05:56 KST)" (scheduled at 2025-01-14 17:05:36.538863+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:05:56 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:06:10 KST)" (scheduled at 2025-01-14 17:05:50.800030+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:06:10 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:06:16 KST)" (scheduled at 2025-01-14 17:05:56.538863+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:06:16 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:06:30 KST)" (scheduled at 2025-01-14 17:06:10.800030+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:06:30 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:06:36 KST)" (scheduled at 2025-01-14 17:06:16.538863+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:06:36 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:06:50 KST)" (scheduled at 2025-01-14 17:06:30.800030+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:06:50 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:06:56 KST)" (scheduled at 2025-01-14 17:06:36.538863+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:06:56 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:07:10 KST)" (scheduled at 2025-01-14 17:06:50.800030+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:07:10 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:07:16 KST)" (scheduled at 2025-01-14 17:06:56.538863+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:07:16 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:07:30 KST)" (scheduled at 2025-01-14 17:07:10.800030+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:07:30 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:07:36 KST)" (scheduled at 2025-01-14 17:07:16.538863+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:07:36 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:07:50 KST)" (scheduled at 2025-01-14 17:07:30.800030+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:07:50 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:07:56 KST)" (scheduled at 2025-01-14 17:07:36.538863+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:07:56 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:08:10 KST)" (scheduled at 2025-01-14 17:07:50.800030+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:08:10 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:08:16 KST)" (scheduled at 2025-01-14 17:07:56.538863+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:08:16 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:08:30 KST)" (scheduled at 2025-01-14 17:08:10.800030+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:08:30 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:08:36 KST)" (scheduled at 2025-01-14 17:08:16.538863+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:08:36 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:08:50 KST)" (scheduled at 2025-01-14 17:08:30.800030+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:08:50 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:08:56 KST)" (scheduled at 2025-01-14 17:08:36.538863+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:08:56 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:09:10 KST)" (scheduled at 2025-01-14 17:08:50.800030+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:09:10 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:09:16 KST)" (scheduled at 2025-01-14 17:08:56.538863+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:09:16 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:09:30 KST)" (scheduled at 2025-01-14 17:09:10.800030+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:09:30 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:09:36 KST)" (scheduled at 2025-01-14 17:09:16.538863+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:09:36 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:09:50 KST)" (scheduled at 2025-01-14 17:09:30.800030+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:09:50 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:09:56 KST)" (scheduled at 2025-01-14 17:09:36.538863+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:09:56 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:10:10 KST)" (scheduled at 2025-01-14 17:09:50.800030+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:10:10 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:10:16 KST)" (scheduled at 2025-01-14 17:09:56.538863+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:10:16 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:10:30 KST)" (scheduled at 2025-01-14 17:10:10.800030+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:10:30 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:10:36 KST)" (scheduled at 2025-01-14 17:10:16.538863+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:10:36 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:werkzeug: * Detected change in 'C:\\ProgramData\\Anaconda3\\envs\\ai\\Lib\\site-packages\\IPython\\core\\interactiveshell.py', reloading
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:10:50 KST)" (scheduled at 2025-01-14 17:10:30.800030+09:00)
INFO:werkzeug: * Restarting with watchdog (windowsapi)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:10:50 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawl_and_insert_data" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 524-771-621
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:11:10 KST)" (scheduled at 2025-01-14 17:10:50.800030+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:11:10 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:11:01 KST)" (scheduled at 2025-01-14 17:11:01.175408+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:11:21 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:11:30 KST)" (scheduled at 2025-01-14 17:11:10.800030+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:11:30 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:11:41 KST)" (scheduled at 2025-01-14 17:11:21.175408+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:11:41 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:11:50 KST)" (scheduled at 2025-01-14 17:11:30.800030+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:11:50 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:12:01 KST)" (scheduled at 2025-01-14 17:11:41.175408+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:12:01 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:12:10 KST)" (scheduled at 2025-01-14 17:11:50.800030+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:12:10 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:12:21 KST)" (scheduled at 2025-01-14 17:12:01.175408+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:12:21 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:12:30 KST)" (scheduled at 2025-01-14 17:12:10.800030+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:12:30 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:12:41 KST)" (scheduled at 2025-01-14 17:12:21.175408+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:12:41 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:12:50 KST)" (scheduled at 2025-01-14 17:12:30.800030+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:12:50 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:13:01 KST)" (scheduled at 2025-01-14 17:12:41.175408+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:13:01 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:13:10 KST)" (scheduled at 2025-01-14 17:12:50.800030+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:13:10 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:13:21 KST)" (scheduled at 2025-01-14 17:13:01.175408+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:13:21 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:13:30 KST)" (scheduled at 2025-01-14 17:13:10.800030+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:13:30 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:13:41 KST)" (scheduled at 2025-01-14 17:13:21.175408+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:13:41 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:13:50 KST)" (scheduled at 2025-01-14 17:13:30.800030+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:13:50 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:14:01 KST)" (scheduled at 2025-01-14 17:13:41.175408+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:14:01 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:14:10 KST)" (scheduled at 2025-01-14 17:13:50.800030+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:14:10 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:14:21 KST)" (scheduled at 2025-01-14 17:14:01.175408+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:14:21 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:14:30 KST)" (scheduled at 2025-01-14 17:14:10.800030+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:14:30 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:14:41 KST)" (scheduled at 2025-01-14 17:14:21.175408+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:14:41 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:14:50 KST)" (scheduled at 2025-01-14 17:14:30.800030+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:14:50 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:15:01 KST)" (scheduled at 2025-01-14 17:14:41.175408+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:15:01 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:15:10 KST)" (scheduled at 2025-01-14 17:14:50.800030+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:15:10 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:15:21 KST)" (scheduled at 2025-01-14 17:15:01.175408+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:15:21 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:15:30 KST)" (scheduled at 2025-01-14 17:15:10.800030+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:15:30 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:15:41 KST)" (scheduled at 2025-01-14 17:15:21.175408+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:15:41 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:15:50 KST)" (scheduled at 2025-01-14 17:15:30.800030+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:15:50 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:16:01 KST)" (scheduled at 2025-01-14 17:15:41.175408+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:16:01 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:16:10 KST)" (scheduled at 2025-01-14 17:15:50.800030+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:16:10 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:16:21 KST)" (scheduled at 2025-01-14 17:16:01.175408+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:16:21 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:16:30 KST)" (scheduled at 2025-01-14 17:16:10.800030+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:16:30 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:16:41 KST)" (scheduled at 2025-01-14 17:16:21.175408+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:16:41 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:16:50 KST)" (scheduled at 2025-01-14 17:16:30.800030+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:16:50 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:17:01 KST)" (scheduled at 2025-01-14 17:16:41.175408+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:17:01 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:17:10 KST)" (scheduled at 2025-01-14 17:16:50.800030+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:17:10 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:17:21 KST)" (scheduled at 2025-01-14 17:17:01.175408+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:17:21 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:17:30 KST)" (scheduled at 2025-01-14 17:17:10.800030+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:17:30 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:17:41 KST)" (scheduled at 2025-01-14 17:17:21.175408+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:17:41 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:17:50 KST)" (scheduled at 2025-01-14 17:17:30.800030+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:17:50 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:18:01 KST)" (scheduled at 2025-01-14 17:17:41.175408+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:18:01 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:18:10 KST)" (scheduled at 2025-01-14 17:17:50.800030+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:18:10 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:18:21 KST)" (scheduled at 2025-01-14 17:18:01.175408+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:18:21 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:18:30 KST)" (scheduled at 2025-01-14 17:18:10.800030+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:18:30 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:18:41 KST)" (scheduled at 2025-01-14 17:18:21.175408+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:18:41 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:18:50 KST)" (scheduled at 2025-01-14 17:18:30.800030+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:18:50 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:19:01 KST)" (scheduled at 2025-01-14 17:18:41.175408+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:19:01 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:19:10 KST)" (scheduled at 2025-01-14 17:18:50.800030+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:19:10 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:19:21 KST)" (scheduled at 2025-01-14 17:19:01.175408+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:19:21 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:19:30 KST)" (scheduled at 2025-01-14 17:19:10.800030+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:19:30 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:19:41 KST)" (scheduled at 2025-01-14 17:19:21.175408+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:19:41 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:19:50 KST)" (scheduled at 2025-01-14 17:19:30.800030+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:19:50 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:20:01 KST)" (scheduled at 2025-01-14 17:19:41.175408+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:20:01 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:20:10 KST)" (scheduled at 2025-01-14 17:19:50.800030+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:20:10 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:20:21 KST)" (scheduled at 2025-01-14 17:20:01.175408+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:20:21 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:20:30 KST)" (scheduled at 2025-01-14 17:20:10.800030+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:20:30 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:20:41 KST)" (scheduled at 2025-01-14 17:20:21.175408+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:20:41 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:20:50 KST)" (scheduled at 2025-01-14 17:20:30.800030+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:20:50 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:21:01 KST)" (scheduled at 2025-01-14 17:20:41.175408+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:21:01 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:21:10 KST)" (scheduled at 2025-01-14 17:20:50.800030+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:21:10 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:21:21 KST)" (scheduled at 2025-01-14 17:21:01.175408+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:21:21 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:21:30 KST)" (scheduled at 2025-01-14 17:21:10.800030+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:21:30 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:21:41 KST)" (scheduled at 2025-01-14 17:21:21.175408+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:21:41 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:21:50 KST)" (scheduled at 2025-01-14 17:21:30.800030+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:21:50 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:22:01 KST)" (scheduled at 2025-01-14 17:21:41.175408+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:22:01 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:22:10 KST)" (scheduled at 2025-01-14 17:21:50.800030+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:22:10 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:22:21 KST)" (scheduled at 2025-01-14 17:22:01.175408+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:22:21 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:22:30 KST)" (scheduled at 2025-01-14 17:22:10.800030+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:22:30 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:22:41 KST)" (scheduled at 2025-01-14 17:22:21.175408+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:22:41 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:22:50 KST)" (scheduled at 2025-01-14 17:22:30.800030+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:22:50 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:23:01 KST)" (scheduled at 2025-01-14 17:22:41.175408+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:23:01 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:23:10 KST)" (scheduled at 2025-01-14 17:22:50.800030+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:23:10 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:23:21 KST)" (scheduled at 2025-01-14 17:23:01.175408+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:23:21 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:23:30 KST)" (scheduled at 2025-01-14 17:23:10.800030+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:23:30 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:23:41 KST)" (scheduled at 2025-01-14 17:23:21.175408+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:23:41 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:23:50 KST)" (scheduled at 2025-01-14 17:23:30.800030+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:23:50 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:24:01 KST)" (scheduled at 2025-01-14 17:23:41.175408+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:24:01 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:24:10 KST)" (scheduled at 2025-01-14 17:23:50.800030+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:24:10 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:24:21 KST)" (scheduled at 2025-01-14 17:24:01.175408+09:00)
INFO:werkzeug: * Detected change in 'C:\\ProgramData\\Anaconda3\\Lib\\site-packages\\pandas\\__init__.py', reloading
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:24:21 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:24:30 KST)" (scheduled at 2025-01-14 17:24:10.800030+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:24:30 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawl_and_insert_data" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 524-771-621
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:24:50 KST)" (scheduled at 2025-01-14 17:24:30.800030+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:24:50 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:24:41 KST)" (scheduled at 2025-01-14 17:24:41.379071+09:00)
INFO:werkzeug: * Detected change in 'C:\\Users\\soldesk\\AppData\\Roaming\\Python\\Python310\\site-packages\\apscheduler\\executors\\base.py', reloading
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:25:01 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:25:10 KST)" (scheduled at 2025-01-14 17:24:50.800030+09:00)
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:25:10 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawl_and_insert_data" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 524-771-621
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:25:30 KST)" (scheduled at 2025-01-14 17:25:10.800030+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:25:30 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:25:19 KST)" (scheduled at 2025-01-14 17:25:19.413694+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:25:39 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:25:50 KST)" (scheduled at 2025-01-14 17:25:30.800030+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:25:50 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 257, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 46: illegal multibyte sequence
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawl_and_insert_data" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
INFO:werkzeug:[33mPress CTRL+C to quit[0m
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawl_and_insert_data" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 524-771-621
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawl_and_insert_data" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
INFO:werkzeug:[33mPress CTRL+C to quit[0m
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawl_and_insert_data" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 524-771-621
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:38:45 KST)" (scheduled at 2025-01-14 17:38:45.007632+09:00)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:38:51 KST)" (scheduled at 2025-01-14 17:38:51.177741+09:00)
WARNING:apscheduler.scheduler:Execution of job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:39:05 KST)" skipped: maximum number of running instances reached (1)
WARNING:apscheduler.scheduler:Execution of job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:39:11 KST)" skipped: maximum number of running instances reached (1)
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:39:31 KST)" executed successfully
WARNING:apscheduler.scheduler:Execution of job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:39:25 KST)" skipped: maximum number of running instances reached (1)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:39:51 KST)" (scheduled at 2025-01-14 17:39:31.177741+09:00)
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
WARNING:apscheduler.scheduler:Execution of job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:39:45 KST)" skipped: maximum number of running instances reached (1)
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:40:05 KST)" executed successfully
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
WARNING:apscheduler.scheduler:Execution of job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:39:51 KST)" skipped: maximum number of running instances reached (1)
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:40:11 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:40:25 KST)" (scheduled at 2025-01-14 17:40:05.007632+09:00)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:40:31 KST)" (scheduled at 2025-01-14 17:40:11.177741+09:00)
WARNING:apscheduler.scheduler:Execution of job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:40:25 KST)" skipped: maximum number of running instances reached (1)
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:40:45 KST)" executed successfully
WARNING:apscheduler.scheduler:Execution of job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:40:31 KST)" skipped: maximum number of running instances reached (1)
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:40:51 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:41:05 KST)" (scheduled at 2025-01-14 17:40:45.007632+09:00)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:41:11 KST)" (scheduled at 2025-01-14 17:40:51.177741+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:41:11 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 108, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 38, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchWindowException: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x004EFD53+23747]
	(No symbol) [0x00477D54]
	(No symbol) [0x0034BE53]
	(No symbol) [0x0032D91B]
	(No symbol) [0x003B7EFF]
	(No symbol) [0x003CAD49]
	(No symbol) [0x003B1B96]
	(No symbol) [0x00383F3C]
	(No symbol) [0x00384EBD]
	GetHandleVerifier [0x007CAC73+3017699]
	GetHandleVerifier [0x007DB93B+3086507]
	GetHandleVerifier [0x007D40F2+3055714]
	GetHandleVerifier [0x00585AF0+637536]
	(No symbol) [0x00480A5D]
	(No symbol) [0x0047DA28]
	(No symbol) [0x0047DBC5]
	(No symbol) [0x004707F0]
	BaseThreadInitThunk [0x76E2FCC9+25]
	RtlGetAppContainerNamedObjectPath [0x77B2809E+286]
	RtlGetAppContainerNamedObjectPath [0x77B2806E+238]

INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
WARNING:apscheduler.scheduler:Execution of job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:41:05 KST)" skipped: maximum number of running instances reached (1)
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawl_and_insert_data" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
INFO:werkzeug:[33mPress CTRL+C to quit[0m
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:41:31 KST)" (scheduled at 2025-01-14 17:41:11.177741+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:41:31 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 108, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 38, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchWindowException: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x004EFD53+23747]
	(No symbol) [0x00477D54]
	(No symbol) [0x0034BE53]
	(No symbol) [0x0032D91B]
	(No symbol) [0x003B7EFF]
	(No symbol) [0x003CAD49]
	(No symbol) [0x003B1B96]
	(No symbol) [0x00383F3C]
	(No symbol) [0x00384EBD]
	GetHandleVerifier [0x007CAC73+3017699]
	GetHandleVerifier [0x007DB93B+3086507]
	GetHandleVerifier [0x007D40F2+3055714]
	GetHandleVerifier [0x00585AF0+637536]
	(No symbol) [0x00480A5D]
	(No symbol) [0x0047DA28]
	(No symbol) [0x0047DBC5]
	(No symbol) [0x004707F0]
	BaseThreadInitThunk [0x76E2FCC9+25]
	RtlGetAppContainerNamedObjectPath [0x77B2809E+286]
	RtlGetAppContainerNamedObjectPath [0x77B2806E+238]

INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawl_and_insert_data" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 524-771-621
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:41:27 KST)" (scheduled at 2025-01-14 17:41:27.239420+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 17:41:47 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 108, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 38, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchWindowException: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x004EFD53+23747]
	(No symbol) [0x00477D54]
	(No symbol) [0x0034BE53]
	(No symbol) [0x0032D91B]
	(No symbol) [0x003B7EFF]
	(No symbol) [0x003CAD49]
	(No symbol) [0x003B1B96]
	(No symbol) [0x00383F3C]
	(No symbol) [0x00384EBD]
	GetHandleVerifier [0x007CAC73+3017699]
	GetHandleVerifier [0x007DB93B+3086507]
	GetHandleVerifier [0x007D40F2+3055714]
	GetHandleVerifier [0x00585AF0+637536]
	(No symbol) [0x00480A5D]
	(No symbol) [0x0047DA28]
	(No symbol) [0x0047DBC5]
	(No symbol) [0x004707F0]
	BaseThreadInitThunk [0x76E2FCC9+25]
	RtlGetAppContainerNamedObjectPath [0x77B2809E+286]
	RtlGetAppContainerNamedObjectPath [0x77B2806E+238]

INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:There is no [win64] chromedriver "131.0.6778.264" for browser google-chrome "131.0.6778" in cache
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:WebDriver version 131.0.6778.264 selected
INFO:WDM:Modern chrome version https://storage.googleapis.com/chrome-for-testing-public/131.0.6778.264/win32/chromedriver-win32.zip
INFO:WDM:About to download new driver from https://storage.googleapis.com/chrome-for-testing-public/131.0.6778.264/win32/chromedriver-win32.zip
INFO:WDM:Driver downloading response is 200
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver has been saved in cache [C:\Users\i\.wdm\drivers\chromedriver\win64\131.0.6778.264]
INFO:WDM:====== WebDriver manager ======
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawl_and_insert_data" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
INFO:werkzeug:[33mPress CTRL+C to quit[0m
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\i\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawl_and_insert_data" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
INFO:werkzeug:[33mPress CTRL+C to quit[0m
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\i\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:WDM:====== WebDriver manager ======
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawl_and_insert_data" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 569-178-434
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\i\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawl_and_insert_data" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 569-178-434
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 18:59:28 KST)" (scheduled at 2025-01-14 18:59:28.975517+09:00)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 18:59:30 KST)" (scheduled at 2025-01-14 18:59:30.966502+09:00)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 18:59:34 KST)" (scheduled at 2025-01-14 18:59:34.380568+09:00)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 18:59:36 KST)" (scheduled at 2025-01-14 18:59:36.166765+09:00)
INFO:werkzeug: * Detected change in 'C:\\Users\\i\\AppData\\Roaming\\Python\\Python310\\site-packages\\openai\\types\\__init__.py', reloading
INFO:werkzeug: * Detected change in 'C:\\Users\\i\\AppData\\Roaming\\Python\\Python310\\site-packages\\openai\\types\\__init__.py', reloading
INFO:werkzeug: * Detected change in 'C:\\Users\\i\\AppData\\Roaming\\Python\\Python310\\site-packages\\openai\\types\\batch.py', reloading
INFO:werkzeug: * Detected change in 'C:\\Users\\i\\AppData\\Roaming\\Python\\Python310\\site-packages\\openai\\types\\batch.py', reloading
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 18:59:50 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 288, in crawl_and_insert_data
    from openai import OpenAI # 1.x~
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\openai\__init__.py", line 8, in <module>
    from . import types
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\openai\types\__init__.py", line 5, in <module>
    from .batch import Batch as Batch
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\openai\types\batch.py", line 7, in <module>
    from .._models import BaseModel
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\openai\_models.py", line 26, in <module>
    from ._types import (
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\openai\_types.py", line 21, in <module>
    import httpx
ModuleNotFoundError: No module named 'httpx'
WARNING:apscheduler.scheduler:Execution of job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 18:59:48 KST)" skipped: maximum number of running instances reached (1)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 19:00:10 KST)" (scheduled at 2025-01-14 18:59:50.966502+09:00)
WARNING:apscheduler.scheduler:Execution of job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 18:59:54 KST)" skipped: maximum number of running instances reached (1)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 19:00:10 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 288, in crawl_and_insert_data
    from openai import OpenAI # 1.x~
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\openai\__init__.py", line 8, in <module>
    from . import types
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\openai\types\__init__.py", line 5, in <module>
    from .batch import Batch as Batch
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\openai\types\batch.py", line 7, in <module>
    from .._models import BaseModel
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\openai\_models.py", line 26, in <module>
    from ._types import (
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\openai\_types.py", line 21, in <module>
    import httpx
ModuleNotFoundError: No module named 'httpx'
WARNING:apscheduler.scheduler:Execution of job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 18:59:56 KST)" skipped: maximum number of running instances reached (1)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 19:00:08 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 288, in crawl_and_insert_data
    from openai import OpenAI # 1.x~
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\openai\__init__.py", line 8, in <module>
    from . import types
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\openai\types\__init__.py", line 5, in <module>
    from .batch import Batch as Batch
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\openai\types\batch.py", line 7, in <module>
    from .._models import BaseModel
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\openai\_models.py", line 26, in <module>
    from ._types import (
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\openai\_types.py", line 21, in <module>
    import httpx
ModuleNotFoundError: No module named 'httpx'
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 19:00:28 KST)" (scheduled at 2025-01-14 19:00:08.975517+09:00)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 19:00:30 KST)" (scheduled at 2025-01-14 19:00:10.966502+09:00)
WARNING:apscheduler.scheduler:Execution of job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 19:00:14 KST)" skipped: maximum number of running instances reached (1)
WARNING:apscheduler.scheduler:Execution of job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 19:00:16 KST)" skipped: maximum number of running instances reached (1)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 19:00:36 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 129, in crawl_and_insert_data
    url = driver.current_url
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 437, in current_url
    return self.execute(Command.GET_CURRENT_URL)["value"]
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: disconnected: not connected to DevTools
  (failed to check if window was closed: disconnected: not connected to DevTools)
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x007BFD53+23747]
	(No symbol) [0x00747D54]
	(No symbol) [0x0061BE53]
	(No symbol) [0x0060C408]
	(No symbol) [0x0060C329]
	(No symbol) [0x0061E2E0]
	(No symbol) [0x0069AD69]
	(No symbol) [0x00681B96]
	(No symbol) [0x00653F3C]
	(No symbol) [0x00654EBD]
	GetHandleVerifier [0x00A9AC73+3017699]
	GetHandleVerifier [0x00AAB93B+3086507]
	GetHandleVerifier [0x00AA40F2+3055714]
	GetHandleVerifier [0x00855AF0+637536]
	(No symbol) [0x00750A5D]
	(No symbol) [0x0074DA28]
	(No symbol) [0x0074DBC5]
	(No symbol) [0x007407F0]
	BaseThreadInitThunk [0x754CFCC9+25]
	RtlGetAppContainerNamedObjectPath [0x76F4809E+286]
	RtlGetAppContainerNamedObjectPath [0x76F4806E+238]

ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 19:00:34 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 129, in crawl_and_insert_data
    url = driver.current_url
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 437, in current_url
    return self.execute(Command.GET_CURRENT_URL)["value"]
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: disconnected: not connected to DevTools
  (failed to check if window was closed: disconnected: not connected to DevTools)
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x007BFD53+23747]
	(No symbol) [0x00747D54]
	(No symbol) [0x0061BE53]
	(No symbol) [0x0060C408]
	(No symbol) [0x0060C329]
	(No symbol) [0x0061E2E0]
	(No symbol) [0x0069AD69]
	(No symbol) [0x00681B96]
	(No symbol) [0x00653F3C]
	(No symbol) [0x00654EBD]
	GetHandleVerifier [0x00A9AC73+3017699]
	GetHandleVerifier [0x00AAB93B+3086507]
	GetHandleVerifier [0x00AA40F2+3055714]
	GetHandleVerifier [0x00855AF0+637536]
	(No symbol) [0x00750A5D]
	(No symbol) [0x0074DA28]
	(No symbol) [0x0074DBC5]
	(No symbol) [0x007407F0]
	BaseThreadInitThunk [0x754CFCC9+25]
	RtlGetAppContainerNamedObjectPath [0x76F4809E+286]
	RtlGetAppContainerNamedObjectPath [0x76F4806E+238]

INFO:werkzeug: * Restarting with watchdog (windowsapi)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 19:00:30 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 129, in crawl_and_insert_data
    url = driver.current_url
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 437, in current_url
    return self.execute(Command.GET_CURRENT_URL)["value"]
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: disconnected: not connected to DevTools
  (failed to check if window was closed: disconnected: not connected to DevTools)
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x007BFD53+23747]
	(No symbol) [0x00747D54]
	(No symbol) [0x0061BE53]
	(No symbol) [0x0060C408]
	(No symbol) [0x0060C329]
	(No symbol) [0x0061E2E0]
	(No symbol) [0x0069AD69]
	(No symbol) [0x00681B96]
	(No symbol) [0x00653F3C]
	(No symbol) [0x00654EBD]
	GetHandleVerifier [0x00A9AC73+3017699]
	GetHandleVerifier [0x00AAB93B+3086507]
	GetHandleVerifier [0x00AA40F2+3055714]
	GetHandleVerifier [0x00855AF0+637536]
	(No symbol) [0x00750A5D]
	(No symbol) [0x0074DA28]
	(No symbol) [0x0074DBC5]
	(No symbol) [0x007407F0]
	BaseThreadInitThunk [0x754CFCC9+25]
	RtlGetAppContainerNamedObjectPath [0x76F4809E+286]
	RtlGetAppContainerNamedObjectPath [0x76F4806E+238]

ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 19:00:28 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 129, in crawl_and_insert_data
    url = driver.current_url
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 437, in current_url
    return self.execute(Command.GET_CURRENT_URL)["value"]
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: disconnected: not connected to DevTools
  (failed to check if window was closed: disconnected: not connected to DevTools)
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x007BFD53+23747]
	(No symbol) [0x00747D54]
	(No symbol) [0x0061BE53]
	(No symbol) [0x0060C408]
	(No symbol) [0x0060C329]
	(No symbol) [0x0061E2E0]
	(No symbol) [0x0069AD69]
	(No symbol) [0x00681B96]
	(No symbol) [0x00653F3C]
	(No symbol) [0x00654EBD]
	GetHandleVerifier [0x00A9AC73+3017699]
	GetHandleVerifier [0x00AAB93B+3086507]
	GetHandleVerifier [0x00AA40F2+3055714]
	GetHandleVerifier [0x00855AF0+637536]
	(No symbol) [0x00750A5D]
	(No symbol) [0x0074DA28]
	(No symbol) [0x0074DBC5]
	(No symbol) [0x007407F0]
	BaseThreadInitThunk [0x754CFCC9+25]
	RtlGetAppContainerNamedObjectPath [0x76F4809E+286]
	RtlGetAppContainerNamedObjectPath [0x76F4806E+238]

INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 19:00:48 KST)" (scheduled at 2025-01-14 19:00:28.975517+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 19:00:48 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 108, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 38, in load
    driver.get(url) # url 접속
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: disconnected: not connected to DevTools
  (failed to check if window was closed: disconnected: not connected to DevTools)
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x007BFD53+23747]
	(No symbol) [0x00747D54]
	(No symbol) [0x0061BE53]
	(No symbol) [0x0060C408]
	(No symbol) [0x0060C329]
	(No symbol) [0x0061E2E0]
	(No symbol) [0x0069AD69]
	(No symbol) [0x00681B96]
	(No symbol) [0x00653F3C]
	(No symbol) [0x00654EBD]
	GetHandleVerifier [0x00A9AC73+3017699]
	GetHandleVerifier [0x00AAB93B+3086507]
	GetHandleVerifier [0x00AA40F2+3055714]
	GetHandleVerifier [0x00855AF0+637536]
	(No symbol) [0x00750A5D]
	(No symbol) [0x0074DA28]
	(No symbol) [0x0074DBC5]
	(No symbol) [0x007407F0]
	BaseThreadInitThunk [0x754CFCC9+25]
	RtlGetAppContainerNamedObjectPath [0x76F4809E+286]
	RtlGetAppContainerNamedObjectPath [0x76F4806E+238]

INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 19:00:50 KST)" (scheduled at 2025-01-14 19:00:30.966502+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 19:00:50 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 108, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 38, in load
    driver.get(url) # url 접속
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: disconnected: not connected to DevTools
  (failed to check if window was closed: disconnected: not connected to DevTools)
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x007BFD53+23747]
	(No symbol) [0x00747D54]
	(No symbol) [0x0061BE53]
	(No symbol) [0x0060C408]
	(No symbol) [0x0060C329]
	(No symbol) [0x0061E2E0]
	(No symbol) [0x0069AD69]
	(No symbol) [0x00681B96]
	(No symbol) [0x00653F3C]
	(No symbol) [0x00654EBD]
	GetHandleVerifier [0x00A9AC73+3017699]
	GetHandleVerifier [0x00AAB93B+3086507]
	GetHandleVerifier [0x00AA40F2+3055714]
	GetHandleVerifier [0x00855AF0+637536]
	(No symbol) [0x00750A5D]
	(No symbol) [0x0074DA28]
	(No symbol) [0x0074DBC5]
	(No symbol) [0x007407F0]
	BaseThreadInitThunk [0x754CFCC9+25]
	RtlGetAppContainerNamedObjectPath [0x76F4809E+286]
	RtlGetAppContainerNamedObjectPath [0x76F4806E+238]

INFO:WDM:====== WebDriver manager ======
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\i\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\i\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawl_and_insert_data" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 569-178-434
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawl_and_insert_data" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 569-178-434
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 19:01:08 KST)" (scheduled at 2025-01-14 19:00:48.975517+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 19:01:08 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 108, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 38, in load
    driver.get(url) # url 접속
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: disconnected: not connected to DevTools
  (failed to check if window was closed: disconnected: not connected to DevTools)
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x007BFD53+23747]
	(No symbol) [0x00747D54]
	(No symbol) [0x0061BE53]
	(No symbol) [0x0060C408]
	(No symbol) [0x0060C329]
	(No symbol) [0x0061E2E0]
	(No symbol) [0x0069AD69]
	(No symbol) [0x00681B96]
	(No symbol) [0x00653F3C]
	(No symbol) [0x00654EBD]
	GetHandleVerifier [0x00A9AC73+3017699]
	GetHandleVerifier [0x00AAB93B+3086507]
	GetHandleVerifier [0x00AA40F2+3055714]
	GetHandleVerifier [0x00855AF0+637536]
	(No symbol) [0x00750A5D]
	(No symbol) [0x0074DA28]
	(No symbol) [0x0074DBC5]
	(No symbol) [0x007407F0]
	BaseThreadInitThunk [0x754CFCC9+25]
	RtlGetAppContainerNamedObjectPath [0x76F4809E+286]
	RtlGetAppContainerNamedObjectPath [0x76F4806E+238]

INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 19:01:10 KST)" (scheduled at 2025-01-14 19:00:50.966502+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 19:01:10 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 108, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 38, in load
    driver.get(url) # url 접속
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: disconnected: not connected to DevTools
  (failed to check if window was closed: disconnected: not connected to DevTools)
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x007BFD53+23747]
	(No symbol) [0x00747D54]
	(No symbol) [0x0061BE53]
	(No symbol) [0x0060C408]
	(No symbol) [0x0060C329]
	(No symbol) [0x0061E2E0]
	(No symbol) [0x0069AD69]
	(No symbol) [0x00681B96]
	(No symbol) [0x00653F3C]
	(No symbol) [0x00654EBD]
	GetHandleVerifier [0x00A9AC73+3017699]
	GetHandleVerifier [0x00AAB93B+3086507]
	GetHandleVerifier [0x00AA40F2+3055714]
	GetHandleVerifier [0x00855AF0+637536]
	(No symbol) [0x00750A5D]
	(No symbol) [0x0074DA28]
	(No symbol) [0x0074DBC5]
	(No symbol) [0x007407F0]
	BaseThreadInitThunk [0x754CFCC9+25]
	RtlGetAppContainerNamedObjectPath [0x76F4809E+286]
	RtlGetAppContainerNamedObjectPath [0x76F4806E+238]

INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 19:00:57 KST)" (scheduled at 2025-01-14 19:00:57.912732+09:00)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 19:00:57 KST)" (scheduled at 2025-01-14 19:00:57.979729+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 19:01:17 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 129, in crawl_and_insert_data
    url = driver.current_url
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 437, in current_url
    return self.execute(Command.GET_CURRENT_URL)["value"]
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchWindowException: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x007BFD53+23747]
	(No symbol) [0x00747D54]
	(No symbol) [0x0061BE53]
	(No symbol) [0x005FD91B]
	(No symbol) [0x00687EFF]
	(No symbol) [0x0069AD49]
	(No symbol) [0x00681B96]
	(No symbol) [0x00653F3C]
	(No symbol) [0x00654EBD]
	GetHandleVerifier [0x00A9AC73+3017699]
	GetHandleVerifier [0x00AAB93B+3086507]
	GetHandleVerifier [0x00AA40F2+3055714]
	GetHandleVerifier [0x00855AF0+637536]
	(No symbol) [0x00750A5D]
	(No symbol) [0x0074DA28]
	(No symbol) [0x0074DBC5]
	(No symbol) [0x007407F0]
	BaseThreadInitThunk [0x754CFCC9+25]
	RtlGetAppContainerNamedObjectPath [0x76F4809E+286]
	RtlGetAppContainerNamedObjectPath [0x76F4806E+238]

ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 19:01:17 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 288, in crawl_and_insert_data
    from openai import OpenAI # 1.x~
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\openai\__init__.py", line 8, in <module>
    from . import types
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\openai\types\__init__.py", line 5, in <module>
    from .batch import Batch as Batch
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\openai\types\batch.py", line 7, in <module>
    from .._models import BaseModel
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\openai\_models.py", line 26, in <module>
    from ._types import (
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\openai\_types.py", line 21, in <module>
    import httpx
ModuleNotFoundError: No module named 'httpx'
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 19:01:28 KST)" (scheduled at 2025-01-14 19:01:08.975517+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 19:01:28 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 108, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 38, in load
    driver.get(url) # url 접속
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: disconnected: not connected to DevTools
  (failed to check if window was closed: disconnected: not connected to DevTools)
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x007BFD53+23747]
	(No symbol) [0x00747D54]
	(No symbol) [0x0061BE53]
	(No symbol) [0x0060C408]
	(No symbol) [0x0060C329]
	(No symbol) [0x0061E2E0]
	(No symbol) [0x0069AD69]
	(No symbol) [0x00681B96]
	(No symbol) [0x00653F3C]
	(No symbol) [0x00654EBD]
	GetHandleVerifier [0x00A9AC73+3017699]
	GetHandleVerifier [0x00AAB93B+3086507]
	GetHandleVerifier [0x00AA40F2+3055714]
	GetHandleVerifier [0x00855AF0+637536]
	(No symbol) [0x00750A5D]
	(No symbol) [0x0074DA28]
	(No symbol) [0x0074DBC5]
	(No symbol) [0x007407F0]
	BaseThreadInitThunk [0x754CFCC9+25]
	RtlGetAppContainerNamedObjectPath [0x76F4809E+286]
	RtlGetAppContainerNamedObjectPath [0x76F4806E+238]

INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 19:01:30 KST)" (scheduled at 2025-01-14 19:01:10.966502+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 19:01:30 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 108, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 38, in load
    driver.get(url) # url 접속
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: disconnected: not connected to DevTools
  (failed to check if window was closed: disconnected: not connected to DevTools)
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x007BFD53+23747]
	(No symbol) [0x00747D54]
	(No symbol) [0x0061BE53]
	(No symbol) [0x0060C408]
	(No symbol) [0x0060C329]
	(No symbol) [0x0061E2E0]
	(No symbol) [0x0069AD69]
	(No symbol) [0x00681B96]
	(No symbol) [0x00653F3C]
	(No symbol) [0x00654EBD]
	GetHandleVerifier [0x00A9AC73+3017699]
	GetHandleVerifier [0x00AAB93B+3086507]
	GetHandleVerifier [0x00AA40F2+3055714]
	GetHandleVerifier [0x00855AF0+637536]
	(No symbol) [0x00750A5D]
	(No symbol) [0x0074DA28]
	(No symbol) [0x0074DBC5]
	(No symbol) [0x007407F0]
	BaseThreadInitThunk [0x754CFCC9+25]
	RtlGetAppContainerNamedObjectPath [0x76F4809E+286]
	RtlGetAppContainerNamedObjectPath [0x76F4806E+238]

INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 19:01:37 KST)" (scheduled at 2025-01-14 19:01:17.912732+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 19:01:37 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 108, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 38, in load
    driver.get(url) # url 접속
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchWindowException: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x007BFD53+23747]
	(No symbol) [0x00747D54]
	(No symbol) [0x0061BE53]
	(No symbol) [0x005FD91B]
	(No symbol) [0x00687EFF]
	(No symbol) [0x0069AD49]
	(No symbol) [0x00681B96]
	(No symbol) [0x00653F3C]
	(No symbol) [0x00654EBD]
	GetHandleVerifier [0x00A9AC73+3017699]
	GetHandleVerifier [0x00AAB93B+3086507]
	GetHandleVerifier [0x00AA40F2+3055714]
	GetHandleVerifier [0x00855AF0+637536]
	(No symbol) [0x00750A5D]
	(No symbol) [0x0074DA28]
	(No symbol) [0x0074DBC5]
	(No symbol) [0x007407F0]
	BaseThreadInitThunk [0x754CFCC9+25]
	RtlGetAppContainerNamedObjectPath [0x76F4809E+286]
	RtlGetAppContainerNamedObjectPath [0x76F4806E+238]

INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 19:01:37 KST)" (scheduled at 2025-01-14 19:01:17.979729+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 19:01:37 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 108, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 38, in load
    driver.get(url) # url 접속
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchWindowException: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x007BFD53+23747]
	(No symbol) [0x00747D54]
	(No symbol) [0x0061BE53]
	(No symbol) [0x005FD91B]
	(No symbol) [0x00687EFF]
	(No symbol) [0x0069AD49]
	(No symbol) [0x00681B96]
	(No symbol) [0x00653F3C]
	(No symbol) [0x00654EBD]
	GetHandleVerifier [0x00A9AC73+3017699]
	GetHandleVerifier [0x00AAB93B+3086507]
	GetHandleVerifier [0x00AA40F2+3055714]
	GetHandleVerifier [0x00855AF0+637536]
	(No symbol) [0x00750A5D]
	(No symbol) [0x0074DA28]
	(No symbol) [0x0074DBC5]
	(No symbol) [0x007407F0]
	BaseThreadInitThunk [0x754CFCC9+25]
	RtlGetAppContainerNamedObjectPath [0x76F4809E+286]
	RtlGetAppContainerNamedObjectPath [0x76F4806E+238]

INFO:werkzeug: * Detected change in 'C:\\kd\\ws_java\\team4_v2sbm3c\\src\\main\\python\\exc.py', reloading
INFO:werkzeug: * Detected change in 'C:\\kd\\ws_java\\team4_v2sbm3c\\src\\main\\python\\exc.py', reloading
INFO:werkzeug: * Detected change in 'C:\\kd\\ws_java\\team4_v2sbm3c\\src\\main\\python\\exc.py', reloading
INFO:werkzeug: * Detected change in 'C:\\kd\\ws_java\\team4_v2sbm3c\\src\\main\\python\\exc.py', reloading
INFO:werkzeug: * Detected change in 'C:\\kd\\ws_java\\team4_v2sbm3c\\src\\main\\python\\exc.py', reloading
INFO:werkzeug: * Detected change in 'C:\\kd\\ws_java\\team4_v2sbm3c\\src\\main\\python\\exc.py', reloading
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\i\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:WDM:Driver [C:\Users\i\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 19:01:48 KST)" (scheduled at 2025-01-14 19:01:28.975517+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 19:01:48 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 108, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 38, in load
    driver.get(url) # url 접속
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: disconnected: not connected to DevTools
  (failed to check if window was closed: disconnected: not connected to DevTools)
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x007BFD53+23747]
	(No symbol) [0x00747D54]
	(No symbol) [0x0061BE53]
	(No symbol) [0x0060C408]
	(No symbol) [0x0060C329]
	(No symbol) [0x0061E2E0]
	(No symbol) [0x0069AD69]
	(No symbol) [0x00681B96]
	(No symbol) [0x00653F3C]
	(No symbol) [0x00654EBD]
	GetHandleVerifier [0x00A9AC73+3017699]
	GetHandleVerifier [0x00AAB93B+3086507]
	GetHandleVerifier [0x00AA40F2+3055714]
	GetHandleVerifier [0x00855AF0+637536]
	(No symbol) [0x00750A5D]
	(No symbol) [0x0074DA28]
	(No symbol) [0x0074DBC5]
	(No symbol) [0x007407F0]
	BaseThreadInitThunk [0x754CFCC9+25]
	RtlGetAppContainerNamedObjectPath [0x76F4809E+286]
	RtlGetAppContainerNamedObjectPath [0x76F4806E+238]

INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawl_and_insert_data" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 569-178-434
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawl_and_insert_data" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 569-178-434
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 19:01:50 KST)" (scheduled at 2025-01-14 19:01:30.966502+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 19:01:50 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 108, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 38, in load
    driver.get(url) # url 접속
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: disconnected: not connected to DevTools
  (failed to check if window was closed: disconnected: not connected to DevTools)
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x007BFD53+23747]
	(No symbol) [0x00747D54]
	(No symbol) [0x0061BE53]
	(No symbol) [0x0060C408]
	(No symbol) [0x0060C329]
	(No symbol) [0x0061E2E0]
	(No symbol) [0x0069AD69]
	(No symbol) [0x00681B96]
	(No symbol) [0x00653F3C]
	(No symbol) [0x00654EBD]
	GetHandleVerifier [0x00A9AC73+3017699]
	GetHandleVerifier [0x00AAB93B+3086507]
	GetHandleVerifier [0x00AA40F2+3055714]
	GetHandleVerifier [0x00855AF0+637536]
	(No symbol) [0x00750A5D]
	(No symbol) [0x0074DA28]
	(No symbol) [0x0074DBC5]
	(No symbol) [0x007407F0]
	BaseThreadInitThunk [0x754CFCC9+25]
	RtlGetAppContainerNamedObjectPath [0x76F4809E+286]
	RtlGetAppContainerNamedObjectPath [0x76F4806E+238]

INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 19:02:08 KST)" (scheduled at 2025-01-14 19:01:48.975517+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 19:02:08 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 108, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 38, in load
    driver.get(url) # url 접속
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: disconnected: not connected to DevTools
  (failed to check if window was closed: disconnected: not connected to DevTools)
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x007BFD53+23747]
	(No symbol) [0x00747D54]
	(No symbol) [0x0061BE53]
	(No symbol) [0x0060C408]
	(No symbol) [0x0060C329]
	(No symbol) [0x0061E2E0]
	(No symbol) [0x0069AD69]
	(No symbol) [0x00681B96]
	(No symbol) [0x00653F3C]
	(No symbol) [0x00654EBD]
	GetHandleVerifier [0x00A9AC73+3017699]
	GetHandleVerifier [0x00AAB93B+3086507]
	GetHandleVerifier [0x00AA40F2+3055714]
	GetHandleVerifier [0x00855AF0+637536]
	(No symbol) [0x00750A5D]
	(No symbol) [0x0074DA28]
	(No symbol) [0x0074DBC5]
	(No symbol) [0x007407F0]
	BaseThreadInitThunk [0x754CFCC9+25]
	RtlGetAppContainerNamedObjectPath [0x76F4809E+286]
	RtlGetAppContainerNamedObjectPath [0x76F4806E+238]

INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 19:01:49 KST)" (scheduled at 2025-01-14 19:01:49.436942+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 19:02:09 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 108, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 38, in load
    driver.get(url) # url 접속
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchWindowException: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x007BFD53+23747]
	(No symbol) [0x00747D54]
	(No symbol) [0x0061BE53]
	(No symbol) [0x005FD91B]
	(No symbol) [0x00687EFF]
	(No symbol) [0x0069AD49]
	(No symbol) [0x00681B96]
	(No symbol) [0x00653F3C]
	(No symbol) [0x00654EBD]
	GetHandleVerifier [0x00A9AC73+3017699]
	GetHandleVerifier [0x00AAB93B+3086507]
	GetHandleVerifier [0x00AA40F2+3055714]
	GetHandleVerifier [0x00855AF0+637536]
	(No symbol) [0x00750A5D]
	(No symbol) [0x0074DA28]
	(No symbol) [0x0074DBC5]
	(No symbol) [0x007407F0]
	BaseThreadInitThunk [0x754CFCC9+25]
	RtlGetAppContainerNamedObjectPath [0x76F4809E+286]
	RtlGetAppContainerNamedObjectPath [0x76F4806E+238]

INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 19:01:49 KST)" (scheduled at 2025-01-14 19:01:49.529942+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 19:02:09 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 108, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 38, in load
    driver.get(url) # url 접속
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchWindowException: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x007BFD53+23747]
	(No symbol) [0x00747D54]
	(No symbol) [0x0061BE53]
	(No symbol) [0x005FD91B]
	(No symbol) [0x00687EFF]
	(No symbol) [0x0069AD49]
	(No symbol) [0x00681B96]
	(No symbol) [0x00653F3C]
	(No symbol) [0x00654EBD]
	GetHandleVerifier [0x00A9AC73+3017699]
	GetHandleVerifier [0x00AAB93B+3086507]
	GetHandleVerifier [0x00AA40F2+3055714]
	GetHandleVerifier [0x00855AF0+637536]
	(No symbol) [0x00750A5D]
	(No symbol) [0x0074DA28]
	(No symbol) [0x0074DBC5]
	(No symbol) [0x007407F0]
	BaseThreadInitThunk [0x754CFCC9+25]
	RtlGetAppContainerNamedObjectPath [0x76F4809E+286]
	RtlGetAppContainerNamedObjectPath [0x76F4806E+238]

INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 19:02:10 KST)" (scheduled at 2025-01-14 19:01:50.966502+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 19:02:10 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 108, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 38, in load
    driver.get(url) # url 접속
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: disconnected: not connected to DevTools
  (failed to check if window was closed: disconnected: not connected to DevTools)
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x007BFD53+23747]
	(No symbol) [0x00747D54]
	(No symbol) [0x0061BE53]
	(No symbol) [0x0060C408]
	(No symbol) [0x0060C329]
	(No symbol) [0x0061E2E0]
	(No symbol) [0x0069AD69]
	(No symbol) [0x00681B96]
	(No symbol) [0x00653F3C]
	(No symbol) [0x00654EBD]
	GetHandleVerifier [0x00A9AC73+3017699]
	GetHandleVerifier [0x00AAB93B+3086507]
	GetHandleVerifier [0x00AA40F2+3055714]
	GetHandleVerifier [0x00855AF0+637536]
	(No symbol) [0x00750A5D]
	(No symbol) [0x0074DA28]
	(No symbol) [0x0074DBC5]
	(No symbol) [0x007407F0]
	BaseThreadInitThunk [0x754CFCC9+25]
	RtlGetAppContainerNamedObjectPath [0x76F4809E+286]
	RtlGetAppContainerNamedObjectPath [0x76F4806E+238]

INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 19:02:28 KST)" (scheduled at 2025-01-14 19:02:08.975517+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 19:02:28 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 108, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 38, in load
    driver.get(url) # url 접속
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: disconnected: not connected to DevTools
  (failed to check if window was closed: disconnected: not connected to DevTools)
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x007BFD53+23747]
	(No symbol) [0x00747D54]
	(No symbol) [0x0061BE53]
	(No symbol) [0x0060C408]
	(No symbol) [0x0060C329]
	(No symbol) [0x0061E2E0]
	(No symbol) [0x0069AD69]
	(No symbol) [0x00681B96]
	(No symbol) [0x00653F3C]
	(No symbol) [0x00654EBD]
	GetHandleVerifier [0x00A9AC73+3017699]
	GetHandleVerifier [0x00AAB93B+3086507]
	GetHandleVerifier [0x00AA40F2+3055714]
	GetHandleVerifier [0x00855AF0+637536]
	(No symbol) [0x00750A5D]
	(No symbol) [0x0074DA28]
	(No symbol) [0x0074DBC5]
	(No symbol) [0x007407F0]
	BaseThreadInitThunk [0x754CFCC9+25]
	RtlGetAppContainerNamedObjectPath [0x76F4809E+286]
	RtlGetAppContainerNamedObjectPath [0x76F4806E+238]

INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 19:02:29 KST)" (scheduled at 2025-01-14 19:02:09.436942+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 19:02:29 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 108, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 38, in load
    driver.get(url) # url 접속
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchWindowException: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x007BFD53+23747]
	(No symbol) [0x00747D54]
	(No symbol) [0x0061BE53]
	(No symbol) [0x005FD91B]
	(No symbol) [0x00687EFF]
	(No symbol) [0x0069AD49]
	(No symbol) [0x00681B96]
	(No symbol) [0x00653F3C]
	(No symbol) [0x00654EBD]
	GetHandleVerifier [0x00A9AC73+3017699]
	GetHandleVerifier [0x00AAB93B+3086507]
	GetHandleVerifier [0x00AA40F2+3055714]
	GetHandleVerifier [0x00855AF0+637536]
	(No symbol) [0x00750A5D]
	(No symbol) [0x0074DA28]
	(No symbol) [0x0074DBC5]
	(No symbol) [0x007407F0]
	BaseThreadInitThunk [0x754CFCC9+25]
	RtlGetAppContainerNamedObjectPath [0x76F4809E+286]
	RtlGetAppContainerNamedObjectPath [0x76F4806E+238]

INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 19:02:29 KST)" (scheduled at 2025-01-14 19:02:09.529942+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 19:02:29 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 108, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 38, in load
    driver.get(url) # url 접속
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchWindowException: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x007BFD53+23747]
	(No symbol) [0x00747D54]
	(No symbol) [0x0061BE53]
	(No symbol) [0x005FD91B]
	(No symbol) [0x00687EFF]
	(No symbol) [0x0069AD49]
	(No symbol) [0x00681B96]
	(No symbol) [0x00653F3C]
	(No symbol) [0x00654EBD]
	GetHandleVerifier [0x00A9AC73+3017699]
	GetHandleVerifier [0x00AAB93B+3086507]
	GetHandleVerifier [0x00AA40F2+3055714]
	GetHandleVerifier [0x00855AF0+637536]
	(No symbol) [0x00750A5D]
	(No symbol) [0x0074DA28]
	(No symbol) [0x0074DBC5]
	(No symbol) [0x007407F0]
	BaseThreadInitThunk [0x754CFCC9+25]
	RtlGetAppContainerNamedObjectPath [0x76F4809E+286]
	RtlGetAppContainerNamedObjectPath [0x76F4806E+238]

INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 19:02:30 KST)" (scheduled at 2025-01-14 19:02:10.966502+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 19:02:30 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 108, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 38, in load
    driver.get(url) # url 접속
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: disconnected: not connected to DevTools
  (failed to check if window was closed: disconnected: not connected to DevTools)
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x007BFD53+23747]
	(No symbol) [0x00747D54]
	(No symbol) [0x0061BE53]
	(No symbol) [0x0060C408]
	(No symbol) [0x0060C329]
	(No symbol) [0x0061E2E0]
	(No symbol) [0x0069AD69]
	(No symbol) [0x00681B96]
	(No symbol) [0x00653F3C]
	(No symbol) [0x00654EBD]
	GetHandleVerifier [0x00A9AC73+3017699]
	GetHandleVerifier [0x00AAB93B+3086507]
	GetHandleVerifier [0x00AA40F2+3055714]
	GetHandleVerifier [0x00855AF0+637536]
	(No symbol) [0x00750A5D]
	(No symbol) [0x0074DA28]
	(No symbol) [0x0074DBC5]
	(No symbol) [0x007407F0]
	BaseThreadInitThunk [0x754CFCC9+25]
	RtlGetAppContainerNamedObjectPath [0x76F4809E+286]
	RtlGetAppContainerNamedObjectPath [0x76F4806E+238]

INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 19:02:48 KST)" (scheduled at 2025-01-14 19:02:28.975517+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 19:02:48 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 108, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 38, in load
    driver.get(url) # url 접속
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: disconnected: not connected to DevTools
  (failed to check if window was closed: disconnected: not connected to DevTools)
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x007BFD53+23747]
	(No symbol) [0x00747D54]
	(No symbol) [0x0061BE53]
	(No symbol) [0x0060C408]
	(No symbol) [0x0060C329]
	(No symbol) [0x0061E2E0]
	(No symbol) [0x0069AD69]
	(No symbol) [0x00681B96]
	(No symbol) [0x00653F3C]
	(No symbol) [0x00654EBD]
	GetHandleVerifier [0x00A9AC73+3017699]
	GetHandleVerifier [0x00AAB93B+3086507]
	GetHandleVerifier [0x00AA40F2+3055714]
	GetHandleVerifier [0x00855AF0+637536]
	(No symbol) [0x00750A5D]
	(No symbol) [0x0074DA28]
	(No symbol) [0x0074DBC5]
	(No symbol) [0x007407F0]
	BaseThreadInitThunk [0x754CFCC9+25]
	RtlGetAppContainerNamedObjectPath [0x76F4809E+286]
	RtlGetAppContainerNamedObjectPath [0x76F4806E+238]

INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 19:02:49 KST)" (scheduled at 2025-01-14 19:02:29.436942+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 19:02:49 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 108, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 38, in load
    driver.get(url) # url 접속
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchWindowException: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x007BFD53+23747]
	(No symbol) [0x00747D54]
	(No symbol) [0x0061BE53]
	(No symbol) [0x005FD91B]
	(No symbol) [0x00687EFF]
	(No symbol) [0x0069AD49]
	(No symbol) [0x00681B96]
	(No symbol) [0x00653F3C]
	(No symbol) [0x00654EBD]
	GetHandleVerifier [0x00A9AC73+3017699]
	GetHandleVerifier [0x00AAB93B+3086507]
	GetHandleVerifier [0x00AA40F2+3055714]
	GetHandleVerifier [0x00855AF0+637536]
	(No symbol) [0x00750A5D]
	(No symbol) [0x0074DA28]
	(No symbol) [0x0074DBC5]
	(No symbol) [0x007407F0]
	BaseThreadInitThunk [0x754CFCC9+25]
	RtlGetAppContainerNamedObjectPath [0x76F4809E+286]
	RtlGetAppContainerNamedObjectPath [0x76F4806E+238]

INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 19:02:49 KST)" (scheduled at 2025-01-14 19:02:29.529942+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 19:02:49 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 108, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 38, in load
    driver.get(url) # url 접속
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchWindowException: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x007BFD53+23747]
	(No symbol) [0x00747D54]
	(No symbol) [0x0061BE53]
	(No symbol) [0x005FD91B]
	(No symbol) [0x00687EFF]
	(No symbol) [0x0069AD49]
	(No symbol) [0x00681B96]
	(No symbol) [0x00653F3C]
	(No symbol) [0x00654EBD]
	GetHandleVerifier [0x00A9AC73+3017699]
	GetHandleVerifier [0x00AAB93B+3086507]
	GetHandleVerifier [0x00AA40F2+3055714]
	GetHandleVerifier [0x00855AF0+637536]
	(No symbol) [0x00750A5D]
	(No symbol) [0x0074DA28]
	(No symbol) [0x0074DBC5]
	(No symbol) [0x007407F0]
	BaseThreadInitThunk [0x754CFCC9+25]
	RtlGetAppContainerNamedObjectPath [0x76F4809E+286]
	RtlGetAppContainerNamedObjectPath [0x76F4806E+238]

INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 19:02:50 KST)" (scheduled at 2025-01-14 19:02:30.966502+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 19:02:50 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 108, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 38, in load
    driver.get(url) # url 접속
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: disconnected: not connected to DevTools
  (failed to check if window was closed: disconnected: not connected to DevTools)
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x007BFD53+23747]
	(No symbol) [0x00747D54]
	(No symbol) [0x0061BE53]
	(No symbol) [0x0060C408]
	(No symbol) [0x0060C329]
	(No symbol) [0x0061E2E0]
	(No symbol) [0x0069AD69]
	(No symbol) [0x00681B96]
	(No symbol) [0x00653F3C]
	(No symbol) [0x00654EBD]
	GetHandleVerifier [0x00A9AC73+3017699]
	GetHandleVerifier [0x00AAB93B+3086507]
	GetHandleVerifier [0x00AA40F2+3055714]
	GetHandleVerifier [0x00855AF0+637536]
	(No symbol) [0x00750A5D]
	(No symbol) [0x0074DA28]
	(No symbol) [0x0074DBC5]
	(No symbol) [0x007407F0]
	BaseThreadInitThunk [0x754CFCC9+25]
	RtlGetAppContainerNamedObjectPath [0x76F4809E+286]
	RtlGetAppContainerNamedObjectPath [0x76F4806E+238]

INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 19:03:08 KST)" (scheduled at 2025-01-14 19:02:48.975517+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 19:03:08 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 108, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 38, in load
    driver.get(url) # url 접속
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: disconnected: not connected to DevTools
  (failed to check if window was closed: disconnected: not connected to DevTools)
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x007BFD53+23747]
	(No symbol) [0x00747D54]
	(No symbol) [0x0061BE53]
	(No symbol) [0x0060C408]
	(No symbol) [0x0060C329]
	(No symbol) [0x0061E2E0]
	(No symbol) [0x0069AD69]
	(No symbol) [0x00681B96]
	(No symbol) [0x00653F3C]
	(No symbol) [0x00654EBD]
	GetHandleVerifier [0x00A9AC73+3017699]
	GetHandleVerifier [0x00AAB93B+3086507]
	GetHandleVerifier [0x00AA40F2+3055714]
	GetHandleVerifier [0x00855AF0+637536]
	(No symbol) [0x00750A5D]
	(No symbol) [0x0074DA28]
	(No symbol) [0x0074DBC5]
	(No symbol) [0x007407F0]
	BaseThreadInitThunk [0x754CFCC9+25]
	RtlGetAppContainerNamedObjectPath [0x76F4809E+286]
	RtlGetAppContainerNamedObjectPath [0x76F4806E+238]

INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 19:03:09 KST)" (scheduled at 2025-01-14 19:02:49.436942+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 19:03:09 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 108, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 38, in load
    driver.get(url) # url 접속
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchWindowException: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x007BFD53+23747]
	(No symbol) [0x00747D54]
	(No symbol) [0x0061BE53]
	(No symbol) [0x005FD91B]
	(No symbol) [0x00687EFF]
	(No symbol) [0x0069AD49]
	(No symbol) [0x00681B96]
	(No symbol) [0x00653F3C]
	(No symbol) [0x00654EBD]
	GetHandleVerifier [0x00A9AC73+3017699]
	GetHandleVerifier [0x00AAB93B+3086507]
	GetHandleVerifier [0x00AA40F2+3055714]
	GetHandleVerifier [0x00855AF0+637536]
	(No symbol) [0x00750A5D]
	(No symbol) [0x0074DA28]
	(No symbol) [0x0074DBC5]
	(No symbol) [0x007407F0]
	BaseThreadInitThunk [0x754CFCC9+25]
	RtlGetAppContainerNamedObjectPath [0x76F4809E+286]
	RtlGetAppContainerNamedObjectPath [0x76F4806E+238]

INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 19:03:09 KST)" (scheduled at 2025-01-14 19:02:49.529942+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 19:03:09 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 108, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 38, in load
    driver.get(url) # url 접속
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchWindowException: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x007BFD53+23747]
	(No symbol) [0x00747D54]
	(No symbol) [0x0061BE53]
	(No symbol) [0x005FD91B]
	(No symbol) [0x00687EFF]
	(No symbol) [0x0069AD49]
	(No symbol) [0x00681B96]
	(No symbol) [0x00653F3C]
	(No symbol) [0x00654EBD]
	GetHandleVerifier [0x00A9AC73+3017699]
	GetHandleVerifier [0x00AAB93B+3086507]
	GetHandleVerifier [0x00AA40F2+3055714]
	GetHandleVerifier [0x00855AF0+637536]
	(No symbol) [0x00750A5D]
	(No symbol) [0x0074DA28]
	(No symbol) [0x0074DBC5]
	(No symbol) [0x007407F0]
	BaseThreadInitThunk [0x754CFCC9+25]
	RtlGetAppContainerNamedObjectPath [0x76F4809E+286]
	RtlGetAppContainerNamedObjectPath [0x76F4806E+238]

INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 19:03:10 KST)" (scheduled at 2025-01-14 19:02:50.966502+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 19:03:10 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 108, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 38, in load
    driver.get(url) # url 접속
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: disconnected: not connected to DevTools
  (failed to check if window was closed: disconnected: not connected to DevTools)
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x007BFD53+23747]
	(No symbol) [0x00747D54]
	(No symbol) [0x0061BE53]
	(No symbol) [0x0060C408]
	(No symbol) [0x0060C329]
	(No symbol) [0x0061E2E0]
	(No symbol) [0x0069AD69]
	(No symbol) [0x00681B96]
	(No symbol) [0x00653F3C]
	(No symbol) [0x00654EBD]
	GetHandleVerifier [0x00A9AC73+3017699]
	GetHandleVerifier [0x00AAB93B+3086507]
	GetHandleVerifier [0x00AA40F2+3055714]
	GetHandleVerifier [0x00855AF0+637536]
	(No symbol) [0x00750A5D]
	(No symbol) [0x0074DA28]
	(No symbol) [0x0074DBC5]
	(No symbol) [0x007407F0]
	BaseThreadInitThunk [0x754CFCC9+25]
	RtlGetAppContainerNamedObjectPath [0x76F4809E+286]
	RtlGetAppContainerNamedObjectPath [0x76F4806E+238]

INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 19:03:28 KST)" (scheduled at 2025-01-14 19:03:08.975517+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 19:03:28 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 108, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 38, in load
    driver.get(url) # url 접속
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: disconnected: not connected to DevTools
  (failed to check if window was closed: disconnected: not connected to DevTools)
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x007BFD53+23747]
	(No symbol) [0x00747D54]
	(No symbol) [0x0061BE53]
	(No symbol) [0x0060C408]
	(No symbol) [0x0060C329]
	(No symbol) [0x0061E2E0]
	(No symbol) [0x0069AD69]
	(No symbol) [0x00681B96]
	(No symbol) [0x00653F3C]
	(No symbol) [0x00654EBD]
	GetHandleVerifier [0x00A9AC73+3017699]
	GetHandleVerifier [0x00AAB93B+3086507]
	GetHandleVerifier [0x00AA40F2+3055714]
	GetHandleVerifier [0x00855AF0+637536]
	(No symbol) [0x00750A5D]
	(No symbol) [0x0074DA28]
	(No symbol) [0x0074DBC5]
	(No symbol) [0x007407F0]
	BaseThreadInitThunk [0x754CFCC9+25]
	RtlGetAppContainerNamedObjectPath [0x76F4809E+286]
	RtlGetAppContainerNamedObjectPath [0x76F4806E+238]

INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 19:03:29 KST)" (scheduled at 2025-01-14 19:03:09.436942+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 19:03:29 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 108, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 38, in load
    driver.get(url) # url 접속
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchWindowException: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x007BFD53+23747]
	(No symbol) [0x00747D54]
	(No symbol) [0x0061BE53]
	(No symbol) [0x005FD91B]
	(No symbol) [0x00687EFF]
	(No symbol) [0x0069AD49]
	(No symbol) [0x00681B96]
	(No symbol) [0x00653F3C]
	(No symbol) [0x00654EBD]
	GetHandleVerifier [0x00A9AC73+3017699]
	GetHandleVerifier [0x00AAB93B+3086507]
	GetHandleVerifier [0x00AA40F2+3055714]
	GetHandleVerifier [0x00855AF0+637536]
	(No symbol) [0x00750A5D]
	(No symbol) [0x0074DA28]
	(No symbol) [0x0074DBC5]
	(No symbol) [0x007407F0]
	BaseThreadInitThunk [0x754CFCC9+25]
	RtlGetAppContainerNamedObjectPath [0x76F4809E+286]
	RtlGetAppContainerNamedObjectPath [0x76F4806E+238]

INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 19:03:29 KST)" (scheduled at 2025-01-14 19:03:09.529942+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 19:03:29 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 108, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 38, in load
    driver.get(url) # url 접속
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchWindowException: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x007BFD53+23747]
	(No symbol) [0x00747D54]
	(No symbol) [0x0061BE53]
	(No symbol) [0x005FD91B]
	(No symbol) [0x00687EFF]
	(No symbol) [0x0069AD49]
	(No symbol) [0x00681B96]
	(No symbol) [0x00653F3C]
	(No symbol) [0x00654EBD]
	GetHandleVerifier [0x00A9AC73+3017699]
	GetHandleVerifier [0x00AAB93B+3086507]
	GetHandleVerifier [0x00AA40F2+3055714]
	GetHandleVerifier [0x00855AF0+637536]
	(No symbol) [0x00750A5D]
	(No symbol) [0x0074DA28]
	(No symbol) [0x0074DBC5]
	(No symbol) [0x007407F0]
	BaseThreadInitThunk [0x754CFCC9+25]
	RtlGetAppContainerNamedObjectPath [0x76F4809E+286]
	RtlGetAppContainerNamedObjectPath [0x76F4806E+238]

INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 19:03:30 KST)" (scheduled at 2025-01-14 19:03:10.966502+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 19:03:30 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 108, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 38, in load
    driver.get(url) # url 접속
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: disconnected: not connected to DevTools
  (failed to check if window was closed: disconnected: not connected to DevTools)
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x007BFD53+23747]
	(No symbol) [0x00747D54]
	(No symbol) [0x0061BE53]
	(No symbol) [0x0060C408]
	(No symbol) [0x0060C329]
	(No symbol) [0x0061E2E0]
	(No symbol) [0x0069AD69]
	(No symbol) [0x00681B96]
	(No symbol) [0x00653F3C]
	(No symbol) [0x00654EBD]
	GetHandleVerifier [0x00A9AC73+3017699]
	GetHandleVerifier [0x00AAB93B+3086507]
	GetHandleVerifier [0x00AA40F2+3055714]
	GetHandleVerifier [0x00855AF0+637536]
	(No symbol) [0x00750A5D]
	(No symbol) [0x0074DA28]
	(No symbol) [0x0074DBC5]
	(No symbol) [0x007407F0]
	BaseThreadInitThunk [0x754CFCC9+25]
	RtlGetAppContainerNamedObjectPath [0x76F4809E+286]
	RtlGetAppContainerNamedObjectPath [0x76F4806E+238]

INFO:werkzeug: * Detected change in 'C:\\kd\\ws_java\\team4_v2sbm3c\\src\\main\\python\\exc.py', reloading
INFO:werkzeug: * Detected change in 'C:\\kd\\ws_java\\team4_v2sbm3c\\src\\main\\python\\exc.py', reloading
INFO:werkzeug: * Detected change in 'C:\\kd\\ws_java\\team4_v2sbm3c\\src\\main\\python\\exc.py', reloading
INFO:werkzeug: * Detected change in 'C:\\kd\\ws_java\\team4_v2sbm3c\\src\\main\\python\\exc.py', reloading
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
INFO:WDM:====== WebDriver manager ======
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 19:03:48 KST)" (scheduled at 2025-01-14 19:03:28.975517+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 19:03:48 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 108, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 38, in load
    driver.get(url) # url 접속
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: disconnected: not connected to DevTools
  (failed to check if window was closed: disconnected: not connected to DevTools)
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x007BFD53+23747]
	(No symbol) [0x00747D54]
	(No symbol) [0x0061BE53]
	(No symbol) [0x0060C408]
	(No symbol) [0x0060C329]
	(No symbol) [0x0061E2E0]
	(No symbol) [0x0069AD69]
	(No symbol) [0x00681B96]
	(No symbol) [0x00653F3C]
	(No symbol) [0x00654EBD]
	GetHandleVerifier [0x00A9AC73+3017699]
	GetHandleVerifier [0x00AAB93B+3086507]
	GetHandleVerifier [0x00AA40F2+3055714]
	GetHandleVerifier [0x00855AF0+637536]
	(No symbol) [0x00750A5D]
	(No symbol) [0x0074DA28]
	(No symbol) [0x0074DBC5]
	(No symbol) [0x007407F0]
	BaseThreadInitThunk [0x754CFCC9+25]
	RtlGetAppContainerNamedObjectPath [0x76F4809E+286]
	RtlGetAppContainerNamedObjectPath [0x76F4806E+238]

INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\i\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\i\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 19:03:50 KST)" (scheduled at 2025-01-14 19:03:30.966502+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 19:03:50 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 108, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 38, in load
    driver.get(url) # url 접속
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: disconnected: not connected to DevTools
  (failed to check if window was closed: disconnected: not connected to DevTools)
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x007BFD53+23747]
	(No symbol) [0x00747D54]
	(No symbol) [0x0061BE53]
	(No symbol) [0x0060C408]
	(No symbol) [0x0060C329]
	(No symbol) [0x0061E2E0]
	(No symbol) [0x0069AD69]
	(No symbol) [0x00681B96]
	(No symbol) [0x00653F3C]
	(No symbol) [0x00654EBD]
	GetHandleVerifier [0x00A9AC73+3017699]
	GetHandleVerifier [0x00AAB93B+3086507]
	GetHandleVerifier [0x00AA40F2+3055714]
	GetHandleVerifier [0x00855AF0+637536]
	(No symbol) [0x00750A5D]
	(No symbol) [0x0074DA28]
	(No symbol) [0x0074DBC5]
	(No symbol) [0x007407F0]
	BaseThreadInitThunk [0x754CFCC9+25]
	RtlGetAppContainerNamedObjectPath [0x76F4809E+286]
	RtlGetAppContainerNamedObjectPath [0x76F4806E+238]

INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawl_and_insert_data" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 569-178-434
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawl_and_insert_data" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 569-178-434
INFO:werkzeug: * Detected change in 'C:\\kd\\ws_java\\team4_v2sbm3c\\src\\main\\python\\exc.py', reloading
INFO:werkzeug: * Detected change in 'C:\\kd\\ws_java\\team4_v2sbm3c\\src\\main\\python\\exc.py', reloading
INFO:werkzeug: * Detected change in 'C:\\kd\\ws_java\\team4_v2sbm3c\\src\\main\\python\\exc.py', reloading
INFO:werkzeug: * Detected change in 'C:\\kd\\ws_java\\team4_v2sbm3c\\src\\main\\python\\exc.py', reloading
INFO:werkzeug: * Detected change in 'C:\\kd\\ws_java\\team4_v2sbm3c\\src\\main\\python\\exc.py', reloading
INFO:werkzeug: * Detected change in 'C:\\kd\\ws_java\\team4_v2sbm3c\\src\\main\\python\\exc.py', reloading
INFO:werkzeug: * Detected change in 'C:\\kd\\ws_java\\team4_v2sbm3c\\src\\main\\python\\exc.py', reloading
INFO:werkzeug: * Detected change in 'C:\\kd\\ws_java\\team4_v2sbm3c\\src\\main\\python\\exc.py', reloading
INFO:werkzeug: * Detected change in 'C:\\kd\\ws_java\\team4_v2sbm3c\\src\\main\\python\\exc.py', reloading
INFO:werkzeug: * Detected change in 'C:\\kd\\ws_java\\team4_v2sbm3c\\src\\main\\python\\exc.py', reloading
INFO:werkzeug: * Detected change in 'C:\\kd\\ws_java\\team4_v2sbm3c\\src\\main\\python\\exc.py', reloading
INFO:werkzeug: * Detected change in 'C:\\kd\\ws_java\\team4_v2sbm3c\\src\\main\\python\\exc.py', reloading
INFO:werkzeug: * Detected change in 'C:\\kd\\ws_java\\team4_v2sbm3c\\src\\main\\python\\exc.py', reloading
INFO:werkzeug: * Detected change in 'C:\\kd\\ws_java\\team4_v2sbm3c\\src\\main\\python\\exc.py', reloading
INFO:werkzeug: * Detected change in 'C:\\kd\\ws_java\\team4_v2sbm3c\\src\\main\\python\\exc.py', reloading
INFO:werkzeug: * Detected change in 'C:\\kd\\ws_java\\team4_v2sbm3c\\src\\main\\python\\exc.py', reloading
INFO:werkzeug: * Detected change in 'C:\\kd\\ws_java\\team4_v2sbm3c\\src\\main\\python\\exc.py', reloading
INFO:werkzeug: * Detected change in 'C:\\kd\\ws_java\\team4_v2sbm3c\\src\\main\\python\\exc.py', reloading
INFO:werkzeug: * Detected change in 'C:\\kd\\ws_java\\team4_v2sbm3c\\src\\main\\python\\exc.py', reloading
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\i\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\i\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawl_and_insert_data" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 569-178-434
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawl_and_insert_data" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 569-178-434
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 19:04:08 KST)" (scheduled at 2025-01-14 19:03:48.975517+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 19:04:08 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 108, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 38, in load
    driver.get(url) # url 접속
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: disconnected: not connected to DevTools
  (failed to check if window was closed: disconnected: not connected to DevTools)
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x007BFD53+23747]
	(No symbol) [0x00747D54]
	(No symbol) [0x0061BE53]
	(No symbol) [0x0060C408]
	(No symbol) [0x0060C329]
	(No symbol) [0x0061E2E0]
	(No symbol) [0x0069AD69]
	(No symbol) [0x00681B96]
	(No symbol) [0x00653F3C]
	(No symbol) [0x00654EBD]
	GetHandleVerifier [0x00A9AC73+3017699]
	GetHandleVerifier [0x00AAB93B+3086507]
	GetHandleVerifier [0x00AA40F2+3055714]
	GetHandleVerifier [0x00855AF0+637536]
	(No symbol) [0x00750A5D]
	(No symbol) [0x0074DA28]
	(No symbol) [0x0074DBC5]
	(No symbol) [0x007407F0]
	BaseThreadInitThunk [0x754CFCC9+25]
	RtlGetAppContainerNamedObjectPath [0x76F4809E+286]
	RtlGetAppContainerNamedObjectPath [0x76F4806E+238]

INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 19:04:10 KST)" (scheduled at 2025-01-14 19:03:50.966502+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 19:04:10 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 108, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 38, in load
    driver.get(url) # url 접속
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: disconnected: not connected to DevTools
  (failed to check if window was closed: disconnected: not connected to DevTools)
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x007BFD53+23747]
	(No symbol) [0x00747D54]
	(No symbol) [0x0061BE53]
	(No symbol) [0x0060C408]
	(No symbol) [0x0060C329]
	(No symbol) [0x0061E2E0]
	(No symbol) [0x0069AD69]
	(No symbol) [0x00681B96]
	(No symbol) [0x00653F3C]
	(No symbol) [0x00654EBD]
	GetHandleVerifier [0x00A9AC73+3017699]
	GetHandleVerifier [0x00AAB93B+3086507]
	GetHandleVerifier [0x00AA40F2+3055714]
	GetHandleVerifier [0x00855AF0+637536]
	(No symbol) [0x00750A5D]
	(No symbol) [0x0074DA28]
	(No symbol) [0x0074DBC5]
	(No symbol) [0x007407F0]
	BaseThreadInitThunk [0x754CFCC9+25]
	RtlGetAppContainerNamedObjectPath [0x76F4809E+286]
	RtlGetAppContainerNamedObjectPath [0x76F4806E+238]

INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 19:04:07 KST)" (scheduled at 2025-01-14 19:04:07.617254+09:00)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 19:04:07 KST)" (scheduled at 2025-01-14 19:04:07.804253+09:00)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 19:04:28 KST)" (scheduled at 2025-01-14 19:04:08.975517+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 19:04:28 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 108, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 38, in load
    driver.get(url) # url 접속
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: disconnected: not connected to DevTools
  (failed to check if window was closed: disconnected: not connected to DevTools)
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x007BFD53+23747]
	(No symbol) [0x00747D54]
	(No symbol) [0x0061BE53]
	(No symbol) [0x0060C408]
	(No symbol) [0x0060C329]
	(No symbol) [0x0061E2E0]
	(No symbol) [0x0069AD69]
	(No symbol) [0x00681B96]
	(No symbol) [0x00653F3C]
	(No symbol) [0x00654EBD]
	GetHandleVerifier [0x00A9AC73+3017699]
	GetHandleVerifier [0x00AAB93B+3086507]
	GetHandleVerifier [0x00AA40F2+3055714]
	GetHandleVerifier [0x00855AF0+637536]
	(No symbol) [0x00750A5D]
	(No symbol) [0x0074DA28]
	(No symbol) [0x0074DBC5]
	(No symbol) [0x007407F0]
	BaseThreadInitThunk [0x754CFCC9+25]
	RtlGetAppContainerNamedObjectPath [0x76F4809E+286]
	RtlGetAppContainerNamedObjectPath [0x76F4806E+238]

INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 19:04:30 KST)" (scheduled at 2025-01-14 19:04:10.966502+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 19:04:30 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 108, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 38, in load
    driver.get(url) # url 접속
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: disconnected: not connected to DevTools
  (failed to check if window was closed: disconnected: not connected to DevTools)
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x007BFD53+23747]
	(No symbol) [0x00747D54]
	(No symbol) [0x0061BE53]
	(No symbol) [0x0060C408]
	(No symbol) [0x0060C329]
	(No symbol) [0x0061E2E0]
	(No symbol) [0x0069AD69]
	(No symbol) [0x00681B96]
	(No symbol) [0x00653F3C]
	(No symbol) [0x00654EBD]
	GetHandleVerifier [0x00A9AC73+3017699]
	GetHandleVerifier [0x00AAB93B+3086507]
	GetHandleVerifier [0x00AA40F2+3055714]
	GetHandleVerifier [0x00855AF0+637536]
	(No symbol) [0x00750A5D]
	(No symbol) [0x0074DA28]
	(No symbol) [0x0074DBC5]
	(No symbol) [0x007407F0]
	BaseThreadInitThunk [0x754CFCC9+25]
	RtlGetAppContainerNamedObjectPath [0x76F4809E+286]
	RtlGetAppContainerNamedObjectPath [0x76F4806E+238]

ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 19:04:27 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 129, in crawl_and_insert_data
    url = driver.current_url
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 437, in current_url
    return self.execute(Command.GET_CURRENT_URL)["value"]
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchWindowException: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x007BFD53+23747]
	(No symbol) [0x00747D54]
	(No symbol) [0x0061BE53]
	(No symbol) [0x005FD91B]
	(No symbol) [0x00687EFF]
	(No symbol) [0x0069AD49]
	(No symbol) [0x00681B96]
	(No symbol) [0x00653F3C]
	(No symbol) [0x00654EBD]
	GetHandleVerifier [0x00A9AC73+3017699]
	GetHandleVerifier [0x00AAB93B+3086507]
	GetHandleVerifier [0x00AA40F2+3055714]
	GetHandleVerifier [0x00855AF0+637536]
	(No symbol) [0x00750A5D]
	(No symbol) [0x0074DA28]
	(No symbol) [0x0074DBC5]
	(No symbol) [0x007407F0]
	BaseThreadInitThunk [0x754CFCC9+25]
	RtlGetAppContainerNamedObjectPath [0x76F4809E+286]
	RtlGetAppContainerNamedObjectPath [0x76F4806E+238]

ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 19:04:27 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 222, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2014' in position 80: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 19:04:47 KST)" (scheduled at 2025-01-14 19:04:27.617254+09:00)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 19:04:47 KST)" (scheduled at 2025-01-14 19:04:27.804253+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 19:04:47 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 108, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 38, in load
    driver.get(url) # url 접속
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchWindowException: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x007BFD53+23747]
	(No symbol) [0x00747D54]
	(No symbol) [0x0061BE53]
	(No symbol) [0x005FD91B]
	(No symbol) [0x00687EFF]
	(No symbol) [0x0069AD49]
	(No symbol) [0x00681B96]
	(No symbol) [0x00653F3C]
	(No symbol) [0x00654EBD]
	GetHandleVerifier [0x00A9AC73+3017699]
	GetHandleVerifier [0x00AAB93B+3086507]
	GetHandleVerifier [0x00AA40F2+3055714]
	GetHandleVerifier [0x00855AF0+637536]
	(No symbol) [0x00750A5D]
	(No symbol) [0x0074DA28]
	(No symbol) [0x0074DBC5]
	(No symbol) [0x007407F0]
	BaseThreadInitThunk [0x754CFCC9+25]
	RtlGetAppContainerNamedObjectPath [0x76F4809E+286]
	RtlGetAppContainerNamedObjectPath [0x76F4806E+238]

INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 19:04:48 KST)" (scheduled at 2025-01-14 19:04:28.975517+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 19:04:48 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 108, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 38, in load
    driver.get(url) # url 접속
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: disconnected: not connected to DevTools
  (failed to check if window was closed: disconnected: not connected to DevTools)
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x007BFD53+23747]
	(No symbol) [0x00747D54]
	(No symbol) [0x0061BE53]
	(No symbol) [0x0060C408]
	(No symbol) [0x0060C329]
	(No symbol) [0x0061E2E0]
	(No symbol) [0x0069AD69]
	(No symbol) [0x00681B96]
	(No symbol) [0x00653F3C]
	(No symbol) [0x00654EBD]
	GetHandleVerifier [0x00A9AC73+3017699]
	GetHandleVerifier [0x00AAB93B+3086507]
	GetHandleVerifier [0x00AA40F2+3055714]
	GetHandleVerifier [0x00855AF0+637536]
	(No symbol) [0x00750A5D]
	(No symbol) [0x0074DA28]
	(No symbol) [0x0074DBC5]
	(No symbol) [0x007407F0]
	BaseThreadInitThunk [0x754CFCC9+25]
	RtlGetAppContainerNamedObjectPath [0x76F4809E+286]
	RtlGetAppContainerNamedObjectPath [0x76F4806E+238]

INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 19:04:50 KST)" (scheduled at 2025-01-14 19:04:30.966502+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 19:04:50 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 108, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 38, in load
    driver.get(url) # url 접속
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: disconnected: not connected to DevTools
  (failed to check if window was closed: disconnected: not connected to DevTools)
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x007BFD53+23747]
	(No symbol) [0x00747D54]
	(No symbol) [0x0061BE53]
	(No symbol) [0x0060C408]
	(No symbol) [0x0060C329]
	(No symbol) [0x0061E2E0]
	(No symbol) [0x0069AD69]
	(No symbol) [0x00681B96]
	(No symbol) [0x00653F3C]
	(No symbol) [0x00654EBD]
	GetHandleVerifier [0x00A9AC73+3017699]
	GetHandleVerifier [0x00AAB93B+3086507]
	GetHandleVerifier [0x00AA40F2+3055714]
	GetHandleVerifier [0x00855AF0+637536]
	(No symbol) [0x00750A5D]
	(No symbol) [0x0074DA28]
	(No symbol) [0x0074DBC5]
	(No symbol) [0x007407F0]
	BaseThreadInitThunk [0x754CFCC9+25]
	RtlGetAppContainerNamedObjectPath [0x76F4809E+286]
	RtlGetAppContainerNamedObjectPath [0x76F4806E+238]

ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 19:04:47 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 222, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2014' in position 80: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 19:05:07 KST)" (scheduled at 2025-01-14 19:04:47.617254+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 19:05:07 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 108, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 38, in load
    driver.get(url) # url 접속
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchWindowException: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x007BFD53+23747]
	(No symbol) [0x00747D54]
	(No symbol) [0x0061BE53]
	(No symbol) [0x005FD91B]
	(No symbol) [0x00687EFF]
	(No symbol) [0x0069AD49]
	(No symbol) [0x00681B96]
	(No symbol) [0x00653F3C]
	(No symbol) [0x00654EBD]
	GetHandleVerifier [0x00A9AC73+3017699]
	GetHandleVerifier [0x00AAB93B+3086507]
	GetHandleVerifier [0x00AA40F2+3055714]
	GetHandleVerifier [0x00855AF0+637536]
	(No symbol) [0x00750A5D]
	(No symbol) [0x0074DA28]
	(No symbol) [0x0074DBC5]
	(No symbol) [0x007407F0]
	BaseThreadInitThunk [0x754CFCC9+25]
	RtlGetAppContainerNamedObjectPath [0x76F4809E+286]
	RtlGetAppContainerNamedObjectPath [0x76F4806E+238]

INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 19:05:07 KST)" (scheduled at 2025-01-14 19:04:47.804253+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 19:05:07 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 108, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 38, in load
    driver.get(url) # url 접속
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchWindowException: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x007BFD53+23747]
	(No symbol) [0x00747D54]
	(No symbol) [0x0061BE53]
	(No symbol) [0x005FD91B]
	(No symbol) [0x00687EFF]
	(No symbol) [0x0069AD49]
	(No symbol) [0x00681B96]
	(No symbol) [0x00653F3C]
	(No symbol) [0x00654EBD]
	GetHandleVerifier [0x00A9AC73+3017699]
	GetHandleVerifier [0x00AAB93B+3086507]
	GetHandleVerifier [0x00AA40F2+3055714]
	GetHandleVerifier [0x00855AF0+637536]
	(No symbol) [0x00750A5D]
	(No symbol) [0x0074DA28]
	(No symbol) [0x0074DBC5]
	(No symbol) [0x007407F0]
	BaseThreadInitThunk [0x754CFCC9+25]
	RtlGetAppContainerNamedObjectPath [0x76F4809E+286]
	RtlGetAppContainerNamedObjectPath [0x76F4806E+238]

INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 19:05:08 KST)" (scheduled at 2025-01-14 19:04:48.975517+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 19:05:08 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 108, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 38, in load
    driver.get(url) # url 접속
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: disconnected: not connected to DevTools
  (failed to check if window was closed: disconnected: not connected to DevTools)
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x007BFD53+23747]
	(No symbol) [0x00747D54]
	(No symbol) [0x0061BE53]
	(No symbol) [0x0060C408]
	(No symbol) [0x0060C329]
	(No symbol) [0x0061E2E0]
	(No symbol) [0x0069AD69]
	(No symbol) [0x00681B96]
	(No symbol) [0x00653F3C]
	(No symbol) [0x00654EBD]
	GetHandleVerifier [0x00A9AC73+3017699]
	GetHandleVerifier [0x00AAB93B+3086507]
	GetHandleVerifier [0x00AA40F2+3055714]
	GetHandleVerifier [0x00855AF0+637536]
	(No symbol) [0x00750A5D]
	(No symbol) [0x0074DA28]
	(No symbol) [0x0074DBC5]
	(No symbol) [0x007407F0]
	BaseThreadInitThunk [0x754CFCC9+25]
	RtlGetAppContainerNamedObjectPath [0x76F4809E+286]
	RtlGetAppContainerNamedObjectPath [0x76F4806E+238]

INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 19:05:10 KST)" (scheduled at 2025-01-14 19:04:50.966502+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 19:05:10 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 108, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 38, in load
    driver.get(url) # url 접속
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: disconnected: not connected to DevTools
  (failed to check if window was closed: disconnected: not connected to DevTools)
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x007BFD53+23747]
	(No symbol) [0x00747D54]
	(No symbol) [0x0061BE53]
	(No symbol) [0x0060C408]
	(No symbol) [0x0060C329]
	(No symbol) [0x0061E2E0]
	(No symbol) [0x0069AD69]
	(No symbol) [0x00681B96]
	(No symbol) [0x00653F3C]
	(No symbol) [0x00654EBD]
	GetHandleVerifier [0x00A9AC73+3017699]
	GetHandleVerifier [0x00AAB93B+3086507]
	GetHandleVerifier [0x00AA40F2+3055714]
	GetHandleVerifier [0x00855AF0+637536]
	(No symbol) [0x00750A5D]
	(No symbol) [0x0074DA28]
	(No symbol) [0x0074DBC5]
	(No symbol) [0x007407F0]
	BaseThreadInitThunk [0x754CFCC9+25]
	RtlGetAppContainerNamedObjectPath [0x76F4809E+286]
	RtlGetAppContainerNamedObjectPath [0x76F4806E+238]

INFO:werkzeug: * Detected change in 'C:\\kd\\ws_java\\team4_v2sbm3c\\src\\main\\python\\exc2.py', reloading
INFO:werkzeug: * Detected change in 'C:\\kd\\ws_java\\team4_v2sbm3c\\src\\main\\python\\exc2.py', reloading
INFO:werkzeug: * Detected change in 'C:\\kd\\ws_java\\team4_v2sbm3c\\src\\main\\python\\exc2.py', reloading
INFO:werkzeug: * Detected change in 'C:\\kd\\ws_java\\team4_v2sbm3c\\src\\main\\python\\exc2.py', reloading
INFO:werkzeug: * Detected change in 'C:\\kd\\ws_java\\team4_v2sbm3c\\src\\main\\python\\exc2.py', reloading
INFO:werkzeug: * Detected change in 'C:\\kd\\ws_java\\team4_v2sbm3c\\src\\main\\python\\exc2.py', reloading
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\i\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:WDM:Driver [C:\Users\i\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawl_and_insert_data" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 569-178-434
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawl_and_insert_data" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 569-178-434
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 19:05:28 KST)" (scheduled at 2025-01-14 19:05:08.975517+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 19:05:28 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 108, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 38, in load
    driver.get(url) # url 접속
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: disconnected: not connected to DevTools
  (failed to check if window was closed: disconnected: not connected to DevTools)
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x007BFD53+23747]
	(No symbol) [0x00747D54]
	(No symbol) [0x0061BE53]
	(No symbol) [0x0060C408]
	(No symbol) [0x0060C329]
	(No symbol) [0x0061E2E0]
	(No symbol) [0x0069AD69]
	(No symbol) [0x00681B96]
	(No symbol) [0x00653F3C]
	(No symbol) [0x00654EBD]
	GetHandleVerifier [0x00A9AC73+3017699]
	GetHandleVerifier [0x00AAB93B+3086507]
	GetHandleVerifier [0x00AA40F2+3055714]
	GetHandleVerifier [0x00855AF0+637536]
	(No symbol) [0x00750A5D]
	(No symbol) [0x0074DA28]
	(No symbol) [0x0074DBC5]
	(No symbol) [0x007407F0]
	BaseThreadInitThunk [0x754CFCC9+25]
	RtlGetAppContainerNamedObjectPath [0x76F4809E+286]
	RtlGetAppContainerNamedObjectPath [0x76F4806E+238]

INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 19:05:30 KST)" (scheduled at 2025-01-14 19:05:10.966502+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 19:05:30 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 108, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 38, in load
    driver.get(url) # url 접속
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: disconnected: not connected to DevTools
  (failed to check if window was closed: disconnected: not connected to DevTools)
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x007BFD53+23747]
	(No symbol) [0x00747D54]
	(No symbol) [0x0061BE53]
	(No symbol) [0x0060C408]
	(No symbol) [0x0060C329]
	(No symbol) [0x0061E2E0]
	(No symbol) [0x0069AD69]
	(No symbol) [0x00681B96]
	(No symbol) [0x00653F3C]
	(No symbol) [0x00654EBD]
	GetHandleVerifier [0x00A9AC73+3017699]
	GetHandleVerifier [0x00AAB93B+3086507]
	GetHandleVerifier [0x00AA40F2+3055714]
	GetHandleVerifier [0x00855AF0+637536]
	(No symbol) [0x00750A5D]
	(No symbol) [0x0074DA28]
	(No symbol) [0x0074DBC5]
	(No symbol) [0x007407F0]
	BaseThreadInitThunk [0x754CFCC9+25]
	RtlGetAppContainerNamedObjectPath [0x76F4809E+286]
	RtlGetAppContainerNamedObjectPath [0x76F4806E+238]

INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 19:05:21 KST)" (scheduled at 2025-01-14 19:05:21.531972+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 19:05:41 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 108, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 38, in load
    driver.get(url) # url 접속
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchWindowException: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x007BFD53+23747]
	(No symbol) [0x00747D54]
	(No symbol) [0x0061BE53]
	(No symbol) [0x005FD91B]
	(No symbol) [0x00687EFF]
	(No symbol) [0x0069AD49]
	(No symbol) [0x00681B96]
	(No symbol) [0x00653F3C]
	(No symbol) [0x00654EBD]
	GetHandleVerifier [0x00A9AC73+3017699]
	GetHandleVerifier [0x00AAB93B+3086507]
	GetHandleVerifier [0x00AA40F2+3055714]
	GetHandleVerifier [0x00855AF0+637536]
	(No symbol) [0x00750A5D]
	(No symbol) [0x0074DA28]
	(No symbol) [0x0074DBC5]
	(No symbol) [0x007407F0]
	BaseThreadInitThunk [0x754CFCC9+25]
	RtlGetAppContainerNamedObjectPath [0x76F4809E+286]
	RtlGetAppContainerNamedObjectPath [0x76F4806E+238]

INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 19:05:21 KST)" (scheduled at 2025-01-14 19:05:21.620974+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 19:05:41 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 108, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 38, in load
    driver.get(url) # url 접속
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchWindowException: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x007BFD53+23747]
	(No symbol) [0x00747D54]
	(No symbol) [0x0061BE53]
	(No symbol) [0x005FD91B]
	(No symbol) [0x00687EFF]
	(No symbol) [0x0069AD49]
	(No symbol) [0x00681B96]
	(No symbol) [0x00653F3C]
	(No symbol) [0x00654EBD]
	GetHandleVerifier [0x00A9AC73+3017699]
	GetHandleVerifier [0x00AAB93B+3086507]
	GetHandleVerifier [0x00AA40F2+3055714]
	GetHandleVerifier [0x00855AF0+637536]
	(No symbol) [0x00750A5D]
	(No symbol) [0x0074DA28]
	(No symbol) [0x0074DBC5]
	(No symbol) [0x007407F0]
	BaseThreadInitThunk [0x754CFCC9+25]
	RtlGetAppContainerNamedObjectPath [0x76F4809E+286]
	RtlGetAppContainerNamedObjectPath [0x76F4806E+238]

INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\i\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawl_and_insert_data" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
INFO:werkzeug:[33mPress CTRL+C to quit[0m
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\i\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawl_and_insert_data" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 569-178-434
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 19:19:11 KST)" (scheduled at 2025-01-14 19:19:11.045759+09:00)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 19:19:15 KST)" (scheduled at 2025-01-14 19:19:15.907193+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:00:20], next run at: 2025-01-14 19:19:35 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 108, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 38, in load
    driver.get(url) # url 접속
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchWindowException: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x007BFD53+23747]
	(No symbol) [0x00747D54]
	(No symbol) [0x0061BE53]
	(No symbol) [0x005FD91B]
	(No symbol) [0x00687EFF]
	(No symbol) [0x0069AD49]
	(No symbol) [0x00681B96]
	(No symbol) [0x00653F3C]
	(No symbol) [0x00654EBD]
	GetHandleVerifier [0x00A9AC73+3017699]
	GetHandleVerifier [0x00AAB93B+3086507]
	GetHandleVerifier [0x00AA40F2+3055714]
	GetHandleVerifier [0x00855AF0+637536]
	(No symbol) [0x00750A5D]
	(No symbol) [0x0074DA28]
	(No symbol) [0x0074DBC5]
	(No symbol) [0x007407F0]
	BaseThreadInitThunk [0x754CFCC9+25]
	RtlGetAppContainerNamedObjectPath [0x76F4809E+286]
	RtlGetAppContainerNamedObjectPath [0x76F4806E+238]

INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:WebDriver version 131.0.6778.264 selected
INFO:WDM:Modern chrome version https://storage.googleapis.com/chrome-for-testing-public/131.0.6778.264/win32/chromedriver-win32.zip
INFO:WDM:About to download new driver from https://storage.googleapis.com/chrome-for-testing-public/131.0.6778.264/win32/chromedriver-win32.zip
INFO:WDM:Driver downloading response is 200
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver has been saved in cache [C:\Users\i\.wdm\drivers\chromedriver\win64\131.0.6778.264]
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawl_and_insert_data" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
INFO:werkzeug:[33mPress CTRL+C to quit[0m
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\i\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawl_and_insert_data" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 569-178-434
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 16:54:40 KST)" (scheduled at 2025-01-15 16:54:40.056877+09:00)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 16:54:45 KST)" (scheduled at 2025-01-15 16:54:45.232364+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 16:55:40 KST)" executed successfully
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 16:55:45 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 16:56:40 KST)" (scheduled at 2025-01-15 16:55:40.056877+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 16:56:40 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 16:56:45 KST)" (scheduled at 2025-01-15 16:55:45.232364+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 16:56:45 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 16:57:40 KST)" (scheduled at 2025-01-15 16:56:40.056877+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 16:57:40 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 16:57:45 KST)" (scheduled at 2025-01-15 16:56:45.232364+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 16:57:45 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 16:58:40 KST)" (scheduled at 2025-01-15 16:57:40.056877+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 16:58:40 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 16:58:45 KST)" (scheduled at 2025-01-15 16:57:45.232364+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 16:58:45 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 16:59:40 KST)" (scheduled at 2025-01-15 16:58:40.056877+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 16:59:40 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 16:59:45 KST)" (scheduled at 2025-01-15 16:58:45.232364+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 16:59:45 KST)" executed successfully
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\i\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawl_and_insert_data" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
INFO:werkzeug:[33mPress CTRL+C to quit[0m
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\i\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawl_and_insert_data" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 569-178-434
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\i\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawl_and_insert_data" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
INFO:werkzeug:[33mPress CTRL+C to quit[0m
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\i\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:WDM:====== WebDriver manager ======
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawl_and_insert_data" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
INFO:werkzeug:[33mPress CTRL+C to quit[0m
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\i\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawl_and_insert_data" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 569-178-434
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\i\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawl_and_insert_data" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 569-178-434
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:00:40 KST)" (scheduled at 2025-01-15 16:59:40.056877+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:00:45 KST)" (scheduled at 2025-01-15 16:59:45.232364+09:00)
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\i\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:00:40 KST)" executed successfully
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawl_and_insert_data" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
INFO:werkzeug:[33mPress CTRL+C to quit[0m
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:00:45 KST)" executed successfully
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\i\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 16:59:54 KST)" (scheduled at 2025-01-15 16:59:54.741488+09:00)
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawl_and_insert_data" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 569-178-434
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:00:54 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:00:00 KST)" (scheduled at 2025-01-15 17:00:00.484357+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:01:00 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:00:26 KST)" (scheduled at 2025-01-15 17:00:26.604499+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:01:26 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:00:30 KST)" (scheduled at 2025-01-15 17:00:30.738027+09:00)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:00:32 KST)" (scheduled at 2025-01-15 17:00:32.594516+09:00)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:00:36 KST)" (scheduled at 2025-01-15 17:00:36.738369+09:00)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:01:40 KST)" (scheduled at 2025-01-15 17:00:40.056877+09:00)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:01:45 KST)" (scheduled at 2025-01-15 17:00:45.232364+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:01:40 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:00:48 KST)" (scheduled at 2025-01-15 17:00:48.987824+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:01:45 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:01:54 KST)" (scheduled at 2025-01-15 17:00:54.741488+09:00)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:00:55 KST)" (scheduled at 2025-01-15 17:00:55.155013+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:01:36 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:02:00 KST)" (scheduled at 2025-01-15 17:01:00.484357+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:01:54 KST)" executed successfully
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:02:00 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:02:26 KST)" (scheduled at 2025-01-15 17:01:26.604499+09:00)
WARNING:apscheduler.scheduler:Execution of job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:01:30 KST)" skipped: maximum number of running instances reached (1)
WARNING:apscheduler.scheduler:Execution of job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:01:32 KST)" skipped: maximum number of running instances reached (1)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:02:26 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:02:36 KST)" (scheduled at 2025-01-15 17:01:36.738369+09:00)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:02:40 KST)" (scheduled at 2025-01-15 17:01:40.056877+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:01:55 KST)" executed successfully
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:02:36 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:02:45 KST)" (scheduled at 2025-01-15 17:01:45.232364+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:02:40 KST)" executed successfully
WARNING:apscheduler.scheduler:Execution of job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:01:48 KST)" skipped: maximum number of running instances reached (1)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:02:32 KST)" executed successfully
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:02:45 KST)" executed successfully
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:02:30 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:02:54 KST)" (scheduled at 2025-01-15 17:01:54.741488+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:02:48 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:02:55 KST)" (scheduled at 2025-01-15 17:01:55.155013+09:00)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:03:00 KST)" (scheduled at 2025-01-15 17:02:00.484357+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:02:55 KST)" executed successfully
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:02:54 KST)" executed successfully
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\i\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawl_and_insert_data" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
INFO:werkzeug:[33mPress CTRL+C to quit[0m
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:03:00 KST)" executed successfully
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\i\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawl_and_insert_data" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 569-178-434
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:03:26 KST)" (scheduled at 2025-01-15 17:02:26.604499+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:03:26 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:03:30 KST)" (scheduled at 2025-01-15 17:02:30.738027+09:00)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:03:32 KST)" (scheduled at 2025-01-15 17:02:32.594516+09:00)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:03:36 KST)" (scheduled at 2025-01-15 17:02:36.738369+09:00)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:03:40 KST)" (scheduled at 2025-01-15 17:02:40.056877+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:03:30 KST)" executed successfully
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:03:36 KST)" executed successfully
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:03:32 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:03:45 KST)" (scheduled at 2025-01-15 17:02:45.232364+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:03:40 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:03:48 KST)" (scheduled at 2025-01-15 17:02:48.987824+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:03:45 KST)" executed successfully
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:03:48 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:03:54 KST)" (scheduled at 2025-01-15 17:02:54.741488+09:00)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:03:55 KST)" (scheduled at 2025-01-15 17:02:55.155013+09:00)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:04:00 KST)" (scheduled at 2025-01-15 17:03:00.484357+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:03:54 KST)" executed successfully
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:03:55 KST)" executed successfully
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:04:00 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:03:07 KST)" (scheduled at 2025-01-15 17:03:07.825891+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:04:07 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:03:14 KST)" (scheduled at 2025-01-15 17:03:14.428325+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:04:14 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:04:26 KST)" (scheduled at 2025-01-15 17:03:26.604499+09:00)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:04:30 KST)" (scheduled at 2025-01-15 17:03:30.738027+09:00)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:04:32 KST)" (scheduled at 2025-01-15 17:03:32.594516+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:04:26 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:04:36 KST)" (scheduled at 2025-01-15 17:03:36.738369+09:00)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:04:40 KST)" (scheduled at 2025-01-15 17:03:40.056877+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:04:32 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:04:45 KST)" (scheduled at 2025-01-15 17:03:45.232364+09:00)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:04:48 KST)" (scheduled at 2025-01-15 17:03:48.987824+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:04:30 KST)" executed successfully
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:04:40 KST)" executed successfully
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:04:36 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:04:54 KST)" (scheduled at 2025-01-15 17:03:54.741488+09:00)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:04:55 KST)" (scheduled at 2025-01-15 17:03:55.155013+09:00)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:05:00 KST)" (scheduled at 2025-01-15 17:04:00.484357+09:00)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:05:07 KST)" (scheduled at 2025-01-15 17:04:07.825891+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:05:00 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:05:14 KST)" (scheduled at 2025-01-15 17:04:14.428325+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:04:45 KST)" executed successfully
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:04:48 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:05:26 KST)" (scheduled at 2025-01-15 17:04:26.604499+09:00)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:05:30 KST)" (scheduled at 2025-01-15 17:04:30.738027+09:00)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:05:32 KST)" (scheduled at 2025-01-15 17:04:32.594516+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:04:54 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:05:36 KST)" (scheduled at 2025-01-15 17:04:36.738369+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:05:26 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:05:40 KST)" (scheduled at 2025-01-15 17:04:40.056877+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:04:55 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:05:45 KST)" (scheduled at 2025-01-15 17:04:45.232364+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:05:30 KST)" executed successfully
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:05:36 KST)" executed successfully
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:05:14 KST)" executed successfully
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:05:40 KST)" executed successfully
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:05:32 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:05:48 KST)" (scheduled at 2025-01-15 17:04:48.987824+09:00)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:05:54 KST)" (scheduled at 2025-01-15 17:04:54.741488+09:00)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:05:55 KST)" (scheduled at 2025-01-15 17:04:55.155013+09:00)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:06:00 KST)" (scheduled at 2025-01-15 17:05:00.484357+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:05:48 KST)" executed successfully
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:05:54 KST)" executed successfully
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:05:55 KST)" executed successfully
WARNING:apscheduler.scheduler:Execution of job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:05:07 KST)" skipped: maximum number of running instances reached (1)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:06:00 KST)" executed successfully
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:05:45 KST)" executed successfully
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:06:07 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:06:14 KST)" (scheduled at 2025-01-15 17:05:14.428325+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:06:14 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:06:26 KST)" (scheduled at 2025-01-15 17:05:26.604499+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:06:26 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:06:30 KST)" (scheduled at 2025-01-15 17:05:30.738027+09:00)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:06:32 KST)" (scheduled at 2025-01-15 17:05:32.594516+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:06:30 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:06:36 KST)" (scheduled at 2025-01-15 17:05:36.738369+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:06:32 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:06:40 KST)" (scheduled at 2025-01-15 17:05:40.056877+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:06:36 KST)" executed successfully
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:06:40 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:06:45 KST)" (scheduled at 2025-01-15 17:05:45.232364+09:00)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:06:48 KST)" (scheduled at 2025-01-15 17:05:48.987824+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:06:48 KST)" executed successfully
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:06:45 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:06:54 KST)" (scheduled at 2025-01-15 17:05:54.741488+09:00)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:06:55 KST)" (scheduled at 2025-01-15 17:05:55.155013+09:00)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:07:00 KST)" (scheduled at 2025-01-15 17:06:00.484357+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:06:55 KST)" executed successfully
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:06:54 KST)" executed successfully
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:07:00 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:07:07 KST)" (scheduled at 2025-01-15 17:06:07.825891+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:07:07 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:07:14 KST)" (scheduled at 2025-01-15 17:06:14.428325+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:07:14 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:07:26 KST)" (scheduled at 2025-01-15 17:06:26.604499+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:07:26 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:07:30 KST)" (scheduled at 2025-01-15 17:06:30.738027+09:00)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:07:32 KST)" (scheduled at 2025-01-15 17:06:32.594516+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:07:30 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:07:36 KST)" (scheduled at 2025-01-15 17:06:36.738369+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:07:32 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:07:40 KST)" (scheduled at 2025-01-15 17:06:40.056877+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:07:36 KST)" executed successfully
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:07:40 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:07:45 KST)" (scheduled at 2025-01-15 17:06:45.232364+09:00)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:07:48 KST)" (scheduled at 2025-01-15 17:06:48.987824+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:07:45 KST)" executed successfully
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:07:48 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:07:54 KST)" (scheduled at 2025-01-15 17:06:54.741488+09:00)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:07:55 KST)" (scheduled at 2025-01-15 17:06:55.155013+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:07:55 KST)" executed successfully
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:07:54 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:08:00 KST)" (scheduled at 2025-01-15 17:07:00.484357+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:08:00 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:08:07 KST)" (scheduled at 2025-01-15 17:07:07.825891+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:08:07 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:08:14 KST)" (scheduled at 2025-01-15 17:07:14.428325+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:08:14 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:08:26 KST)" (scheduled at 2025-01-15 17:07:26.604499+09:00)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:08:30 KST)" (scheduled at 2025-01-15 17:07:30.738027+09:00)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:08:32 KST)" (scheduled at 2025-01-15 17:07:32.594516+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:08:26 KST)" executed successfully
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:08:30 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:08:36 KST)" (scheduled at 2025-01-15 17:07:36.738369+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:08:32 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:08:40 KST)" (scheduled at 2025-01-15 17:07:40.056877+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:08:36 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:08:45 KST)" (scheduled at 2025-01-15 17:07:45.232364+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:08:40 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:08:48 KST)" (scheduled at 2025-01-15 17:07:48.987824+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:08:45 KST)" executed successfully
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:08:48 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:08:54 KST)" (scheduled at 2025-01-15 17:07:54.741488+09:00)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:08:55 KST)" (scheduled at 2025-01-15 17:07:55.155013+09:00)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:09:00 KST)" (scheduled at 2025-01-15 17:08:00.484357+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:08:55 KST)" executed successfully
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:08:54 KST)" executed successfully
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:09:00 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:09:07 KST)" (scheduled at 2025-01-15 17:08:07.825891+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:09:07 KST)" executed successfully
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:09:14 KST)" (scheduled at 2025-01-15 17:08:14.428325+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:09:14 KST)" executed successfully
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\i\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawl_and_insert_data" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
INFO:werkzeug:[33mPress CTRL+C to quit[0m
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:09:26 KST)" (scheduled at 2025-01-15 17:08:26.604499+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:09:26 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:09:30 KST)" (scheduled at 2025-01-15 17:08:30.738027+09:00)
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\i\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:09:32 KST)" (scheduled at 2025-01-15 17:08:32.594516+09:00)
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawl_and_insert_data" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 569-178-434
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:09:30 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:09:36 KST)" (scheduled at 2025-01-15 17:08:36.738369+09:00)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:09:40 KST)" (scheduled at 2025-01-15 17:08:40.056877+09:00)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:09:45 KST)" (scheduled at 2025-01-15 17:08:45.232364+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:09:32 KST)" executed successfully
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:09:36 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:09:48 KST)" (scheduled at 2025-01-15 17:08:48.987824+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:09:45 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:09:54 KST)" (scheduled at 2025-01-15 17:08:54.741488+09:00)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:09:55 KST)" (scheduled at 2025-01-15 17:08:55.155013+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:09:48 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:10:00 KST)" (scheduled at 2025-01-15 17:09:00.484357+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:09:55 KST)" executed successfully
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:09:40 KST)" executed successfully
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:09:54 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:10:07 KST)" (scheduled at 2025-01-15 17:09:07.825891+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:10:00 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:10:14 KST)" (scheduled at 2025-01-15 17:09:14.428325+09:00)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:10:07 KST)" executed successfully
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:10:14 KST)" executed successfully
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\i\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:09:24 KST)" (scheduled at 2025-01-15 17:09:24.406309+09:00)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:10:26 KST)" (scheduled at 2025-01-15 17:09:26.604499+09:00)
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawl_and_insert_data" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
INFO:werkzeug:[33mPress CTRL+C to quit[0m
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:10:30 KST)" (scheduled at 2025-01-15 17:09:30.738027+09:00)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:10:32 KST)" (scheduled at 2025-01-15 17:09:32.594516+09:00)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:09:34 KST)" (scheduled at 2025-01-15 17:09:34.341309+09:00)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:10:36 KST)" (scheduled at 2025-01-15 17:09:36.738369+09:00)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:10:40 KST)" (scheduled at 2025-01-15 17:09:40.056877+09:00)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:10:45 KST)" (scheduled at 2025-01-15 17:09:45.232364+09:00)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:10:48 KST)" (scheduled at 2025-01-15 17:09:48.987824+09:00)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:10:54 KST)" (scheduled at 2025-01-15 17:09:54.741488+09:00)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:10:55 KST)" (scheduled at 2025-01-15 17:09:55.155013+09:00)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:11:00 KST)" (scheduled at 2025-01-15 17:10:00.484357+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:10:55 KST)" executed successfully
INFO:werkzeug: * Detected change in 'C:\\Users\\i\\AppData\\Roaming\\Python\\Python310\\site-packages\\apscheduler\\executors\\base.py', reloading
INFO:werkzeug: * Detected change in 'C:\\Users\\i\\AppData\\Roaming\\Python\\Python310\\site-packages\\apscheduler\\executors\\base.py', reloading
INFO:werkzeug: * Detected change in 'C:\\Users\\i\\AppData\\Roaming\\Python\\Python310\\site-packages\\apscheduler\\executors\\base.py', reloading
INFO:werkzeug: * Detected change in 'C:\\Users\\i\\AppData\\Roaming\\Python\\Python310\\site-packages\\apscheduler\\executors\\base.py', reloading
INFO:werkzeug: * Detected change in 'C:\\Users\\i\\AppData\\Roaming\\Python\\Python310\\site-packages\\apscheduler\\executors\\base.py', reloading
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:10:34 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 126, in crawl_and_insert_data
    url = driver.current_url.strip()
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 437, in current_url
    return self.execute(Command.GET_CURRENT_URL)["value"]
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: target frame detached: received Inspector.detached event
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x00A3FD53+23747]
	(No symbol) [0x009C7D54]
	(No symbol) [0x0089BE53]
	(No symbol) [0x0088E998]
	(No symbol) [0x0088DBA7]
	(No symbol) [0x0088D503]
	(No symbol) [0x0088D43D]
	(No symbol) [0x0088B8BB]
	(No symbol) [0x0088BF2D]
	(No symbol) [0x008981BA]
	(No symbol) [0x008A78B5]
	(No symbol) [0x008AC726]
	(No symbol) [0x0088C535]
	(No symbol) [0x008A74E1]
	(No symbol) [0x0091B33D]
	(No symbol) [0x00901B96]
	(No symbol) [0x008D3F3C]
	(No symbol) [0x008D4EBD]
	GetHandleVerifier [0x00D1AC73+3017699]
	GetHandleVerifier [0x00D2B93B+3086507]
	GetHandleVerifier [0x00D240F2+3055714]
	GetHandleVerifier [0x00AD5AF0+637536]
	(No symbol) [0x009D0A5D]
	(No symbol) [0x009CDA28]
	(No symbol) [0x009CDBC5]
	(No symbol) [0x009C07F0]
	BaseThreadInitThunk [0x754CFCC9+25]
	RtlGetAppContainerNamedObjectPath [0x76F4809E+286]
	RtlGetAppContainerNamedObjectPath [0x76F4806E+238]

INFO:werkzeug: * Detected change in 'C:\\Users\\i\\AppData\\Roaming\\Python\\Python310\\site-packages\\apscheduler\\executors\\base.py', reloading
INFO:werkzeug: * Detected change in 'C:\\Users\\i\\AppData\\Roaming\\Python\\Python310\\site-packages\\selenium\\webdriver\\remote\\webdriver.py', reloading
INFO:werkzeug: * Detected change in 'C:\\Users\\i\\AppData\\Roaming\\Python\\Python310\\site-packages\\selenium\\webdriver\\remote\\webdriver.py', reloading
INFO:werkzeug: * Detected change in 'C:\\Users\\i\\AppData\\Roaming\\Python\\Python310\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py', reloading
INFO:werkzeug: * Detected change in 'C:\\Users\\i\\AppData\\Roaming\\Python\\Python310\\site-packages\\selenium\\webdriver\\remote\\webdriver.py', reloading
INFO:werkzeug: * Detected change in 'C:\\Users\\i\\AppData\\Roaming\\Python\\Python310\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py', reloading
INFO:werkzeug: * Detected change in 'C:\\Users\\i\\AppData\\Roaming\\Python\\Python310\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py', reloading
INFO:werkzeug: * Detected change in 'C:\\Users\\i\\AppData\\Roaming\\Python\\Python310\\site-packages\\selenium\\webdriver\\remote\\webdriver.py', reloading
INFO:werkzeug: * Detected change in 'C:\\Users\\i\\AppData\\Roaming\\Python\\Python310\\site-packages\\selenium\\webdriver\\remote\\webdriver.py', reloading
INFO:werkzeug: * Detected change in 'C:\\Users\\i\\AppData\\Roaming\\Python\\Python310\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py', reloading
INFO:werkzeug: * Detected change in 'C:\\Users\\i\\AppData\\Roaming\\Python\\Python310\\site-packages\\selenium\\webdriver\\remote\\webdriver.py', reloading
INFO:werkzeug: * Detected change in 'C:\\Users\\i\\AppData\\Roaming\\Python\\Python310\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py', reloading
INFO:werkzeug: * Detected change in 'C:\\Users\\i\\AppData\\Roaming\\Python\\Python310\\site-packages\\selenium\\webdriver\\remote\\webdriver.py', reloading
INFO:werkzeug: * Detected change in 'C:\\Users\\i\\AppData\\Roaming\\Python\\Python310\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py', reloading
INFO:werkzeug: * Detected change in 'C:\\Users\\i\\AppData\\Roaming\\Python\\Python310\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py', reloading
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:11:07 KST)" (scheduled at 2025-01-15 17:10:07.825891+09:00)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\i\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\i\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:WDM:====== WebDriver manager ======
INFO:WDM:====== WebDriver manager ======
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\i\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\i\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\i\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:10:30 KST)" executed successfully
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:10:36 KST)" executed successfully
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
WARNING:apscheduler.scheduler:Execution of job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:10:24 KST)" skipped: maximum number of running instances reached (1)
WARNING:apscheduler.scheduler:Execution of job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:10:26 KST)" skipped: maximum number of running instances reached (1)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:11:28 KST)" (scheduled at 2025-01-15 17:10:28.160312+09:00)
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawl_and_insert_data" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 569-178-434
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawl_and_insert_data" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 569-178-434
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:11:26 KST)" executed successfully
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:10:45 KST)" executed successfully
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:11:30 KST)" (scheduled at 2025-01-15 17:10:30.738027+09:00)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
WARNING:apscheduler.scheduler:Execution of job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:10:32 KST)" skipped: maximum number of running instances reached (1)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:11:00 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 126, in crawl_and_insert_data
    url = driver.current_url.strip()
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 437, in current_url
    return self.execute(Command.GET_CURRENT_URL)["value"]
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: target frame detached: received Inspector.detached event
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x00A3FD53+23747]
	(No symbol) [0x009C7D54]
	(No symbol) [0x0089BE53]
	(No symbol) [0x0088E998]
	(No symbol) [0x0088DBA7]
	(No symbol) [0x0088D503]
	(No symbol) [0x0088D43D]
	(No symbol) [0x0088B8BB]
	(No symbol) [0x0088BF2D]
	(No symbol) [0x008981BA]
	(No symbol) [0x008A78B5]
	(No symbol) [0x008AC726]
	(No symbol) [0x0088C535]
	(No symbol) [0x008A74E1]
	(No symbol) [0x0091B33D]
	(No symbol) [0x00901B96]
	(No symbol) [0x008D3F3C]
	(No symbol) [0x008D4EBD]
	GetHandleVerifier [0x00D1AC73+3017699]
	GetHandleVerifier [0x00D2B93B+3086507]
	GetHandleVerifier [0x00D240F2+3055714]
	GetHandleVerifier [0x00AD5AF0+637536]
	(No symbol) [0x009D0A5D]
	(No symbol) [0x009CDA28]
	(No symbol) [0x009CDBC5]
	(No symbol) [0x009C07F0]
	BaseThreadInitThunk [0x754CFCC9+25]
	RtlGetAppContainerNamedObjectPath [0x76F4809E+286]
	RtlGetAppContainerNamedObjectPath [0x76F4806E+238]

INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\i\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:11:30 KST)" executed successfully
INFO:WDM:====== WebDriver manager ======
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:10:48 KST)" executed successfully
WARNING:apscheduler.scheduler:Execution of job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:10:40 KST)" skipped: maximum number of running instances reached (1)
INFO:werkzeug: * Detected change in 'C:\\Users\\i\\AppData\\Roaming\\Python\\Python310\\site-packages\\selenium\\webdriver\\remote\\remote_connection.py', reloading
INFO:werkzeug: * Detected change in 'C:\\Users\\i\\AppData\\Roaming\\Python\\Python310\\site-packages\\selenium\\webdriver\\remote\\remote_connection.py', reloading
INFO:werkzeug: * Detected change in 'C:\\ProgramData\\Anaconda3\\Lib\\site-packages\\urllib3\\request.py', reloading
INFO:werkzeug: * Detected change in 'C:\\ProgramData\\Anaconda3\\Lib\\site-packages\\urllib3\\request.py', reloading
INFO:werkzeug: * Detected change in 'C:\\ProgramData\\Anaconda3\\Lib\\site-packages\\urllib3\\poolmanager.py', reloading
INFO:werkzeug: * Detected change in 'C:\\ProgramData\\Anaconda3\\Lib\\site-packages\\urllib3\\poolmanager.py', reloading
INFO:werkzeug: * Detected change in 'C:\\ProgramData\\Anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py', reloading
INFO:werkzeug: * Detected change in 'C:\\ProgramData\\Anaconda3\\Lib\\site-packages\\urllib3\\util\\retry.py', reloading
INFO:werkzeug: * Detected change in 'C:\\ProgramData\\Anaconda3\\Lib\\site-packages\\urllib3\\packages\\six.py', reloading
INFO:werkzeug: * Detected change in 'C:\\ProgramData\\Anaconda3\\Lib\\site-packages\\urllib3\\packages\\six.py', reloading
INFO:werkzeug: * Detected change in 'C:\\ProgramData\\Anaconda3\\Lib\\http\\client.py', reloading
INFO:werkzeug: * Detected change in 'C:\\ProgramData\\Anaconda3\\Lib\\http\\client.py', reloading
INFO:werkzeug: * Detected change in 'C:\\ProgramData\\Anaconda3\\Lib\\socket.py', reloading
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:11:28 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 449, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 444, in _make_request
    httplib_response = conn.getresponse()
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1374, in getresponse
    response.begin()
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 318, in begin
    version, status, reason = self._read_status()
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 279, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "C:\ProgramData\Anaconda3\lib\socket.py", line 705, in readinto
    return self._sock.recv_into(b)
ConnectionResetError: [WinError 10054] 현재 연결은 원격 호스트에 의해 강제로 끊겼습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 550, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\packages\six.py", line 769, in reraise
    raise value.with_traceback(tb)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 449, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 444, in _make_request
    httplib_response = conn.getresponse()
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1374, in getresponse
    response.begin()
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 318, in begin
    version, status, reason = self._read_status()
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 279, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "C:\ProgramData\Anaconda3\lib\socket.py", line 705, in readinto
    return self._sock.recv_into(b)
urllib3.exceptions.ProtocolError: ('Connection aborted.', ConnectionResetError(10054, '현재 연결은 원격 호스트에 의해 강제로 끊겼습니다', None, 10054, None))
INFO:werkzeug: * Detected change in 'C:\\ProgramData\\Anaconda3\\Lib\\socket.py', reloading
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawl_and_insert_data" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 569-178-434
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000179F82A3DC0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/6052896cbb80a7be4e12ca11c240f513/element
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\i\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\i\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:WDM:====== WebDriver manager ======
INFO:WDM:====== WebDriver manager ======
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:11:48 KST)" (scheduled at 2025-01-15 17:10:48.987824+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:11:07 KST)" executed successfully
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000179F82A3E80>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/6052896cbb80a7be4e12ca11c240f513/element
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:WebDriver version 131.0.6778.264 selected
INFO:WDM:Modern chrome version https://storage.googleapis.com/chrome-for-testing-public/131.0.6778.264/win32/chromedriver-win32.zip
INFO:WDM:About to download new driver from https://storage.googleapis.com/chrome-for-testing-public/131.0.6778.264/win32/chromedriver-win32.zip
INFO:WDM:Driver downloading response is 200
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver has been saved in cache [C:\Users\i\.wdm\drivers\chromedriver\win64\131.0.6778.264]
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawl_and_insert_data" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
INFO:werkzeug:[33mPress CTRL+C to quit[0m
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\i\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawl_and_insert_data" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 569-178-434
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 09:46:56 KST)" (scheduled at 2025-01-16 09:46:56.398922+09:00)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 09:47:03 KST)" (scheduled at 2025-01-16 09:47:03.503588+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 09:47:56 KST)" executed successfully
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 09:48:03 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 09:48:56 KST)" (scheduled at 2025-01-16 09:47:56.398922+09:00)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\i\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawl_and_insert_data" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
INFO:werkzeug:[33mPress CTRL+C to quit[0m
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\i\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:WDM:====== WebDriver manager ======
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawl_and_insert_data" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 569-178-434
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\i\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawl_and_insert_data" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
INFO:werkzeug:[33mPress CTRL+C to quit[0m
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\i\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawl_and_insert_data" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 569-178-434
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:31:03 KST)" (scheduled at 2025-01-16 10:31:03.303167+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:32:03 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 269, in crawl_and_insert_data
    title = bs.select('#main-content > article > div:nth-child(1) > h1')[0].text
IndexError: list index out of range
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:31:11 KST)" (scheduled at 2025-01-16 10:31:11.931313+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:32:11 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 269, in crawl_and_insert_data
    title = bs.select('#main-content > article > div:nth-child(1) > h1')[0].text
IndexError: list index out of range
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:31:16 KST)" (scheduled at 2025-01-16 10:31:16.229134+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:32:16 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 269, in crawl_and_insert_data
    title = bs.select('#main-content > article > div:nth-child(1) > h1')[0].text
IndexError: list index out of range
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:31:23 KST)" (scheduled at 2025-01-16 10:31:23.139027+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:32:23 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 269, in crawl_and_insert_data
    title = bs.select('#main-content > article > div:nth-child(1) > h1')[0].text
IndexError: list index out of range
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:33:03 KST)" (scheduled at 2025-01-16 10:32:03.303167+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:33:03 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 269, in crawl_and_insert_data
    title = bs.select('#main-content > article > div:nth-child(1) > h1')[0].text
IndexError: list index out of range
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:33:11 KST)" (scheduled at 2025-01-16 10:32:11.931313+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:33:11 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 269, in crawl_and_insert_data
    title = bs.select('#main-content > article > div:nth-child(1) > h1')[0].text
IndexError: list index out of range
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:33:16 KST)" (scheduled at 2025-01-16 10:32:16.229134+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:33:16 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 269, in crawl_and_insert_data
    title = bs.select('#main-content > article > div:nth-child(1) > h1')[0].text
IndexError: list index out of range
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:33:23 KST)" (scheduled at 2025-01-16 10:32:23.139027+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:33:23 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 269, in crawl_and_insert_data
    title = bs.select('#main-content > article > div:nth-child(1) > h1')[0].text
IndexError: list index out of range
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:34:03 KST)" (scheduled at 2025-01-16 10:33:03.303167+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:34:03 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 269, in crawl_and_insert_data
    title = bs.select('#main-content > article > div:nth-child(1) > h1')[0].text
IndexError: list index out of range
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:34:11 KST)" (scheduled at 2025-01-16 10:33:11.931313+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:34:11 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 269, in crawl_and_insert_data
    title = bs.select('#main-content > article > div:nth-child(1) > h1')[0].text
IndexError: list index out of range
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:34:16 KST)" (scheduled at 2025-01-16 10:33:16.229134+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:34:16 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 269, in crawl_and_insert_data
    title = bs.select('#main-content > article > div:nth-child(1) > h1')[0].text
IndexError: list index out of range
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:34:23 KST)" (scheduled at 2025-01-16 10:33:23.139027+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:34:23 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 269, in crawl_and_insert_data
    title = bs.select('#main-content > article > div:nth-child(1) > h1')[0].text
IndexError: list index out of range
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:35:03 KST)" (scheduled at 2025-01-16 10:34:03.303167+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:35:03 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 269, in crawl_and_insert_data
    title = bs.select('#main-content > article > div:nth-child(1) > h1')[0].text
IndexError: list index out of range
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:35:11 KST)" (scheduled at 2025-01-16 10:34:11.931313+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:35:11 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 269, in crawl_and_insert_data
    title = bs.select('#main-content > article > div:nth-child(1) > h1')[0].text
IndexError: list index out of range
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:35:16 KST)" (scheduled at 2025-01-16 10:34:16.229134+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:35:16 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 269, in crawl_and_insert_data
    title = bs.select('#main-content > article > div:nth-child(1) > h1')[0].text
IndexError: list index out of range
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:35:23 KST)" (scheduled at 2025-01-16 10:34:23.139027+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:35:23 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 269, in crawl_and_insert_data
    title = bs.select('#main-content > article > div:nth-child(1) > h1')[0].text
IndexError: list index out of range
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:36:03 KST)" (scheduled at 2025-01-16 10:35:03.303167+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:36:03 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 269, in crawl_and_insert_data
    title = bs.select('#main-content > article > div:nth-child(1) > h1')[0].text
IndexError: list index out of range
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\i\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawl_and_insert_data" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
INFO:werkzeug:[33mPress CTRL+C to quit[0m
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:36:11 KST)" (scheduled at 2025-01-16 10:35:11.931313+09:00)
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\i\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:36:11 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 269, in crawl_and_insert_data
    title = bs.select('#main-content > article > div:nth-child(1) > h1')[0].text
IndexError: list index out of range
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawl_and_insert_data" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 569-178-434
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:36:16 KST)" (scheduled at 2025-01-16 10:35:16.229134+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:36:16 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 269, in crawl_and_insert_data
    title = bs.select('#main-content > article > div:nth-child(1) > h1')[0].text
IndexError: list index out of range
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:36:23 KST)" (scheduled at 2025-01-16 10:35:23.139027+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:36:23 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 269, in crawl_and_insert_data
    title = bs.select('#main-content > article > div:nth-child(1) > h1')[0].text
IndexError: list index out of range
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\i\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawl_and_insert_data" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
INFO:werkzeug:[33mPress CTRL+C to quit[0m
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\i\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawl_and_insert_data" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 569-178-434
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\i\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawl_and_insert_data" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
INFO:werkzeug:[33mPress CTRL+C to quit[0m
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:37:03 KST)" (scheduled at 2025-01-16 10:36:03.303167+09:00)
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\i\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:37:03 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 269, in crawl_and_insert_data
    title = bs.select('#main-content > article > div:nth-child(1) > h1')[0].text
IndexError: list index out of range
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawl_and_insert_data" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 569-178-434
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:36:07 KST)" (scheduled at 2025-01-16 10:36:07.688460+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:37:07 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 269, in crawl_and_insert_data
    title = bs.select('#main-content > article > div:nth-child(1) > h1')[0].text
IndexError: list index out of range
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:37:11 KST)" (scheduled at 2025-01-16 10:36:11.931313+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:37:11 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 269, in crawl_and_insert_data
    title = bs.select('#main-content > article > div:nth-child(1) > h1')[0].text
IndexError: list index out of range
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:36:16 KST)" (scheduled at 2025-01-16 10:36:16.049018+09:00)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:37:16 KST)" (scheduled at 2025-01-16 10:36:16.229134+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:37:16 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 269, in crawl_and_insert_data
    title = bs.select('#main-content > article > div:nth-child(1) > h1')[0].text
IndexError: list index out of range
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:37:16 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 269, in crawl_and_insert_data
    title = bs.select('#main-content > article > div:nth-child(1) > h1')[0].text
IndexError: list index out of range
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:37:23 KST)" (scheduled at 2025-01-16 10:36:23.139027+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:37:23 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 269, in crawl_and_insert_data
    title = bs.select('#main-content > article > div:nth-child(1) > h1')[0].text
IndexError: list index out of range
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:36:39 KST)" (scheduled at 2025-01-16 10:36:39.743394+09:00)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:36:48 KST)" (scheduled at 2025-01-16 10:36:48.909065+09:00)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:36:56 KST)" (scheduled at 2025-01-16 10:36:56.783521+09:00)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:38:03 KST)" (scheduled at 2025-01-16 10:37:03.303167+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:37:39 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 269, in crawl_and_insert_data
    title = bs.select('#main-content > article > div:nth-child(1) > h1')[0].text
IndexError: list index out of range
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:37:48 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 269, in crawl_and_insert_data
    title = bs.select('#main-content > article > div:nth-child(1) > h1')[0].text
IndexError: list index out of range
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:37:06 KST)" (scheduled at 2025-01-16 10:37:06.396757+09:00)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:38:07 KST)" (scheduled at 2025-01-16 10:37:07.688460+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:38:03 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 269, in crawl_and_insert_data
    title = bs.select('#main-content > article > div:nth-child(1) > h1')[0].text
IndexError: list index out of range
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:37:56 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 269, in crawl_and_insert_data
    title = bs.select('#main-content > article > div:nth-child(1) > h1')[0].text
IndexError: list index out of range
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:38:06 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 269, in crawl_and_insert_data
    title = bs.select('#main-content > article > div:nth-child(1) > h1')[0].text
IndexError: list index out of range
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:38:11 KST)" (scheduled at 2025-01-16 10:37:11.931313+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:38:07 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 269, in crawl_and_insert_data
    title = bs.select('#main-content > article > div:nth-child(1) > h1')[0].text
IndexError: list index out of range
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:38:16 KST)" (scheduled at 2025-01-16 10:37:16.049018+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:38:11 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 269, in crawl_and_insert_data
    title = bs.select('#main-content > article > div:nth-child(1) > h1')[0].text
IndexError: list index out of range
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:38:16 KST)" (scheduled at 2025-01-16 10:37:16.229134+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:38:16 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 269, in crawl_and_insert_data
    title = bs.select('#main-content > article > div:nth-child(1) > h1')[0].text
IndexError: list index out of range
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:38:16 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 269, in crawl_and_insert_data
    title = bs.select('#main-content > article > div:nth-child(1) > h1')[0].text
IndexError: list index out of range
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:38:23 KST)" (scheduled at 2025-01-16 10:37:23.139027+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:38:23 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 269, in crawl_and_insert_data
    title = bs.select('#main-content > article > div:nth-child(1) > h1')[0].text
IndexError: list index out of range
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:38:39 KST)" (scheduled at 2025-01-16 10:37:39.743394+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:38:39 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 269, in crawl_and_insert_data
    title = bs.select('#main-content > article > div:nth-child(1) > h1')[0].text
IndexError: list index out of range
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:38:48 KST)" (scheduled at 2025-01-16 10:37:48.909065+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:38:48 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 269, in crawl_and_insert_data
    title = bs.select('#main-content > article > div:nth-child(1) > h1')[0].text
IndexError: list index out of range
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:38:56 KST)" (scheduled at 2025-01-16 10:37:56.783521+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:38:56 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 269, in crawl_and_insert_data
    title = bs.select('#main-content > article > div:nth-child(1) > h1')[0].text
IndexError: list index out of range
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:39:03 KST)" (scheduled at 2025-01-16 10:38:03.303167+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:39:03 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 269, in crawl_and_insert_data
    title = bs.select('#main-content > article > div:nth-child(1) > h1')[0].text
IndexError: list index out of range
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:39:06 KST)" (scheduled at 2025-01-16 10:38:06.396757+09:00)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:39:07 KST)" (scheduled at 2025-01-16 10:38:07.688460+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:39:06 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 269, in crawl_and_insert_data
    title = bs.select('#main-content > article > div:nth-child(1) > h1')[0].text
IndexError: list index out of range
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:39:07 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 269, in crawl_and_insert_data
    title = bs.select('#main-content > article > div:nth-child(1) > h1')[0].text
IndexError: list index out of range
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:39:11 KST)" (scheduled at 2025-01-16 10:38:11.931313+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:39:11 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 269, in crawl_and_insert_data
    title = bs.select('#main-content > article > div:nth-child(1) > h1')[0].text
IndexError: list index out of range
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:39:16 KST)" (scheduled at 2025-01-16 10:38:16.049018+09:00)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:39:16 KST)" (scheduled at 2025-01-16 10:38:16.229134+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:39:16 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 269, in crawl_and_insert_data
    title = bs.select('#main-content > article > div:nth-child(1) > h1')[0].text
IndexError: list index out of range
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:39:16 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 269, in crawl_and_insert_data
    title = bs.select('#main-content > article > div:nth-child(1) > h1')[0].text
IndexError: list index out of range
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:39:23 KST)" (scheduled at 2025-01-16 10:38:23.139027+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:39:23 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 269, in crawl_and_insert_data
    title = bs.select('#main-content > article > div:nth-child(1) > h1')[0].text
IndexError: list index out of range
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:39:39 KST)" (scheduled at 2025-01-16 10:38:39.743394+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:39:39 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 269, in crawl_and_insert_data
    title = bs.select('#main-content > article > div:nth-child(1) > h1')[0].text
IndexError: list index out of range
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:39:48 KST)" (scheduled at 2025-01-16 10:38:48.909065+09:00)
INFO:werkzeug: * Detected change in 'C:\\kd\\ws_java\\team4_v2sbm3c\\src\\main\\python\\exc_2.py', reloading
INFO:werkzeug: * Detected change in 'C:\\kd\\ws_java\\team4_v2sbm3c\\src\\main\\python\\exc_2.py', reloading
INFO:werkzeug: * Detected change in 'C:\\kd\\ws_java\\team4_v2sbm3c\\src\\main\\python\\exc_2.py', reloading
INFO:werkzeug: * Detected change in 'C:\\kd\\ws_java\\team4_v2sbm3c\\src\\main\\python\\exc_2.py', reloading
INFO:werkzeug: * Detected change in 'C:\\kd\\ws_java\\team4_v2sbm3c\\src\\main\\python\\exc_2.py', reloading
INFO:werkzeug: * Detected change in 'C:\\kd\\ws_java\\team4_v2sbm3c\\src\\main\\python\\exc_2.py', reloading
INFO:werkzeug: * Detected change in 'C:\\kd\\ws_java\\team4_v2sbm3c\\src\\main\\python\\exc_2.py', reloading
INFO:werkzeug: * Detected change in 'C:\\kd\\ws_java\\team4_v2sbm3c\\src\\main\\python\\exc_2.py', reloading
INFO:werkzeug: * Detected change in 'C:\\kd\\ws_java\\team4_v2sbm3c\\src\\main\\python\\exc_2.py', reloading
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:39:56 KST)" (scheduled at 2025-01-16 10:38:56.783521+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:====== WebDriver manager ======
INFO:WDM:====== WebDriver manager ======
INFO:WDM:====== WebDriver manager ======
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:40:03 KST)" (scheduled at 2025-01-16 10:39:03.303167+09:00)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:40:07 KST)" (scheduled at 2025-01-16 10:39:07.688460+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:39:48 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 269, in crawl_and_insert_data
    title = bs.select('#main-content > article > div:nth-child(1) > h1')[0].text
IndexError: list index out of range
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:39:56 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 269, in crawl_and_insert_data
    title = bs.select('#main-content > article > div:nth-child(1) > h1')[0].text
IndexError: list index out of range
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\i\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\i\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:40:16 KST)" (scheduled at 2025-01-16 10:39:16.229134+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:40:03 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 269, in crawl_and_insert_data
    title = bs.select('#main-content > article > div:nth-child(1) > h1')[0].text
IndexError: list index out of range
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawl_and_insert_data" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 569-178-434
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawl_and_insert_data" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 569-178-434
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\i\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:WDM:Driver [C:\Users\i\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:WDM:====== WebDriver manager ======
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:40:07 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 269, in crawl_and_insert_data
    title = bs.select('#main-content > article > div:nth-child(1) > h1')[0].text
IndexError: list index out of range
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:40:39 KST)" (scheduled at 2025-01-16 10:39:39.743394+09:00)
INFO:werkzeug: * Detected change in 'C:\\ProgramData\\Anaconda3\\Lib\\site-packages\\pyparsing\\core.py', reloading
INFO:werkzeug: * Detected change in 'C:\\ProgramData\\Anaconda3\\Lib\\site-packages\\pyparsing\\core.py', reloading
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawl_and_insert_data" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 569-178-434
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawl_and_insert_data" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 569-178-434
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:40:16 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 269, in crawl_and_insert_data
    title = bs.select('#main-content > article > div:nth-child(1) > h1')[0].text
IndexError: list index out of range
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\i\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawl_and_insert_data" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 569-178-434
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\i\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:40:39 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 269, in crawl_and_insert_data
    title = bs.select('#main-content > article > div:nth-child(1) > h1')[0].text
IndexError: list index out of range
INFO:WDM:====== WebDriver manager ======
INFO:WDM:====== WebDriver manager ======
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:40:56 KST)" (scheduled at 2025-01-16 10:39:56.783521+09:00)
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawl_and_insert_data" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
INFO:werkzeug:[33mPress CTRL+C to quit[0m
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:41:03 KST)" (scheduled at 2025-01-16 10:40:03.303167+09:00)
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\i\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\i\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawl_and_insert_data" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawl_and_insert_data" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 569-178-434
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 569-178-434
INFO:WDM:====== WebDriver manager ======
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:41:07 KST)" (scheduled at 2025-01-16 10:40:07.688460+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:41:03 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 269, in crawl_and_insert_data
    title = bs.select('#main-content > article > div:nth-child(1) > h1')[0].text
IndexError: list index out of range
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:40:56 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 269, in crawl_and_insert_data
    title = bs.select('#main-content > article > div:nth-child(1) > h1')[0].text
IndexError: list index out of range
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:41:16 KST)" (scheduled at 2025-01-16 10:40:16.229134+09:00)
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\i\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:41:16 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 269, in crawl_and_insert_data
    title = bs.select('#main-content > article > div:nth-child(1) > h1')[0].text
IndexError: list index out of range
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawl_and_insert_data" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 569-178-434
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:41:07 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 269, in crawl_and_insert_data
    title = bs.select('#main-content > article > div:nth-child(1) > h1')[0].text
IndexError: list index out of range
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:41:39 KST)" (scheduled at 2025-01-16 10:40:39.743394+09:00)
INFO:werkzeug: * Detected change in 'C:\\kd\\ws_java\\team4_v2sbm3c\\src\\main\\python\\exc_2.py', reloading
INFO:werkzeug: * Detected change in 'C:\\kd\\ws_java\\team4_v2sbm3c\\src\\main\\python\\exc_2.py', reloading
INFO:werkzeug: * Detected change in 'C:\\kd\\ws_java\\team4_v2sbm3c\\src\\main\\python\\exc_2.py', reloading
INFO:werkzeug: * Detected change in 'C:\\kd\\ws_java\\team4_v2sbm3c\\src\\main\\python\\exc_2.py', reloading
INFO:werkzeug: * Detected change in 'C:\\kd\\ws_java\\team4_v2sbm3c\\src\\main\\python\\exc_2.py', reloading
INFO:werkzeug: * Detected change in 'C:\\kd\\ws_java\\team4_v2sbm3c\\src\\main\\python\\exc_2.py', reloading
INFO:werkzeug: * Detected change in 'C:\\kd\\ws_java\\team4_v2sbm3c\\src\\main\\python\\exc_2.py', reloading
INFO:werkzeug: * Detected change in 'C:\\kd\\ws_java\\team4_v2sbm3c\\src\\main\\python\\exc_2.py', reloading
INFO:werkzeug: * Detected change in 'C:\\kd\\ws_java\\team4_v2sbm3c\\src\\main\\python\\exc_2.py', reloading
INFO:werkzeug: * Detected change in 'C:\\kd\\ws_java\\team4_v2sbm3c\\src\\main\\python\\exc_2.py', reloading
INFO:werkzeug: * Detected change in 'C:\\kd\\ws_java\\team4_v2sbm3c\\src\\main\\python\\exc_2.py', reloading
INFO:werkzeug: * Detected change in 'C:\\kd\\ws_java\\team4_v2sbm3c\\src\\main\\python\\exc_2.py', reloading
INFO:werkzeug: * Detected change in 'C:\\kd\\ws_java\\team4_v2sbm3c\\src\\main\\python\\exc_2.py', reloading
INFO:werkzeug: * Detected change in 'C:\\kd\\ws_java\\team4_v2sbm3c\\src\\main\\python\\exc_2.py', reloading
INFO:werkzeug: * Detected change in 'C:\\kd\\ws_java\\team4_v2sbm3c\\src\\main\\python\\exc_2.py', reloading
INFO:werkzeug: * Detected change in 'C:\\kd\\ws_java\\team4_v2sbm3c\\src\\main\\python\\exc_2.py', reloading
INFO:werkzeug: * Detected change in 'C:\\kd\\ws_java\\team4_v2sbm3c\\src\\main\\python\\exc_2.py', reloading
INFO:werkzeug: * Detected change in 'C:\\kd\\ws_java\\team4_v2sbm3c\\src\\main\\python\\exc_2.py', reloading
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:41:56 KST)" (scheduled at 2025-01-16 10:40:56.783521+09:00)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:40:58 KST)" (scheduled at 2025-01-16 10:40:58.559293+09:00)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:42:03 KST)" (scheduled at 2025-01-16 10:41:03.303167+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:====== WebDriver manager ======
INFO:WDM:====== WebDriver manager ======
INFO:WDM:====== WebDriver manager ======
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:42:07 KST)" (scheduled at 2025-01-16 10:41:07.688460+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:====== WebDriver manager ======
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:42:16 KST)" (scheduled at 2025-01-16 10:41:16.229134+09:00)
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\i\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\i\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:41:39 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 269, in crawl_and_insert_data
    title = bs.select('#main-content > article > div:nth-child(1) > h1')[0].text
IndexError: list index out of range
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\i\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawl_and_insert_data" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawl_and_insert_data" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 569-178-434
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 569-178-434
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawl_and_insert_data" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\i\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 569-178-434
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\i\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\i\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawl_and_insert_data" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 569-178-434
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:42:39 KST)" (scheduled at 2025-01-16 10:41:39.743394+09:00)
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawl_and_insert_data" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawl_and_insert_data" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 569-178-434
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 569-178-434
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:41:58 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 269, in crawl_and_insert_data
    title = bs.select('#main-content > article > div:nth-child(1) > h1')[0].text
IndexError: list index out of range
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:42:16 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 269, in crawl_and_insert_data
    title = bs.select('#main-content > article > div:nth-child(1) > h1')[0].text
IndexError: list index out of range
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:41:56 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 269, in crawl_and_insert_data
    title = bs.select('#main-content > article > div:nth-child(1) > h1')[0].text
IndexError: list index out of range
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:42:07 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 269, in crawl_and_insert_data
    title = bs.select('#main-content > article > div:nth-child(1) > h1')[0].text
IndexError: list index out of range
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:42:03 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 269, in crawl_and_insert_data
    title = bs.select('#main-content > article > div:nth-child(1) > h1')[0].text
IndexError: list index out of range
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:42:39 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 269, in crawl_and_insert_data
    title = bs.select('#main-content > article > div:nth-child(1) > h1')[0].text
IndexError: list index out of range
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:42:56 KST)" (scheduled at 2025-01-16 10:41:56.783521+09:00)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:42:58 KST)" (scheduled at 2025-01-16 10:41:58.559293+09:00)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:43:03 KST)" (scheduled at 2025-01-16 10:42:03.303167+09:00)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:43:07 KST)" (scheduled at 2025-01-16 10:42:07.688460+09:00)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:43:16 KST)" (scheduled at 2025-01-16 10:42:16.229134+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:42:58 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 269, in crawl_and_insert_data
    title = bs.select('#main-content > article > div:nth-child(1) > h1')[0].text
IndexError: list index out of range
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:42:56 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 269, in crawl_and_insert_data
    title = bs.select('#main-content > article > div:nth-child(1) > h1')[0].text
IndexError: list index out of range
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:43:07 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 269, in crawl_and_insert_data
    title = bs.select('#main-content > article > div:nth-child(1) > h1')[0].text
IndexError: list index out of range
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:43:31 KST)" (scheduled at 2025-01-16 10:42:31.878719+09:00)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:42:32 KST)" (scheduled at 2025-01-16 10:42:32.049722+09:00)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:42:32 KST)" (scheduled at 2025-01-16 10:42:32.297718+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:43:03 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 269, in crawl_and_insert_data
    title = bs.select('#main-content > article > div:nth-child(1) > h1')[0].text
IndexError: list index out of range
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:43:39 KST)" (scheduled at 2025-01-16 10:42:39.743394+09:00)
WARNING:apscheduler.executors.default:Run time of job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:42:38 KST)" was missed by 0:00:01.007003
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:42:42 KST)" (scheduled at 2025-01-16 10:42:42.583727+09:00)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:42:42 KST)" (scheduled at 2025-01-16 10:42:42.597720+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:43:16 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 269, in crawl_and_insert_data
    title = bs.select('#main-content > article > div:nth-child(1) > h1')[0].text
IndexError: list index out of range
INFO:werkzeug: * Detected change in 'C:\\kd\\ws_java\\team4_v2sbm3c\\src\\main\\python\\crawling.py', reloading
INFO:werkzeug: * Detected change in 'C:\\kd\\ws_java\\team4_v2sbm3c\\src\\main\\python\\crawling.py', reloading
INFO:werkzeug: * Detected change in 'C:\\kd\\ws_java\\team4_v2sbm3c\\src\\main\\python\\crawling.py', reloading
INFO:werkzeug: * Detected change in 'C:\\kd\\ws_java\\team4_v2sbm3c\\src\\main\\python\\crawling.py', reloading
INFO:werkzeug: * Detected change in 'C:\\kd\\ws_java\\team4_v2sbm3c\\src\\main\\python\\crawling.py', reloading
INFO:werkzeug: * Detected change in 'C:\\kd\\ws_java\\team4_v2sbm3c\\src\\main\\python\\crawling.py', reloading
INFO:werkzeug: * Detected change in 'C:\\Users\\i\\AppData\\Roaming\\Python\\Python310\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py', reloading
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:43:32 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 126, in crawl_and_insert_data
    url = driver.current_url.strip()
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 437, in current_url
    return self.execute(Command.GET_CURRENT_URL)["value"]
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.InvalidSessionIdException: Message: invalid session id
Stacktrace:
	GetHandleVerifier [0x00B3FD53+23747]
	(No symbol) [0x00AC7D54]
	(No symbol) [0x0099BCCD]
	(No symbol) [0x009D32CB]
	(No symbol) [0x00A01C6A]
	(No symbol) [0x009FD764]
	(No symbol) [0x009FCD01]
	(No symbol) [0x00973A3D]
	(No symbol) [0x00973F8E]
	(No symbol) [0x0097455D]
	GetHandleVerifier [0x00E1AC73+3017699]
	GetHandleVerifier [0x00E2B93B+3086507]
	GetHandleVerifier [0x00E240F2+3055714]
	GetHandleVerifier [0x00BD5AF0+637536]
	(No symbol) [0x00AD0A5D]
	(No symbol) [0x009736F8]
	(No symbol) [0x00972E62]
	GetHandleVerifier [0x00E7E41C+3425164]
	BaseThreadInitThunk [0x7572FCC9+25]
	RtlGetAppContainerNamedObjectPath [0x778A809E+286]
	RtlGetAppContainerNamedObjectPath [0x778A806E+238]

INFO:werkzeug: * Detected change in 'C:\\Users\\i\\AppData\\Roaming\\Python\\Python310\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py', reloading
INFO:werkzeug: * Detected change in 'C:\\Users\\i\\AppData\\Roaming\\Python\\Python310\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py', reloading
INFO:werkzeug: * Detected change in 'C:\\Users\\i\\AppData\\Roaming\\Python\\Python310\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py', reloading
INFO:werkzeug: * Detected change in 'C:\\Users\\i\\AppData\\Roaming\\Python\\Python310\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py', reloading
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:43:56 KST)" (scheduled at 2025-01-16 10:42:56.783521+09:00)
INFO:werkzeug: * Detected change in 'C:\\ProgramData\\Anaconda3\\Lib\\subprocess.py', reloading
INFO:werkzeug: * Detected change in 'C:\\ProgramData\\Anaconda3\\Lib\\subprocess.py', reloading
INFO:werkzeug: * Detected change in 'C:\\ProgramData\\Anaconda3\\Lib\\subprocess.py', reloading
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:43:58 KST)" (scheduled at 2025-01-16 10:42:58.559293+09:00)
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:44:03 KST)" (scheduled at 2025-01-16 10:43:03.303167+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:====== WebDriver manager ======
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:44:07 KST)" (scheduled at 2025-01-16 10:43:07.688460+09:00)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:44:16 KST)" (scheduled at 2025-01-16 10:43:16.229134+09:00)
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\i\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\i\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:43:31 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 269, in crawl_and_insert_data
    title = bs.select('#main-content > article > div:nth-child(1) > h1')[0].text
IndexError: list index out of range
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:44:03 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 269, in crawl_and_insert_data
    title = bs.select('#main-content > article > div:nth-child(1) > h1')[0].text
IndexError: list index out of range
INFO:werkzeug: * Restarting with watchdog (windowsapi)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:44:07 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 269, in crawl_and_insert_data
    title = bs.select('#main-content > article > div:nth-child(1) > h1')[0].text
IndexError: list index out of range
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawl_and_insert_data" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 569-178-434
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawl_and_insert_data" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 569-178-434
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:44:16 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 269, in crawl_and_insert_data
    title = bs.select('#main-content > article > div:nth-child(1) > h1')[0].text
IndexError: list index out of range
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:43:39 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 269, in crawl_and_insert_data
    title = bs.select('#main-content > article > div:nth-child(1) > h1')[0].text
IndexError: list index out of range
WARNING:apscheduler.scheduler:Execution of job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:43:32 KST)" skipped: maximum number of running instances reached (1)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:43:42 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 269, in crawl_and_insert_data
    title = bs.select('#main-content > article > div:nth-child(1) > h1')[0].text
IndexError: list index out of range
INFO:WDM:====== WebDriver manager ======
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:43:42 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 269, in crawl_and_insert_data
    title = bs.select('#main-content > article > div:nth-child(1) > h1')[0].text
IndexError: list index out of range
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:44:32 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 126, in crawl_and_insert_data
    url = driver.current_url.strip()
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 437, in current_url
    return self.execute(Command.GET_CURRENT_URL)["value"]
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: disconnected: not connected to DevTools
  (failed to check if window was closed: disconnected: not connected to DevTools)
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x00B3FD53+23747]
	(No symbol) [0x00AC7D54]
	(No symbol) [0x0099BE53]
	(No symbol) [0x0098C408]
	(No symbol) [0x0098C329]
	(No symbol) [0x0099E2E0]
	(No symbol) [0x00A1AD69]
	(No symbol) [0x00A01B96]
	(No symbol) [0x009D3F3C]
	(No symbol) [0x009D4EBD]
	GetHandleVerifier [0x00E1AC73+3017699]
	GetHandleVerifier [0x00E2B93B+3086507]
	GetHandleVerifier [0x00E240F2+3055714]
	GetHandleVerifier [0x00BD5AF0+637536]
	(No symbol) [0x00AD0A5D]
	(No symbol) [0x00ACDA28]
	(No symbol) [0x00ACDBC5]
	(No symbol) [0x00AC07F0]
	BaseThreadInitThunk [0x7572FCC9+25]
	RtlGetAppContainerNamedObjectPath [0x778A809E+286]
	RtlGetAppContainerNamedObjectPath [0x778A806E+238]

INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:44:39 KST)" (scheduled at 2025-01-16 10:43:39.743394+09:00)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\i\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:WDM:====== WebDriver manager ======
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawl_and_insert_data" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 569-178-434
INFO:WDM:====== WebDriver manager ======
WARNING:apscheduler.scheduler:Execution of job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:43:56 KST)" skipped: maximum number of running instances reached (1)
INFO:WDM:====== WebDriver manager ======
WARNING:apscheduler.scheduler:Execution of job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:43:58 KST)" skipped: maximum number of running instances reached (1)
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\i\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:45:03 KST)" (scheduled at 2025-01-16 10:44:03.303167+09:00)
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\i\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:45:07 KST)" (scheduled at 2025-01-16 10:44:07.688460+09:00)
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\i\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawl_and_insert_data" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 569-178-434
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawl_and_insert_data" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 569-178-434
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:44:39 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 269, in crawl_and_insert_data
    title = bs.select('#main-content > article > div:nth-child(1) > h1')[0].text
IndexError: list index out of range
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:45:16 KST)" (scheduled at 2025-01-16 10:44:16.229134+09:00)
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawl_and_insert_data" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 569-178-434
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:44:58 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 269, in crawl_and_insert_data
    title = bs.select('#main-content > article > div:nth-child(1) > h1')[0].text
IndexError: list index out of range
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:45:07 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 269, in crawl_and_insert_data
    title = bs.select('#main-content > article > div:nth-child(1) > h1')[0].text
IndexError: list index out of range
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:45:16 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 269, in crawl_and_insert_data
    title = bs.select('#main-content > article > div:nth-child(1) > h1')[0].text
IndexError: list index out of range
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:45:03 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 269, in crawl_and_insert_data
    title = bs.select('#main-content > article > div:nth-child(1) > h1')[0].text
IndexError: list index out of range
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:44:24 KST)" (scheduled at 2025-01-16 10:44:24.697726+09:00)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:44:24 KST)" (scheduled at 2025-01-16 10:44:24.733724+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:44:56 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 269, in crawl_and_insert_data
    title = bs.select('#main-content > article > div:nth-child(1) > h1')[0].text
IndexError: list index out of range
INFO:werkzeug: * Detected change in 'C:\\Users\\i\\AppData\\Roaming\\Python\\Python310\\site-packages\\apscheduler\\executors\\base.py', reloading
INFO:werkzeug: * Detected change in 'C:\\Users\\i\\AppData\\Roaming\\Python\\Python310\\site-packages\\apscheduler\\executors\\base.py', reloading
INFO:werkzeug: * Detected change in 'C:\\Users\\i\\AppData\\Roaming\\Python\\Python310\\site-packages\\apscheduler\\executors\\base.py', reloading
INFO:werkzeug: * Detected change in 'C:\\Users\\i\\AppData\\Roaming\\Python\\Python310\\site-packages\\apscheduler\\executors\\base.py', reloading
INFO:werkzeug: * Detected change in 'C:\\Users\\i\\AppData\\Roaming\\Python\\Python310\\site-packages\\apscheduler\\executors\\base.py', reloading
INFO:werkzeug: * Detected change in 'C:\\Users\\i\\AppData\\Roaming\\Python\\Python310\\site-packages\\apscheduler\\executors\\base.py', reloading
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:45:24 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 269, in crawl_and_insert_data
    title = bs.select('#main-content > article > div:nth-child(1) > h1')[0].text
IndexError: list index out of range
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:45:39 KST)" (scheduled at 2025-01-16 10:44:39.743394+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:45:24 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 269, in crawl_and_insert_data
    title = bs.select('#main-content > article > div:nth-child(1) > h1')[0].text
IndexError: list index out of range
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:45:56 KST)" (scheduled at 2025-01-16 10:44:56.783521+09:00)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:45:58 KST)" (scheduled at 2025-01-16 10:44:58.559293+09:00)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:46:03 KST)" (scheduled at 2025-01-16 10:45:03.303167+09:00)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:46:07 KST)" (scheduled at 2025-01-16 10:45:07.688460+09:00)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:46:16 KST)" (scheduled at 2025-01-16 10:45:16.229134+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
WARNING:apscheduler.scheduler:Execution of job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:45:39 KST)" skipped: maximum number of running instances reached (1)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:====== WebDriver manager ======
INFO:WDM:====== WebDriver manager ======
INFO:WDM:====== WebDriver manager ======
INFO:WDM:====== WebDriver manager ======
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:46:07 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 269, in crawl_and_insert_data
    title = bs.select('#main-content > article > div:nth-child(1) > h1')[0].text
IndexError: list index out of range
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:46:39 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 269, in crawl_and_insert_data
    title = bs.select('#main-content > article > div:nth-child(1) > h1')[0].text
IndexError: list index out of range
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:45:58 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 269, in crawl_and_insert_data
    title = bs.select('#main-content > article > div:nth-child(1) > h1')[0].text
IndexError: list index out of range
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:46:03 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 269, in crawl_and_insert_data
    title = bs.select('#main-content > article > div:nth-child(1) > h1')[0].text
IndexError: list index out of range
WARNING:apscheduler.scheduler:Execution of job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:45:56 KST)" skipped: maximum number of running instances reached (1)
INFO:WDM:====== WebDriver manager ======
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:46:58 KST)" (scheduled at 2025-01-16 10:45:58.559293+09:00)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:47:03 KST)" (scheduled at 2025-01-16 10:46:03.303167+09:00)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:47:07 KST)" (scheduled at 2025-01-16 10:46:07.688460+09:00)
WARNING:apscheduler.scheduler:Execution of job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:46:16 KST)" skipped: maximum number of running instances reached (1)
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\i\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\i\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\i\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\i\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\i\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\i\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:47:39 KST)" (scheduled at 2025-01-16 10:46:39.743394+09:00)
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawl_and_insert_data" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawl_and_insert_data" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 569-178-434
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 569-178-434
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawl_and_insert_data" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawl_and_insert_data" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 569-178-434
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 569-178-434
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:47:16 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 269, in crawl_and_insert_data
    title = bs.select('#main-content > article > div:nth-child(1) > h1')[0].text
IndexError: list index out of range
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\i\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:47:03 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 269, in crawl_and_insert_data
    title = bs.select('#main-content > article > div:nth-child(1) > h1')[0].text
IndexError: list index out of range
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:47:07 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 269, in crawl_and_insert_data
    title = bs.select('#main-content > article > div:nth-child(1) > h1')[0].text
IndexError: list index out of range
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:46:56 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 269, in crawl_and_insert_data
    title = bs.select('#main-content > article > div:nth-child(1) > h1')[0].text
IndexError: list index out of range
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:47:56 KST)" (scheduled at 2025-01-16 10:46:56.783521+09:00)
WARNING:apscheduler.scheduler:Execution of job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:46:58 KST)" skipped: maximum number of running instances reached (1)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:47:58 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 269, in crawl_and_insert_data
    title = bs.select('#main-content > article > div:nth-child(1) > h1')[0].text
IndexError: list index out of range
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawl_and_insert_data" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
INFO:werkzeug:[33mPress CTRL+C to quit[0m
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:48:03 KST)" (scheduled at 2025-01-16 10:47:03.303167+09:00)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:47:39 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 269, in crawl_and_insert_data
    title = bs.select('#main-content > article > div:nth-child(1) > h1')[0].text
IndexError: list index out of range
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:48:07 KST)" (scheduled at 2025-01-16 10:47:07.688460+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:48:16 KST)" (scheduled at 2025-01-16 10:47:16.229134+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:48:16 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 269, in crawl_and_insert_data
    title = bs.select('#main-content > article > div:nth-child(1) > h1')[0].text
IndexError: list index out of range
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:48:07 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 269, in crawl_and_insert_data
    title = bs.select('#main-content > article > div:nth-child(1) > h1')[0].text
IndexError: list index out of range
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\i\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawl_and_insert_data" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 569-178-434
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:47:56 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 269, in crawl_and_insert_data
    title = bs.select('#main-content > article > div:nth-child(1) > h1')[0].text
IndexError: list index out of range
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:48:03 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 269, in crawl_and_insert_data
    title = bs.select('#main-content > article > div:nth-child(1) > h1')[0].text
IndexError: list index out of range
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:48:39 KST)" (scheduled at 2025-01-16 10:47:39.743394+09:00)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:47:45 KST)" (scheduled at 2025-01-16 10:47:45.578230+09:00)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:47:45 KST)" (scheduled at 2025-01-16 10:47:45.595232+09:00)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:47:46 KST)" (scheduled at 2025-01-16 10:47:46.053228+09:00)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:47:46 KST)" (scheduled at 2025-01-16 10:47:46.069229+09:00)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:48:58 KST)" (scheduled at 2025-01-16 10:47:58.559293+09:00)
WARNING:apscheduler.executors.default:Run time of job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:48:00 KST)" was missed by 0:00:01.596010
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:49:03 KST)" (scheduled at 2025-01-16 10:48:03.303167+09:00)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:49:16 KST)" (scheduled at 2025-01-16 10:48:16.229134+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:48:58 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 269, in crawl_and_insert_data
    title = bs.select('#main-content > article > div:nth-child(1) > h1')[0].text
IndexError: list index out of range
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:49:03 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 269, in crawl_and_insert_data
    title = bs.select('#main-content > article > div:nth-child(1) > h1')[0].text
IndexError: list index out of range
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:48:27 KST)" (scheduled at 2025-01-16 10:48:27.510052+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:48:45 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 269, in crawl_and_insert_data
    title = bs.select('#main-content > article > div:nth-child(1) > h1')[0].text
IndexError: list index out of range
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:48:39 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 269, in crawl_and_insert_data
    title = bs.select('#main-content > article > div:nth-child(1) > h1')[0].text
IndexError: list index out of range
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:49:39 KST)" (scheduled at 2025-01-16 10:48:39.743394+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:48:45 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 126, in crawl_and_insert_data
    url = driver.current_url.strip()
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 437, in current_url
    return self.execute(Command.GET_CURRENT_URL)["value"]
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.InvalidSessionIdException: Message: invalid session id
Stacktrace:
	GetHandleVerifier [0x00B3FD53+23747]
	(No symbol) [0x00AC7D54]
	(No symbol) [0x0099BCCD]
	(No symbol) [0x009D32CB]
	(No symbol) [0x00A01C6A]
	(No symbol) [0x009FD764]
	(No symbol) [0x009FCD01]
	(No symbol) [0x00973A3D]
	(No symbol) [0x00973F8E]
	(No symbol) [0x0097455D]
	GetHandleVerifier [0x00E1AC73+3017699]
	GetHandleVerifier [0x00E2B93B+3086507]
	GetHandleVerifier [0x00E240F2+3055714]
	GetHandleVerifier [0x00BD5AF0+637536]
	(No symbol) [0x00AD0A5D]
	(No symbol) [0x009736F8]
	(No symbol) [0x00972E62]
	GetHandleVerifier [0x00E7E41C+3425164]
	BaseThreadInitThunk [0x7572FCC9+25]
	RtlGetAppContainerNamedObjectPath [0x778A809E+286]
	RtlGetAppContainerNamedObjectPath [0x778A806E+238]

INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:49:45 KST)" (scheduled at 2025-01-16 10:48:45.578230+09:00)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:49:45 KST)" (scheduled at 2025-01-16 10:48:45.595232+09:00)
WARNING:apscheduler.scheduler:Execution of job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:48:46 KST)" skipped: maximum number of running instances reached (1)
WARNING:apscheduler.scheduler:Execution of job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:48:46 KST)" skipped: maximum number of running instances reached (1)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:49:45 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.InvalidSessionIdException: Message: invalid session id
Stacktrace:
	GetHandleVerifier [0x00B3FD53+23747]
	(No symbol) [0x00AC7D54]
	(No symbol) [0x0099BCCD]
	(No symbol) [0x009D32CB]
	(No symbol) [0x00A01C6A]
	(No symbol) [0x009FD764]
	(No symbol) [0x009FCD01]
	(No symbol) [0x00973A3D]
	(No symbol) [0x00973F8E]
	(No symbol) [0x0097455D]
	GetHandleVerifier [0x00E1AC73+3017699]
	GetHandleVerifier [0x00E2B93B+3086507]
	GetHandleVerifier [0x00E240F2+3055714]
	GetHandleVerifier [0x00BD5AF0+637536]
	(No symbol) [0x00AD0A5D]
	(No symbol) [0x009736F8]
	(No symbol) [0x00972E62]
	GetHandleVerifier [0x00E7E41C+3425164]
	BaseThreadInitThunk [0x7572FCC9+25]
	RtlGetAppContainerNamedObjectPath [0x778A809E+286]
	RtlGetAppContainerNamedObjectPath [0x778A806E+238]

INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:49:58 KST)" (scheduled at 2025-01-16 10:48:58.559293+09:00)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:50:00 KST)" (scheduled at 2025-01-16 10:49:00.109054+09:00)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:50:03 KST)" (scheduled at 2025-01-16 10:49:03.303167+09:00)
WARNING:apscheduler.scheduler:Execution of job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:49:16 KST)" skipped: maximum number of running instances reached (1)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:49:27 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 269, in crawl_and_insert_data
    title = bs.select('#main-content > article > div:nth-child(1) > h1')[0].text
IndexError: list index out of range
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:50:27 KST)" (scheduled at 2025-01-16 10:49:27.510052+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:50:16 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 269, in crawl_and_insert_data
    title = bs.select('#main-content > article > div:nth-child(1) > h1')[0].text
IndexError: list index out of range
WARNING:apscheduler.scheduler:Execution of job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:49:39 KST)" skipped: maximum number of running instances reached (1)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\i\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawl_and_insert_data" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
INFO:werkzeug:[33mPress CTRL+C to quit[0m
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\i\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawl_and_insert_data" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 569-178-434
INFO:werkzeug: * Detected change in 'C:\\kd\\ws_java\\team4_v2sbm3c\\src\\main\\python\\exc_2.py', reloading
INFO:werkzeug: * Detected change in 'C:\\kd\\ws_java\\team4_v2sbm3c\\src\\main\\python\\exc_2.py', reloading
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 11:13:02 KST)" (scheduled at 2025-01-16 11:13:02.628076+09:00)
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\i\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawl_and_insert_data" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 569-178-434
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 11:14:02 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 302, in crawl_and_insert_data
    print(p_tag.text.strip())
UnicodeEncodeError: 'cp949' codec can't encode character '\u2013' in position 185: illegal multibyte sequence
INFO:werkzeug: * Detected change in 'C:\\kd\\ws_java\\team4_v2sbm3c\\src\\main\\python\\exc_2.py', reloading
INFO:werkzeug: * Detected change in 'C:\\kd\\ws_java\\team4_v2sbm3c\\src\\main\\python\\exc_2.py', reloading
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\i\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
<<<<<<< HEAD
INFO:WDM:====== WebDriver manager ======
INFO:WDM:====== WebDriver manager ======
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:11:48 KST)" (scheduled at 2025-01-15 17:10:48.987824+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:11:07 KST)" executed successfully
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000179F82A3E80>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/6052896cbb80a7be4e12ca11c240f513/element
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
=======
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawl_and_insert_data" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 569-178-434
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 11:15:02 KST)" (scheduled at 2025-01-16 11:14:02.628076+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 11:15:02 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchWindowException: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x00B3FD53+23747]
	(No symbol) [0x00AC7D54]
	(No symbol) [0x0099BE53]
	(No symbol) [0x0097D91B]
	(No symbol) [0x00A07EFF]
	(No symbol) [0x00A1AD49]
	(No symbol) [0x00A01B96]
	(No symbol) [0x009D3F3C]
	(No symbol) [0x009D4EBD]
	GetHandleVerifier [0x00E1AC73+3017699]
	GetHandleVerifier [0x00E2B93B+3086507]
	GetHandleVerifier [0x00E240F2+3055714]
	GetHandleVerifier [0x00BD5AF0+637536]
	(No symbol) [0x00AD0A5D]
	(No symbol) [0x00ACDA28]
	(No symbol) [0x00ACDBC5]
	(No symbol) [0x00AC07F0]
	BaseThreadInitThunk [0x7572FCC9+25]
	RtlGetAppContainerNamedObjectPath [0x778A809E+286]
	RtlGetAppContainerNamedObjectPath [0x778A806E+238]

INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 11:14:32 KST)" (scheduled at 2025-01-16 11:14:32.339041+09:00)
<<<<<<< HEAD
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\i\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawl_and_insert_data" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
INFO:werkzeug:[33mPress CTRL+C to quit[0m
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\i\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawl_and_insert_data" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 569-178-434
INFO:werkzeug: * Detected change in 'C:\\kd\\ws_java\\team4_v2sbm3c\\src\\main\\python\\pernews.py', reloading
INFO:werkzeug: * Detected change in 'C:\\kd\\ws_java\\team4_v2sbm3c\\src\\main\\python\\exc_2.py', reloading
INFO:werkzeug: * Detected change in 'C:\\kd\\ws_java\\team4_v2sbm3c\\src\\main\\python\\exc.py', reloading
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\i\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawl_and_insert_data" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 569-178-434
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 16:11:46 KST)" (scheduled at 2025-01-16 16:11:46.855485+09:00)
INFO:werkzeug: * Detected change in 'C:\\Users\\i\\AppData\\Roaming\\Python\\Python310\\site-packages\\apscheduler\\executors\\base.py', reloading
INFO:werkzeug: * Detected change in 'C:\\Users\\i\\AppData\\Roaming\\Python\\Python310\\site-packages\\selenium\\webdriver\\remote\\webdriver.py', reloading
INFO:werkzeug: * Detected change in 'C:\\Users\\i\\AppData\\Roaming\\Python\\Python310\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py', reloading
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 16:12:46 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchWindowException: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x00B4FD53+23747]
	(No symbol) [0x00AD7D54]
	(No symbol) [0x009ABE53]
	(No symbol) [0x0098D91B]
	(No symbol) [0x00A17EFF]
	(No symbol) [0x00A2AD49]
	(No symbol) [0x00A11B96]
	(No symbol) [0x009E3F3C]
	(No symbol) [0x009E4EBD]
	GetHandleVerifier [0x00E2AC73+3017699]
	GetHandleVerifier [0x00E3B93B+3086507]
	GetHandleVerifier [0x00E340F2+3055714]
	GetHandleVerifier [0x00BE5AF0+637536]
	(No symbol) [0x00AE0A5D]
	(No symbol) [0x00ADDA28]
	(No symbol) [0x00ADDBC5]
	(No symbol) [0x00AD07F0]
	BaseThreadInitThunk [0x771BFCC9+25]
	RtlGetAppContainerNamedObjectPath [0x77DD809E+286]
	RtlGetAppContainerNamedObjectPath [0x77DD806E+238]

INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\i\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawl_and_insert_data" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 569-178-434
=======
>>>>>>> 5d76b10881f91ca0642cbb910c314941850318f1
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
>>>>>>> e4a3bb73634b33b8c8e529ff3d0b22b9f44556ca
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\i\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawl_and_insert_data" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
INFO:werkzeug:[33mPress CTRL+C to quit[0m
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\i\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawl_and_insert_data" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 569-178-434
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 16:58:43 KST)" (scheduled at 2025-01-16 16:58:43.292697+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 16:59:43 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchWindowException: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x00B4FD53+23747]
	(No symbol) [0x00AD7D54]
	(No symbol) [0x009ABE53]
	(No symbol) [0x0098D91B]
	(No symbol) [0x00A17EFF]
	(No symbol) [0x00A2AD49]
	(No symbol) [0x00A11B96]
	(No symbol) [0x009E3F3C]
	(No symbol) [0x009E4EBD]
	GetHandleVerifier [0x00E2AC73+3017699]
	GetHandleVerifier [0x00E3B93B+3086507]
	GetHandleVerifier [0x00E340F2+3055714]
	GetHandleVerifier [0x00BE5AF0+637536]
	(No symbol) [0x00AE0A5D]
	(No symbol) [0x00ADDA28]
	(No symbol) [0x00ADDBC5]
	(No symbol) [0x00AD07F0]
	BaseThreadInitThunk [0x771BFCC9+25]
	RtlGetAppContainerNamedObjectPath [0x77DD809E+286]
	RtlGetAppContainerNamedObjectPath [0x77DD806E+238]

INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\i\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawl_and_insert_data" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
INFO:werkzeug:[33mPress CTRL+C to quit[0m
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 16:58:48 KST)" (scheduled at 2025-01-16 16:58:48.547344+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 16:59:48 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchWindowException: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x00B4FD53+23747]
	(No symbol) [0x00AD7D54]
	(No symbol) [0x009ABE53]
	(No symbol) [0x0098D91B]
	(No symbol) [0x00A17EFF]
	(No symbol) [0x00A2AD49]
	(No symbol) [0x00A11B96]
	(No symbol) [0x009E3F3C]
	(No symbol) [0x009E4EBD]
	GetHandleVerifier [0x00E2AC73+3017699]
	GetHandleVerifier [0x00E3B93B+3086507]
	GetHandleVerifier [0x00E340F2+3055714]
	GetHandleVerifier [0x00BE5AF0+637536]
	(No symbol) [0x00AE0A5D]
	(No symbol) [0x00ADDA28]
	(No symbol) [0x00ADDBC5]
	(No symbol) [0x00AD07F0]
	BaseThreadInitThunk [0x771BFCC9+25]
	RtlGetAppContainerNamedObjectPath [0x77DD809E+286]
	RtlGetAppContainerNamedObjectPath [0x77DD806E+238]

INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\i\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawl_and_insert_data" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 569-178-434
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 17:00:43 KST)" (scheduled at 2025-01-16 16:59:43.292697+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 17:00:43 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchWindowException: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x00B4FD53+23747]
	(No symbol) [0x00AD7D54]
	(No symbol) [0x009ABE53]
	(No symbol) [0x0098D91B]
	(No symbol) [0x00A17EFF]
	(No symbol) [0x00A2AD49]
	(No symbol) [0x00A11B96]
	(No symbol) [0x009E3F3C]
	(No symbol) [0x009E4EBD]
	GetHandleVerifier [0x00E2AC73+3017699]
	GetHandleVerifier [0x00E3B93B+3086507]
	GetHandleVerifier [0x00E340F2+3055714]
	GetHandleVerifier [0x00BE5AF0+637536]
	(No symbol) [0x00AE0A5D]
	(No symbol) [0x00ADDA28]
	(No symbol) [0x00ADDBC5]
	(No symbol) [0x00AD07F0]
	BaseThreadInitThunk [0x771BFCC9+25]
	RtlGetAppContainerNamedObjectPath [0x77DD809E+286]
	RtlGetAppContainerNamedObjectPath [0x77DD806E+238]

INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 16:59:48 KST)" (scheduled at 2025-01-16 16:59:48.014593+09:00)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 17:00:48 KST)" (scheduled at 2025-01-16 16:59:48.547344+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 17:00:48 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchWindowException: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x00B4FD53+23747]
	(No symbol) [0x00AD7D54]
	(No symbol) [0x009ABE53]
	(No symbol) [0x0098D91B]
	(No symbol) [0x00A17EFF]
	(No symbol) [0x00A2AD49]
	(No symbol) [0x00A11B96]
	(No symbol) [0x009E3F3C]
	(No symbol) [0x009E4EBD]
	GetHandleVerifier [0x00E2AC73+3017699]
	GetHandleVerifier [0x00E3B93B+3086507]
	GetHandleVerifier [0x00E340F2+3055714]
	GetHandleVerifier [0x00BE5AF0+637536]
	(No symbol) [0x00AE0A5D]
	(No symbol) [0x00ADDA28]
	(No symbol) [0x00ADDBC5]
	(No symbol) [0x00AD07F0]
	BaseThreadInitThunk [0x771BFCC9+25]
	RtlGetAppContainerNamedObjectPath [0x77DD809E+286]
	RtlGetAppContainerNamedObjectPath [0x77DD806E+238]

INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 16:59:53 KST)" (scheduled at 2025-01-16 16:59:53.060586+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 17:00:48 KST)" executed successfully
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 17:00:53 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 126, in crawl_and_insert_data
    url = driver.current_url.strip()
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 437, in current_url
    return self.execute(Command.GET_CURRENT_URL)["value"]
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: disconnected: not connected to DevTools
  (failed to check if window was closed: disconnected: not connected to DevTools)
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x00B4FD53+23747]
	(No symbol) [0x00AD7D54]
	(No symbol) [0x009ABE53]
	(No symbol) [0x0099C408]
	(No symbol) [0x0099C329]
	(No symbol) [0x009AE2E0]
	(No symbol) [0x00A2AD69]
	(No symbol) [0x00A11B96]
	(No symbol) [0x009E3F3C]
	(No symbol) [0x009E4EBD]
	GetHandleVerifier [0x00E2AC73+3017699]
	GetHandleVerifier [0x00E3B93B+3086507]
	GetHandleVerifier [0x00E340F2+3055714]
	GetHandleVerifier [0x00BE5AF0+637536]
	(No symbol) [0x00AE0A5D]
	(No symbol) [0x00ADDA28]
	(No symbol) [0x00ADDBC5]
	(No symbol) [0x00AD07F0]
	BaseThreadInitThunk [0x771BFCC9+25]
	RtlGetAppContainerNamedObjectPath [0x77DD809E+286]
	RtlGetAppContainerNamedObjectPath [0x77DD806E+238]

INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 17:01:43 KST)" (scheduled at 2025-01-16 17:00:43.292697+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 17:01:43 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchWindowException: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x00B4FD53+23747]
	(No symbol) [0x00AD7D54]
	(No symbol) [0x009ABE53]
	(No symbol) [0x0098D91B]
	(No symbol) [0x00A17EFF]
	(No symbol) [0x00A2AD49]
	(No symbol) [0x00A11B96]
	(No symbol) [0x009E3F3C]
	(No symbol) [0x009E4EBD]
	GetHandleVerifier [0x00E2AC73+3017699]
	GetHandleVerifier [0x00E3B93B+3086507]
	GetHandleVerifier [0x00E340F2+3055714]
	GetHandleVerifier [0x00BE5AF0+637536]
	(No symbol) [0x00AE0A5D]
	(No symbol) [0x00ADDA28]
	(No symbol) [0x00ADDBC5]
	(No symbol) [0x00AD07F0]
	BaseThreadInitThunk [0x771BFCC9+25]
	RtlGetAppContainerNamedObjectPath [0x77DD809E+286]
	RtlGetAppContainerNamedObjectPath [0x77DD806E+238]

INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 17:01:48 KST)" (scheduled at 2025-01-16 17:00:48.014593+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 17:01:48 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchWindowException: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x00B4FD53+23747]
	(No symbol) [0x00AD7D54]
	(No symbol) [0x009ABE53]
	(No symbol) [0x0098D91B]
	(No symbol) [0x00A17EFF]
	(No symbol) [0x00A2AD49]
	(No symbol) [0x00A11B96]
	(No symbol) [0x009E3F3C]
	(No symbol) [0x009E4EBD]
	GetHandleVerifier [0x00E2AC73+3017699]
	GetHandleVerifier [0x00E3B93B+3086507]
	GetHandleVerifier [0x00E340F2+3055714]
	GetHandleVerifier [0x00BE5AF0+637536]
	(No symbol) [0x00AE0A5D]
	(No symbol) [0x00ADDA28]
	(No symbol) [0x00ADDBC5]
	(No symbol) [0x00AD07F0]
	BaseThreadInitThunk [0x771BFCC9+25]
	RtlGetAppContainerNamedObjectPath [0x77DD809E+286]
	RtlGetAppContainerNamedObjectPath [0x77DD806E+238]

INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 17:01:48 KST)" (scheduled at 2025-01-16 17:00:48.547344+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 17:01:48 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchWindowException: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x00B4FD53+23747]
	(No symbol) [0x00AD7D54]
	(No symbol) [0x009ABE53]
	(No symbol) [0x0098D91B]
	(No symbol) [0x00A17EFF]
	(No symbol) [0x00A2AD49]
	(No symbol) [0x00A11B96]
	(No symbol) [0x009E3F3C]
	(No symbol) [0x009E4EBD]
	GetHandleVerifier [0x00E2AC73+3017699]
	GetHandleVerifier [0x00E3B93B+3086507]
	GetHandleVerifier [0x00E340F2+3055714]
	GetHandleVerifier [0x00BE5AF0+637536]
	(No symbol) [0x00AE0A5D]
	(No symbol) [0x00ADDA28]
	(No symbol) [0x00ADDBC5]
	(No symbol) [0x00AD07F0]
	BaseThreadInitThunk [0x771BFCC9+25]
	RtlGetAppContainerNamedObjectPath [0x77DD809E+286]
	RtlGetAppContainerNamedObjectPath [0x77DD806E+238]

INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 17:01:53 KST)" (scheduled at 2025-01-16 17:00:53.060586+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 17:01:53 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: disconnected: not connected to DevTools
  (failed to check if window was closed: disconnected: not connected to DevTools)
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x00B4FD53+23747]
	(No symbol) [0x00AD7D54]
	(No symbol) [0x009ABE53]
	(No symbol) [0x0099C408]
	(No symbol) [0x0099C329]
	(No symbol) [0x009AE2E0]
	(No symbol) [0x00A2AD69]
	(No symbol) [0x00A11B96]
	(No symbol) [0x009E3F3C]
	(No symbol) [0x009E4EBD]
	GetHandleVerifier [0x00E2AC73+3017699]
	GetHandleVerifier [0x00E3B93B+3086507]
	GetHandleVerifier [0x00E340F2+3055714]
	GetHandleVerifier [0x00BE5AF0+637536]
	(No symbol) [0x00AE0A5D]
	(No symbol) [0x00ADDA28]
	(No symbol) [0x00ADDBC5]
	(No symbol) [0x00AD07F0]
	BaseThreadInitThunk [0x771BFCC9+25]
	RtlGetAppContainerNamedObjectPath [0x77DD809E+286]
	RtlGetAppContainerNamedObjectPath [0x77DD806E+238]

INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 17:02:43 KST)" (scheduled at 2025-01-16 17:01:43.292697+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 17:02:43 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchWindowException: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x00B4FD53+23747]
	(No symbol) [0x00AD7D54]
	(No symbol) [0x009ABE53]
	(No symbol) [0x0098D91B]
	(No symbol) [0x00A17EFF]
	(No symbol) [0x00A2AD49]
	(No symbol) [0x00A11B96]
	(No symbol) [0x009E3F3C]
	(No symbol) [0x009E4EBD]
	GetHandleVerifier [0x00E2AC73+3017699]
	GetHandleVerifier [0x00E3B93B+3086507]
	GetHandleVerifier [0x00E340F2+3055714]
	GetHandleVerifier [0x00BE5AF0+637536]
	(No symbol) [0x00AE0A5D]
	(No symbol) [0x00ADDA28]
	(No symbol) [0x00ADDBC5]
	(No symbol) [0x00AD07F0]
	BaseThreadInitThunk [0x771BFCC9+25]
	RtlGetAppContainerNamedObjectPath [0x77DD809E+286]
	RtlGetAppContainerNamedObjectPath [0x77DD806E+238]

INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\i\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawl_and_insert_data" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
INFO:werkzeug:[33mPress CTRL+C to quit[0m
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 17:01:48 KST)" (scheduled at 2025-01-16 17:01:48.014593+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 17:02:48 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchWindowException: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x00B4FD53+23747]
	(No symbol) [0x00AD7D54]
	(No symbol) [0x009ABE53]
	(No symbol) [0x0098D91B]
	(No symbol) [0x00A17EFF]
	(No symbol) [0x00A2AD49]
	(No symbol) [0x00A11B96]
	(No symbol) [0x009E3F3C]
	(No symbol) [0x009E4EBD]
	GetHandleVerifier [0x00E2AC73+3017699]
	GetHandleVerifier [0x00E3B93B+3086507]
	GetHandleVerifier [0x00E340F2+3055714]
	GetHandleVerifier [0x00BE5AF0+637536]
	(No symbol) [0x00AE0A5D]
	(No symbol) [0x00ADDA28]
	(No symbol) [0x00ADDBC5]
	(No symbol) [0x00AD07F0]
	BaseThreadInitThunk [0x771BFCC9+25]
	RtlGetAppContainerNamedObjectPath [0x77DD809E+286]
	RtlGetAppContainerNamedObjectPath [0x77DD806E+238]

INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 17:02:48 KST)" (scheduled at 2025-01-16 17:01:48.547344+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 17:02:48 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchWindowException: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x00B4FD53+23747]
	(No symbol) [0x00AD7D54]
	(No symbol) [0x009ABE53]
	(No symbol) [0x0098D91B]
	(No symbol) [0x00A17EFF]
	(No symbol) [0x00A2AD49]
	(No symbol) [0x00A11B96]
	(No symbol) [0x009E3F3C]
	(No symbol) [0x009E4EBD]
	GetHandleVerifier [0x00E2AC73+3017699]
	GetHandleVerifier [0x00E3B93B+3086507]
	GetHandleVerifier [0x00E340F2+3055714]
	GetHandleVerifier [0x00BE5AF0+637536]
	(No symbol) [0x00AE0A5D]
	(No symbol) [0x00ADDA28]
	(No symbol) [0x00ADDBC5]
	(No symbol) [0x00AD07F0]
	BaseThreadInitThunk [0x771BFCC9+25]
	RtlGetAppContainerNamedObjectPath [0x77DD809E+286]
	RtlGetAppContainerNamedObjectPath [0x77DD806E+238]

INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\i\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 17:02:53 KST)" (scheduled at 2025-01-16 17:01:53.060586+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 17:02:53 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: disconnected: not connected to DevTools
  (failed to check if window was closed: disconnected: not connected to DevTools)
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x00B4FD53+23747]
	(No symbol) [0x00AD7D54]
	(No symbol) [0x009ABE53]
	(No symbol) [0x0099C408]
	(No symbol) [0x0099C329]
	(No symbol) [0x009AE2E0]
	(No symbol) [0x00A2AD69]
	(No symbol) [0x00A11B96]
	(No symbol) [0x009E3F3C]
	(No symbol) [0x009E4EBD]
	GetHandleVerifier [0x00E2AC73+3017699]
	GetHandleVerifier [0x00E3B93B+3086507]
	GetHandleVerifier [0x00E340F2+3055714]
	GetHandleVerifier [0x00BE5AF0+637536]
	(No symbol) [0x00AE0A5D]
	(No symbol) [0x00ADDA28]
	(No symbol) [0x00ADDBC5]
	(No symbol) [0x00AD07F0]
	BaseThreadInitThunk [0x771BFCC9+25]
	RtlGetAppContainerNamedObjectPath [0x77DD809E+286]
	RtlGetAppContainerNamedObjectPath [0x77DD806E+238]

INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawl_and_insert_data" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 569-178-434
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\i\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawl_and_insert_data" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
INFO:werkzeug:[33mPress CTRL+C to quit[0m
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\i\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawl_and_insert_data" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 569-178-434
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 17:03:43 KST)" (scheduled at 2025-01-16 17:02:43.292697+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 17:03:43 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchWindowException: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x00B4FD53+23747]
	(No symbol) [0x00AD7D54]
	(No symbol) [0x009ABE53]
	(No symbol) [0x0098D91B]
	(No symbol) [0x00A17EFF]
	(No symbol) [0x00A2AD49]
	(No symbol) [0x00A11B96]
	(No symbol) [0x009E3F3C]
	(No symbol) [0x009E4EBD]
	GetHandleVerifier [0x00E2AC73+3017699]
	GetHandleVerifier [0x00E3B93B+3086507]
	GetHandleVerifier [0x00E340F2+3055714]
	GetHandleVerifier [0x00BE5AF0+637536]
	(No symbol) [0x00AE0A5D]
	(No symbol) [0x00ADDA28]
	(No symbol) [0x00ADDBC5]
	(No symbol) [0x00AD07F0]
	BaseThreadInitThunk [0x771BFCC9+25]
	RtlGetAppContainerNamedObjectPath [0x77DD809E+286]
	RtlGetAppContainerNamedObjectPath [0x77DD806E+238]

INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 17:02:46 KST)" (scheduled at 2025-01-16 17:02:46.624698+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 17:03:46 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchWindowException: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x00B4FD53+23747]
	(No symbol) [0x00AD7D54]
	(No symbol) [0x009ABE53]
	(No symbol) [0x0098D91B]
	(No symbol) [0x00A17EFF]
	(No symbol) [0x00A2AD49]
	(No symbol) [0x00A11B96]
	(No symbol) [0x009E3F3C]
	(No symbol) [0x009E4EBD]
	GetHandleVerifier [0x00E2AC73+3017699]
	GetHandleVerifier [0x00E3B93B+3086507]
	GetHandleVerifier [0x00E340F2+3055714]
	GetHandleVerifier [0x00BE5AF0+637536]
	(No symbol) [0x00AE0A5D]
	(No symbol) [0x00ADDA28]
	(No symbol) [0x00ADDBC5]
	(No symbol) [0x00AD07F0]
	BaseThreadInitThunk [0x771BFCC9+25]
	RtlGetAppContainerNamedObjectPath [0x77DD809E+286]
	RtlGetAppContainerNamedObjectPath [0x77DD806E+238]

INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 17:03:48 KST)" (scheduled at 2025-01-16 17:02:48.014593+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 17:03:48 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchWindowException: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x00B4FD53+23747]
	(No symbol) [0x00AD7D54]
	(No symbol) [0x009ABE53]
	(No symbol) [0x0098D91B]
	(No symbol) [0x00A17EFF]
	(No symbol) [0x00A2AD49]
	(No symbol) [0x00A11B96]
	(No symbol) [0x009E3F3C]
	(No symbol) [0x009E4EBD]
	GetHandleVerifier [0x00E2AC73+3017699]
	GetHandleVerifier [0x00E3B93B+3086507]
	GetHandleVerifier [0x00E340F2+3055714]
	GetHandleVerifier [0x00BE5AF0+637536]
	(No symbol) [0x00AE0A5D]
	(No symbol) [0x00ADDA28]
	(No symbol) [0x00ADDBC5]
	(No symbol) [0x00AD07F0]
	BaseThreadInitThunk [0x771BFCC9+25]
	RtlGetAppContainerNamedObjectPath [0x77DD809E+286]
	RtlGetAppContainerNamedObjectPath [0x77DD806E+238]

INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 17:03:48 KST)" (scheduled at 2025-01-16 17:02:48.547344+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 17:03:48 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchWindowException: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x00B4FD53+23747]
	(No symbol) [0x00AD7D54]
	(No symbol) [0x009ABE53]
	(No symbol) [0x0098D91B]
	(No symbol) [0x00A17EFF]
	(No symbol) [0x00A2AD49]
	(No symbol) [0x00A11B96]
	(No symbol) [0x009E3F3C]
	(No symbol) [0x009E4EBD]
	GetHandleVerifier [0x00E2AC73+3017699]
	GetHandleVerifier [0x00E3B93B+3086507]
	GetHandleVerifier [0x00E340F2+3055714]
	GetHandleVerifier [0x00BE5AF0+637536]
	(No symbol) [0x00AE0A5D]
	(No symbol) [0x00ADDA28]
	(No symbol) [0x00ADDBC5]
	(No symbol) [0x00AD07F0]
	BaseThreadInitThunk [0x771BFCC9+25]
	RtlGetAppContainerNamedObjectPath [0x77DD809E+286]
	RtlGetAppContainerNamedObjectPath [0x77DD806E+238]

INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 17:03:53 KST)" (scheduled at 2025-01-16 17:02:53.060586+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 17:03:53 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: disconnected: not connected to DevTools
  (failed to check if window was closed: disconnected: not connected to DevTools)
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x00B4FD53+23747]
	(No symbol) [0x00AD7D54]
	(No symbol) [0x009ABE53]
	(No symbol) [0x0099C408]
	(No symbol) [0x0099C329]
	(No symbol) [0x009AE2E0]
	(No symbol) [0x00A2AD69]
	(No symbol) [0x00A11B96]
	(No symbol) [0x009E3F3C]
	(No symbol) [0x009E4EBD]
	GetHandleVerifier [0x00E2AC73+3017699]
	GetHandleVerifier [0x00E3B93B+3086507]
	GetHandleVerifier [0x00E340F2+3055714]
	GetHandleVerifier [0x00BE5AF0+637536]
	(No symbol) [0x00AE0A5D]
	(No symbol) [0x00ADDA28]
	(No symbol) [0x00ADDBC5]
	(No symbol) [0x00AD07F0]
	BaseThreadInitThunk [0x771BFCC9+25]
	RtlGetAppContainerNamedObjectPath [0x77DD809E+286]
	RtlGetAppContainerNamedObjectPath [0x77DD806E+238]

INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 17:02:54 KST)" (scheduled at 2025-01-16 17:02:54.146682+09:00)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 17:02:57 KST)" (scheduled at 2025-01-16 17:02:57.954681+09:00)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 17:03:03 KST)" (scheduled at 2025-01-16 17:03:03.476262+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 17:04:03 KST)" executed successfully
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 17:03:57 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 126, in crawl_and_insert_data
    url = driver.current_url.strip()
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 437, in current_url
    return self.execute(Command.GET_CURRENT_URL)["value"]
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchWindowException: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x00B4FD53+23747]
	(No symbol) [0x00AD7D54]
	(No symbol) [0x009ABE53]
	(No symbol) [0x0098D91B]
	(No symbol) [0x00A17EFF]
	(No symbol) [0x00A2AD49]
	(No symbol) [0x00A11B96]
	(No symbol) [0x009E3F3C]
	(No symbol) [0x009E4EBD]
	GetHandleVerifier [0x00E2AC73+3017699]
	GetHandleVerifier [0x00E3B93B+3086507]
	GetHandleVerifier [0x00E340F2+3055714]
	GetHandleVerifier [0x00BE5AF0+637536]
	(No symbol) [0x00AE0A5D]
	(No symbol) [0x00ADDA28]
	(No symbol) [0x00ADDBC5]
	(No symbol) [0x00AD07F0]
	BaseThreadInitThunk [0x771BFCC9+25]
	RtlGetAppContainerNamedObjectPath [0x77DD809E+286]
	RtlGetAppContainerNamedObjectPath [0x77DD806E+238]

ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 17:03:54 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 126, in crawl_and_insert_data
    url = driver.current_url.strip()
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 437, in current_url
    return self.execute(Command.GET_CURRENT_URL)["value"]
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchWindowException: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x00B4FD53+23747]
	(No symbol) [0x00AD7D54]
	(No symbol) [0x009ABE53]
	(No symbol) [0x0098D91B]
	(No symbol) [0x00A17EFF]
	(No symbol) [0x00A2AD49]
	(No symbol) [0x00A11B96]
	(No symbol) [0x009E3F3C]
	(No symbol) [0x009E4EBD]
	GetHandleVerifier [0x00E2AC73+3017699]
	GetHandleVerifier [0x00E3B93B+3086507]
	GetHandleVerifier [0x00E340F2+3055714]
	GetHandleVerifier [0x00BE5AF0+637536]
	(No symbol) [0x00AE0A5D]
	(No symbol) [0x00ADDA28]
	(No symbol) [0x00ADDBC5]
	(No symbol) [0x00AD07F0]
	BaseThreadInitThunk [0x771BFCC9+25]
	RtlGetAppContainerNamedObjectPath [0x77DD809E+286]
	RtlGetAppContainerNamedObjectPath [0x77DD806E+238]

INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 17:04:43 KST)" (scheduled at 2025-01-16 17:03:43.292697+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 17:04:43 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchWindowException: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x00B4FD53+23747]
	(No symbol) [0x00AD7D54]
	(No symbol) [0x009ABE53]
	(No symbol) [0x0098D91B]
	(No symbol) [0x00A17EFF]
	(No symbol) [0x00A2AD49]
	(No symbol) [0x00A11B96]
	(No symbol) [0x009E3F3C]
	(No symbol) [0x009E4EBD]
	GetHandleVerifier [0x00E2AC73+3017699]
	GetHandleVerifier [0x00E3B93B+3086507]
	GetHandleVerifier [0x00E340F2+3055714]
	GetHandleVerifier [0x00BE5AF0+637536]
	(No symbol) [0x00AE0A5D]
	(No symbol) [0x00ADDA28]
	(No symbol) [0x00ADDBC5]
	(No symbol) [0x00AD07F0]
	BaseThreadInitThunk [0x771BFCC9+25]
	RtlGetAppContainerNamedObjectPath [0x77DD809E+286]
	RtlGetAppContainerNamedObjectPath [0x77DD806E+238]

INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 17:04:46 KST)" (scheduled at 2025-01-16 17:03:46.624698+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 17:04:46 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchWindowException: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x00B4FD53+23747]
	(No symbol) [0x00AD7D54]
	(No symbol) [0x009ABE53]
	(No symbol) [0x0098D91B]
	(No symbol) [0x00A17EFF]
	(No symbol) [0x00A2AD49]
	(No symbol) [0x00A11B96]
	(No symbol) [0x009E3F3C]
	(No symbol) [0x009E4EBD]
	GetHandleVerifier [0x00E2AC73+3017699]
	GetHandleVerifier [0x00E3B93B+3086507]
	GetHandleVerifier [0x00E340F2+3055714]
	GetHandleVerifier [0x00BE5AF0+637536]
	(No symbol) [0x00AE0A5D]
	(No symbol) [0x00ADDA28]
	(No symbol) [0x00ADDBC5]
	(No symbol) [0x00AD07F0]
	BaseThreadInitThunk [0x771BFCC9+25]
	RtlGetAppContainerNamedObjectPath [0x77DD809E+286]
	RtlGetAppContainerNamedObjectPath [0x77DD806E+238]

INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 17:04:48 KST)" (scheduled at 2025-01-16 17:03:48.014593+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 17:04:48 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchWindowException: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x00B4FD53+23747]
	(No symbol) [0x00AD7D54]
	(No symbol) [0x009ABE53]
	(No symbol) [0x0098D91B]
	(No symbol) [0x00A17EFF]
	(No symbol) [0x00A2AD49]
	(No symbol) [0x00A11B96]
	(No symbol) [0x009E3F3C]
	(No symbol) [0x009E4EBD]
	GetHandleVerifier [0x00E2AC73+3017699]
	GetHandleVerifier [0x00E3B93B+3086507]
	GetHandleVerifier [0x00E340F2+3055714]
	GetHandleVerifier [0x00BE5AF0+637536]
	(No symbol) [0x00AE0A5D]
	(No symbol) [0x00ADDA28]
	(No symbol) [0x00ADDBC5]
	(No symbol) [0x00AD07F0]
	BaseThreadInitThunk [0x771BFCC9+25]
	RtlGetAppContainerNamedObjectPath [0x77DD809E+286]
	RtlGetAppContainerNamedObjectPath [0x77DD806E+238]

INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 17:04:48 KST)" (scheduled at 2025-01-16 17:03:48.547344+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 17:04:48 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchWindowException: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x00B4FD53+23747]
	(No symbol) [0x00AD7D54]
	(No symbol) [0x009ABE53]
	(No symbol) [0x0098D91B]
	(No symbol) [0x00A17EFF]
	(No symbol) [0x00A2AD49]
	(No symbol) [0x00A11B96]
	(No symbol) [0x009E3F3C]
	(No symbol) [0x009E4EBD]
	GetHandleVerifier [0x00E2AC73+3017699]
	GetHandleVerifier [0x00E3B93B+3086507]
	GetHandleVerifier [0x00E340F2+3055714]
	GetHandleVerifier [0x00BE5AF0+637536]
	(No symbol) [0x00AE0A5D]
	(No symbol) [0x00ADDA28]
	(No symbol) [0x00ADDBC5]
	(No symbol) [0x00AD07F0]
	BaseThreadInitThunk [0x771BFCC9+25]
	RtlGetAppContainerNamedObjectPath [0x77DD809E+286]
	RtlGetAppContainerNamedObjectPath [0x77DD806E+238]

INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 17:04:53 KST)" (scheduled at 2025-01-16 17:03:53.060586+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 17:04:53 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: disconnected: not connected to DevTools
  (failed to check if window was closed: disconnected: not connected to DevTools)
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x00B4FD53+23747]
	(No symbol) [0x00AD7D54]
	(No symbol) [0x009ABE53]
	(No symbol) [0x0099C408]
	(No symbol) [0x0099C329]
	(No symbol) [0x009AE2E0]
	(No symbol) [0x00A2AD69]
	(No symbol) [0x00A11B96]
	(No symbol) [0x009E3F3C]
	(No symbol) [0x009E4EBD]
	GetHandleVerifier [0x00E2AC73+3017699]
	GetHandleVerifier [0x00E3B93B+3086507]
	GetHandleVerifier [0x00E340F2+3055714]
	GetHandleVerifier [0x00BE5AF0+637536]
	(No symbol) [0x00AE0A5D]
	(No symbol) [0x00ADDA28]
	(No symbol) [0x00ADDBC5]
	(No symbol) [0x00AD07F0]
	BaseThreadInitThunk [0x771BFCC9+25]
	RtlGetAppContainerNamedObjectPath [0x77DD809E+286]
	RtlGetAppContainerNamedObjectPath [0x77DD806E+238]

INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 17:04:54 KST)" (scheduled at 2025-01-16 17:03:54.146682+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 17:04:54 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchWindowException: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x00B4FD53+23747]
	(No symbol) [0x00AD7D54]
	(No symbol) [0x009ABE53]
	(No symbol) [0x0098D91B]
	(No symbol) [0x00A17EFF]
	(No symbol) [0x00A2AD49]
	(No symbol) [0x00A11B96]
	(No symbol) [0x009E3F3C]
	(No symbol) [0x009E4EBD]
	GetHandleVerifier [0x00E2AC73+3017699]
	GetHandleVerifier [0x00E3B93B+3086507]
	GetHandleVerifier [0x00E340F2+3055714]
	GetHandleVerifier [0x00BE5AF0+637536]
	(No symbol) [0x00AE0A5D]
	(No symbol) [0x00ADDA28]
	(No symbol) [0x00ADDBC5]
	(No symbol) [0x00AD07F0]
	BaseThreadInitThunk [0x771BFCC9+25]
	RtlGetAppContainerNamedObjectPath [0x77DD809E+286]
	RtlGetAppContainerNamedObjectPath [0x77DD806E+238]

INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 17:04:57 KST)" (scheduled at 2025-01-16 17:03:57.954681+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 17:04:57 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchWindowException: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x00B4FD53+23747]
	(No symbol) [0x00AD7D54]
	(No symbol) [0x009ABE53]
	(No symbol) [0x0098D91B]
	(No symbol) [0x00A17EFF]
	(No symbol) [0x00A2AD49]
	(No symbol) [0x00A11B96]
	(No symbol) [0x009E3F3C]
	(No symbol) [0x009E4EBD]
	GetHandleVerifier [0x00E2AC73+3017699]
	GetHandleVerifier [0x00E3B93B+3086507]
	GetHandleVerifier [0x00E340F2+3055714]
	GetHandleVerifier [0x00BE5AF0+637536]
	(No symbol) [0x00AE0A5D]
	(No symbol) [0x00ADDA28]
	(No symbol) [0x00ADDBC5]
	(No symbol) [0x00AD07F0]
	BaseThreadInitThunk [0x771BFCC9+25]
	RtlGetAppContainerNamedObjectPath [0x77DD809E+286]
	RtlGetAppContainerNamedObjectPath [0x77DD806E+238]

INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 17:05:03 KST)" (scheduled at 2025-01-16 17:04:03.476262+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 17:05:03 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchWindowException: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x00B4FD53+23747]
	(No symbol) [0x00AD7D54]
	(No symbol) [0x009ABE53]
	(No symbol) [0x0098D91B]
	(No symbol) [0x00A17EFF]
	(No symbol) [0x00A2AD49]
	(No symbol) [0x00A11B96]
	(No symbol) [0x009E3F3C]
	(No symbol) [0x009E4EBD]
	GetHandleVerifier [0x00E2AC73+3017699]
	GetHandleVerifier [0x00E3B93B+3086507]
	GetHandleVerifier [0x00E340F2+3055714]
	GetHandleVerifier [0x00BE5AF0+637536]
	(No symbol) [0x00AE0A5D]
	(No symbol) [0x00ADDA28]
	(No symbol) [0x00ADDBC5]
	(No symbol) [0x00AD07F0]
	BaseThreadInitThunk [0x771BFCC9+25]
	RtlGetAppContainerNamedObjectPath [0x77DD809E+286]
	RtlGetAppContainerNamedObjectPath [0x77DD806E+238]

INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\i\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawl_and_insert_data" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
INFO:werkzeug:[33mPress CTRL+C to quit[0m
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\i\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawl_and_insert_data" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 569-178-434
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 17:05:43 KST)" (scheduled at 2025-01-16 17:04:43.292697+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 17:05:43 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchWindowException: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x00B4FD53+23747]
	(No symbol) [0x00AD7D54]
	(No symbol) [0x009ABE53]
	(No symbol) [0x0098D91B]
	(No symbol) [0x00A17EFF]
	(No symbol) [0x00A2AD49]
	(No symbol) [0x00A11B96]
	(No symbol) [0x009E3F3C]
	(No symbol) [0x009E4EBD]
	GetHandleVerifier [0x00E2AC73+3017699]
	GetHandleVerifier [0x00E3B93B+3086507]
	GetHandleVerifier [0x00E340F2+3055714]
	GetHandleVerifier [0x00BE5AF0+637536]
	(No symbol) [0x00AE0A5D]
	(No symbol) [0x00ADDA28]
	(No symbol) [0x00ADDBC5]
	(No symbol) [0x00AD07F0]
	BaseThreadInitThunk [0x771BFCC9+25]
	RtlGetAppContainerNamedObjectPath [0x77DD809E+286]
	RtlGetAppContainerNamedObjectPath [0x77DD806E+238]

INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 17:05:46 KST)" (scheduled at 2025-01-16 17:04:46.624698+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 17:05:46 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchWindowException: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x00B4FD53+23747]
	(No symbol) [0x00AD7D54]
	(No symbol) [0x009ABE53]
	(No symbol) [0x0098D91B]
	(No symbol) [0x00A17EFF]
	(No symbol) [0x00A2AD49]
	(No symbol) [0x00A11B96]
	(No symbol) [0x009E3F3C]
	(No symbol) [0x009E4EBD]
	GetHandleVerifier [0x00E2AC73+3017699]
	GetHandleVerifier [0x00E3B93B+3086507]
	GetHandleVerifier [0x00E340F2+3055714]
	GetHandleVerifier [0x00BE5AF0+637536]
	(No symbol) [0x00AE0A5D]
	(No symbol) [0x00ADDA28]
	(No symbol) [0x00ADDBC5]
	(No symbol) [0x00AD07F0]
	BaseThreadInitThunk [0x771BFCC9+25]
	RtlGetAppContainerNamedObjectPath [0x77DD809E+286]
	RtlGetAppContainerNamedObjectPath [0x77DD806E+238]

INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 17:05:48 KST)" (scheduled at 2025-01-16 17:04:48.014593+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 17:05:48 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchWindowException: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x00B4FD53+23747]
	(No symbol) [0x00AD7D54]
	(No symbol) [0x009ABE53]
	(No symbol) [0x0098D91B]
	(No symbol) [0x00A17EFF]
	(No symbol) [0x00A2AD49]
	(No symbol) [0x00A11B96]
	(No symbol) [0x009E3F3C]
	(No symbol) [0x009E4EBD]
	GetHandleVerifier [0x00E2AC73+3017699]
	GetHandleVerifier [0x00E3B93B+3086507]
	GetHandleVerifier [0x00E340F2+3055714]
	GetHandleVerifier [0x00BE5AF0+637536]
	(No symbol) [0x00AE0A5D]
	(No symbol) [0x00ADDA28]
	(No symbol) [0x00ADDBC5]
	(No symbol) [0x00AD07F0]
	BaseThreadInitThunk [0x771BFCC9+25]
	RtlGetAppContainerNamedObjectPath [0x77DD809E+286]
	RtlGetAppContainerNamedObjectPath [0x77DD806E+238]

INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 17:05:48 KST)" (scheduled at 2025-01-16 17:04:48.547344+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 17:05:48 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchWindowException: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x00B4FD53+23747]
	(No symbol) [0x00AD7D54]
	(No symbol) [0x009ABE53]
	(No symbol) [0x0098D91B]
	(No symbol) [0x00A17EFF]
	(No symbol) [0x00A2AD49]
	(No symbol) [0x00A11B96]
	(No symbol) [0x009E3F3C]
	(No symbol) [0x009E4EBD]
	GetHandleVerifier [0x00E2AC73+3017699]
	GetHandleVerifier [0x00E3B93B+3086507]
	GetHandleVerifier [0x00E340F2+3055714]
	GetHandleVerifier [0x00BE5AF0+637536]
	(No symbol) [0x00AE0A5D]
	(No symbol) [0x00ADDA28]
	(No symbol) [0x00ADDBC5]
	(No symbol) [0x00AD07F0]
	BaseThreadInitThunk [0x771BFCC9+25]
	RtlGetAppContainerNamedObjectPath [0x77DD809E+286]
	RtlGetAppContainerNamedObjectPath [0x77DD806E+238]

INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 17:05:53 KST)" (scheduled at 2025-01-16 17:04:53.060586+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 17:05:53 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: disconnected: not connected to DevTools
  (failed to check if window was closed: disconnected: not connected to DevTools)
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x00B4FD53+23747]
	(No symbol) [0x00AD7D54]
	(No symbol) [0x009ABE53]
	(No symbol) [0x0099C408]
	(No symbol) [0x0099C329]
	(No symbol) [0x009AE2E0]
	(No symbol) [0x00A2AD69]
	(No symbol) [0x00A11B96]
	(No symbol) [0x009E3F3C]
	(No symbol) [0x009E4EBD]
	GetHandleVerifier [0x00E2AC73+3017699]
	GetHandleVerifier [0x00E3B93B+3086507]
	GetHandleVerifier [0x00E340F2+3055714]
	GetHandleVerifier [0x00BE5AF0+637536]
	(No symbol) [0x00AE0A5D]
	(No symbol) [0x00ADDA28]
	(No symbol) [0x00ADDBC5]
	(No symbol) [0x00AD07F0]
	BaseThreadInitThunk [0x771BFCC9+25]
	RtlGetAppContainerNamedObjectPath [0x77DD809E+286]
	RtlGetAppContainerNamedObjectPath [0x77DD806E+238]

INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 17:05:54 KST)" (scheduled at 2025-01-16 17:04:54.146682+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 17:05:54 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchWindowException: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x00B4FD53+23747]
	(No symbol) [0x00AD7D54]
	(No symbol) [0x009ABE53]
	(No symbol) [0x0098D91B]
	(No symbol) [0x00A17EFF]
	(No symbol) [0x00A2AD49]
	(No symbol) [0x00A11B96]
	(No symbol) [0x009E3F3C]
	(No symbol) [0x009E4EBD]
	GetHandleVerifier [0x00E2AC73+3017699]
	GetHandleVerifier [0x00E3B93B+3086507]
	GetHandleVerifier [0x00E340F2+3055714]
	GetHandleVerifier [0x00BE5AF0+637536]
	(No symbol) [0x00AE0A5D]
	(No symbol) [0x00ADDA28]
	(No symbol) [0x00ADDBC5]
	(No symbol) [0x00AD07F0]
	BaseThreadInitThunk [0x771BFCC9+25]
	RtlGetAppContainerNamedObjectPath [0x77DD809E+286]
	RtlGetAppContainerNamedObjectPath [0x77DD806E+238]

INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 17:05:57 KST)" (scheduled at 2025-01-16 17:04:57.954681+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 17:05:57 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchWindowException: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x00B4FD53+23747]
	(No symbol) [0x00AD7D54]
	(No symbol) [0x009ABE53]
	(No symbol) [0x0098D91B]
	(No symbol) [0x00A17EFF]
	(No symbol) [0x00A2AD49]
	(No symbol) [0x00A11B96]
	(No symbol) [0x009E3F3C]
	(No symbol) [0x009E4EBD]
	GetHandleVerifier [0x00E2AC73+3017699]
	GetHandleVerifier [0x00E3B93B+3086507]
	GetHandleVerifier [0x00E340F2+3055714]
	GetHandleVerifier [0x00BE5AF0+637536]
	(No symbol) [0x00AE0A5D]
	(No symbol) [0x00ADDA28]
	(No symbol) [0x00ADDBC5]
	(No symbol) [0x00AD07F0]
	BaseThreadInitThunk [0x771BFCC9+25]
	RtlGetAppContainerNamedObjectPath [0x77DD809E+286]
	RtlGetAppContainerNamedObjectPath [0x77DD806E+238]

INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 17:06:03 KST)" (scheduled at 2025-01-16 17:05:03.476262+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 17:06:03 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchWindowException: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x00B4FD53+23747]
	(No symbol) [0x00AD7D54]
	(No symbol) [0x009ABE53]
	(No symbol) [0x0098D91B]
	(No symbol) [0x00A17EFF]
	(No symbol) [0x00A2AD49]
	(No symbol) [0x00A11B96]
	(No symbol) [0x009E3F3C]
	(No symbol) [0x009E4EBD]
	GetHandleVerifier [0x00E2AC73+3017699]
	GetHandleVerifier [0x00E3B93B+3086507]
	GetHandleVerifier [0x00E340F2+3055714]
	GetHandleVerifier [0x00BE5AF0+637536]
	(No symbol) [0x00AE0A5D]
	(No symbol) [0x00ADDA28]
	(No symbol) [0x00ADDBC5]
	(No symbol) [0x00AD07F0]
	BaseThreadInitThunk [0x771BFCC9+25]
	RtlGetAppContainerNamedObjectPath [0x77DD809E+286]
	RtlGetAppContainerNamedObjectPath [0x77DD806E+238]

INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 17:05:18 KST)" (scheduled at 2025-01-16 17:05:18.427025+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 17:06:18 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchWindowException: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x00B4FD53+23747]
	(No symbol) [0x00AD7D54]
	(No symbol) [0x009ABE53]
	(No symbol) [0x0098D91B]
	(No symbol) [0x00A17EFF]
	(No symbol) [0x00A2AD49]
	(No symbol) [0x00A11B96]
	(No symbol) [0x009E3F3C]
	(No symbol) [0x009E4EBD]
	GetHandleVerifier [0x00E2AC73+3017699]
	GetHandleVerifier [0x00E3B93B+3086507]
	GetHandleVerifier [0x00E340F2+3055714]
	GetHandleVerifier [0x00BE5AF0+637536]
	(No symbol) [0x00AE0A5D]
	(No symbol) [0x00ADDA28]
	(No symbol) [0x00ADDBC5]
	(No symbol) [0x00AD07F0]
	BaseThreadInitThunk [0x771BFCC9+25]
	RtlGetAppContainerNamedObjectPath [0x77DD809E+286]
	RtlGetAppContainerNamedObjectPath [0x77DD806E+238]

INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 17:05:23 KST)" (scheduled at 2025-01-16 17:05:23.706019+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 17:06:23 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchWindowException: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x00B4FD53+23747]
	(No symbol) [0x00AD7D54]
	(No symbol) [0x009ABE53]
	(No symbol) [0x0098D91B]
	(No symbol) [0x00A17EFF]
	(No symbol) [0x00A2AD49]
	(No symbol) [0x00A11B96]
	(No symbol) [0x009E3F3C]
	(No symbol) [0x009E4EBD]
	GetHandleVerifier [0x00E2AC73+3017699]
	GetHandleVerifier [0x00E3B93B+3086507]
	GetHandleVerifier [0x00E340F2+3055714]
	GetHandleVerifier [0x00BE5AF0+637536]
	(No symbol) [0x00AE0A5D]
	(No symbol) [0x00ADDA28]
	(No symbol) [0x00ADDBC5]
	(No symbol) [0x00AD07F0]
	BaseThreadInitThunk [0x771BFCC9+25]
	RtlGetAppContainerNamedObjectPath [0x77DD809E+286]
	RtlGetAppContainerNamedObjectPath [0x77DD806E+238]

INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 17:06:43 KST)" (scheduled at 2025-01-16 17:05:43.292697+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 17:06:43 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchWindowException: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x00B4FD53+23747]
	(No symbol) [0x00AD7D54]
	(No symbol) [0x009ABE53]
	(No symbol) [0x0098D91B]
	(No symbol) [0x00A17EFF]
	(No symbol) [0x00A2AD49]
	(No symbol) [0x00A11B96]
	(No symbol) [0x009E3F3C]
	(No symbol) [0x009E4EBD]
	GetHandleVerifier [0x00E2AC73+3017699]
	GetHandleVerifier [0x00E3B93B+3086507]
	GetHandleVerifier [0x00E340F2+3055714]
	GetHandleVerifier [0x00BE5AF0+637536]
	(No symbol) [0x00AE0A5D]
	(No symbol) [0x00ADDA28]
	(No symbol) [0x00ADDBC5]
	(No symbol) [0x00AD07F0]
	BaseThreadInitThunk [0x771BFCC9+25]
	RtlGetAppContainerNamedObjectPath [0x77DD809E+286]
	RtlGetAppContainerNamedObjectPath [0x77DD806E+238]

INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 17:06:46 KST)" (scheduled at 2025-01-16 17:05:46.624698+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 17:06:46 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchWindowException: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x00B4FD53+23747]
	(No symbol) [0x00AD7D54]
	(No symbol) [0x009ABE53]
	(No symbol) [0x0098D91B]
	(No symbol) [0x00A17EFF]
	(No symbol) [0x00A2AD49]
	(No symbol) [0x00A11B96]
	(No symbol) [0x009E3F3C]
	(No symbol) [0x009E4EBD]
	GetHandleVerifier [0x00E2AC73+3017699]
	GetHandleVerifier [0x00E3B93B+3086507]
	GetHandleVerifier [0x00E340F2+3055714]
	GetHandleVerifier [0x00BE5AF0+637536]
	(No symbol) [0x00AE0A5D]
	(No symbol) [0x00ADDA28]
	(No symbol) [0x00ADDBC5]
	(No symbol) [0x00AD07F0]
	BaseThreadInitThunk [0x771BFCC9+25]
	RtlGetAppContainerNamedObjectPath [0x77DD809E+286]
	RtlGetAppContainerNamedObjectPath [0x77DD806E+238]

INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 17:06:48 KST)" (scheduled at 2025-01-16 17:05:48.014593+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 17:06:48 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchWindowException: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x00B4FD53+23747]
	(No symbol) [0x00AD7D54]
	(No symbol) [0x009ABE53]
	(No symbol) [0x0098D91B]
	(No symbol) [0x00A17EFF]
	(No symbol) [0x00A2AD49]
	(No symbol) [0x00A11B96]
	(No symbol) [0x009E3F3C]
	(No symbol) [0x009E4EBD]
	GetHandleVerifier [0x00E2AC73+3017699]
	GetHandleVerifier [0x00E3B93B+3086507]
	GetHandleVerifier [0x00E340F2+3055714]
	GetHandleVerifier [0x00BE5AF0+637536]
	(No symbol) [0x00AE0A5D]
	(No symbol) [0x00ADDA28]
	(No symbol) [0x00ADDBC5]
	(No symbol) [0x00AD07F0]
	BaseThreadInitThunk [0x771BFCC9+25]
	RtlGetAppContainerNamedObjectPath [0x77DD809E+286]
	RtlGetAppContainerNamedObjectPath [0x77DD806E+238]

INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 17:06:48 KST)" (scheduled at 2025-01-16 17:05:48.547344+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 17:06:48 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchWindowException: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x00B4FD53+23747]
	(No symbol) [0x00AD7D54]
	(No symbol) [0x009ABE53]
	(No symbol) [0x0098D91B]
	(No symbol) [0x00A17EFF]
	(No symbol) [0x00A2AD49]
	(No symbol) [0x00A11B96]
	(No symbol) [0x009E3F3C]
	(No symbol) [0x009E4EBD]
	GetHandleVerifier [0x00E2AC73+3017699]
	GetHandleVerifier [0x00E3B93B+3086507]
	GetHandleVerifier [0x00E340F2+3055714]
	GetHandleVerifier [0x00BE5AF0+637536]
	(No symbol) [0x00AE0A5D]
	(No symbol) [0x00ADDA28]
	(No symbol) [0x00ADDBC5]
	(No symbol) [0x00AD07F0]
	BaseThreadInitThunk [0x771BFCC9+25]
	RtlGetAppContainerNamedObjectPath [0x77DD809E+286]
	RtlGetAppContainerNamedObjectPath [0x77DD806E+238]

INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 17:06:53 KST)" (scheduled at 2025-01-16 17:05:53.060586+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 17:06:53 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: disconnected: not connected to DevTools
  (failed to check if window was closed: disconnected: not connected to DevTools)
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x00B4FD53+23747]
	(No symbol) [0x00AD7D54]
	(No symbol) [0x009ABE53]
	(No symbol) [0x0099C408]
	(No symbol) [0x0099C329]
	(No symbol) [0x009AE2E0]
	(No symbol) [0x00A2AD69]
	(No symbol) [0x00A11B96]
	(No symbol) [0x009E3F3C]
	(No symbol) [0x009E4EBD]
	GetHandleVerifier [0x00E2AC73+3017699]
	GetHandleVerifier [0x00E3B93B+3086507]
	GetHandleVerifier [0x00E340F2+3055714]
	GetHandleVerifier [0x00BE5AF0+637536]
	(No symbol) [0x00AE0A5D]
	(No symbol) [0x00ADDA28]
	(No symbol) [0x00ADDBC5]
	(No symbol) [0x00AD07F0]
	BaseThreadInitThunk [0x771BFCC9+25]
	RtlGetAppContainerNamedObjectPath [0x77DD809E+286]
	RtlGetAppContainerNamedObjectPath [0x77DD806E+238]

INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 17:06:54 KST)" (scheduled at 2025-01-16 17:05:54.146682+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 17:06:54 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchWindowException: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x00B4FD53+23747]
	(No symbol) [0x00AD7D54]
	(No symbol) [0x009ABE53]
	(No symbol) [0x0098D91B]
	(No symbol) [0x00A17EFF]
	(No symbol) [0x00A2AD49]
	(No symbol) [0x00A11B96]
	(No symbol) [0x009E3F3C]
	(No symbol) [0x009E4EBD]
	GetHandleVerifier [0x00E2AC73+3017699]
	GetHandleVerifier [0x00E3B93B+3086507]
	GetHandleVerifier [0x00E340F2+3055714]
	GetHandleVerifier [0x00BE5AF0+637536]
	(No symbol) [0x00AE0A5D]
	(No symbol) [0x00ADDA28]
	(No symbol) [0x00ADDBC5]
	(No symbol) [0x00AD07F0]
	BaseThreadInitThunk [0x771BFCC9+25]
	RtlGetAppContainerNamedObjectPath [0x77DD809E+286]
	RtlGetAppContainerNamedObjectPath [0x77DD806E+238]

INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 17:06:57 KST)" (scheduled at 2025-01-16 17:05:57.954681+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 17:06:57 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchWindowException: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x00B4FD53+23747]
	(No symbol) [0x00AD7D54]
	(No symbol) [0x009ABE53]
	(No symbol) [0x0098D91B]
	(No symbol) [0x00A17EFF]
	(No symbol) [0x00A2AD49]
	(No symbol) [0x00A11B96]
	(No symbol) [0x009E3F3C]
	(No symbol) [0x009E4EBD]
	GetHandleVerifier [0x00E2AC73+3017699]
	GetHandleVerifier [0x00E3B93B+3086507]
	GetHandleVerifier [0x00E340F2+3055714]
	GetHandleVerifier [0x00BE5AF0+637536]
	(No symbol) [0x00AE0A5D]
	(No symbol) [0x00ADDA28]
	(No symbol) [0x00ADDBC5]
	(No symbol) [0x00AD07F0]
	BaseThreadInitThunk [0x771BFCC9+25]
	RtlGetAppContainerNamedObjectPath [0x77DD809E+286]
	RtlGetAppContainerNamedObjectPath [0x77DD806E+238]

INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 17:07:03 KST)" (scheduled at 2025-01-16 17:06:03.476262+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 17:07:03 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchWindowException: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x00B4FD53+23747]
	(No symbol) [0x00AD7D54]
	(No symbol) [0x009ABE53]
	(No symbol) [0x0098D91B]
	(No symbol) [0x00A17EFF]
	(No symbol) [0x00A2AD49]
	(No symbol) [0x00A11B96]
	(No symbol) [0x009E3F3C]
	(No symbol) [0x009E4EBD]
	GetHandleVerifier [0x00E2AC73+3017699]
	GetHandleVerifier [0x00E3B93B+3086507]
	GetHandleVerifier [0x00E340F2+3055714]
	GetHandleVerifier [0x00BE5AF0+637536]
	(No symbol) [0x00AE0A5D]
	(No symbol) [0x00ADDA28]
	(No symbol) [0x00ADDBC5]
	(No symbol) [0x00AD07F0]
	BaseThreadInitThunk [0x771BFCC9+25]
	RtlGetAppContainerNamedObjectPath [0x77DD809E+286]
	RtlGetAppContainerNamedObjectPath [0x77DD806E+238]

INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 17:07:18 KST)" (scheduled at 2025-01-16 17:06:18.427025+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 17:07:18 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchWindowException: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x00B4FD53+23747]
	(No symbol) [0x00AD7D54]
	(No symbol) [0x009ABE53]
	(No symbol) [0x0098D91B]
	(No symbol) [0x00A17EFF]
	(No symbol) [0x00A2AD49]
	(No symbol) [0x00A11B96]
	(No symbol) [0x009E3F3C]
	(No symbol) [0x009E4EBD]
	GetHandleVerifier [0x00E2AC73+3017699]
	GetHandleVerifier [0x00E3B93B+3086507]
	GetHandleVerifier [0x00E340F2+3055714]
	GetHandleVerifier [0x00BE5AF0+637536]
	(No symbol) [0x00AE0A5D]
	(No symbol) [0x00ADDA28]
	(No symbol) [0x00ADDBC5]
	(No symbol) [0x00AD07F0]
	BaseThreadInitThunk [0x771BFCC9+25]
	RtlGetAppContainerNamedObjectPath [0x77DD809E+286]
	RtlGetAppContainerNamedObjectPath [0x77DD806E+238]

INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 17:07:23 KST)" (scheduled at 2025-01-16 17:06:23.706019+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 17:07:23 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchWindowException: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x00B4FD53+23747]
	(No symbol) [0x00AD7D54]
	(No symbol) [0x009ABE53]
	(No symbol) [0x0098D91B]
	(No symbol) [0x00A17EFF]
	(No symbol) [0x00A2AD49]
	(No symbol) [0x00A11B96]
	(No symbol) [0x009E3F3C]
	(No symbol) [0x009E4EBD]
	GetHandleVerifier [0x00E2AC73+3017699]
	GetHandleVerifier [0x00E3B93B+3086507]
	GetHandleVerifier [0x00E340F2+3055714]
	GetHandleVerifier [0x00BE5AF0+637536]
	(No symbol) [0x00AE0A5D]
	(No symbol) [0x00ADDA28]
	(No symbol) [0x00ADDBC5]
	(No symbol) [0x00AD07F0]
	BaseThreadInitThunk [0x771BFCC9+25]
	RtlGetAppContainerNamedObjectPath [0x77DD809E+286]
	RtlGetAppContainerNamedObjectPath [0x77DD806E+238]

INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 17:07:43 KST)" (scheduled at 2025-01-16 17:06:43.292697+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 17:07:43 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchWindowException: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x00B4FD53+23747]
	(No symbol) [0x00AD7D54]
	(No symbol) [0x009ABE53]
	(No symbol) [0x0098D91B]
	(No symbol) [0x00A17EFF]
	(No symbol) [0x00A2AD49]
	(No symbol) [0x00A11B96]
	(No symbol) [0x009E3F3C]
	(No symbol) [0x009E4EBD]
	GetHandleVerifier [0x00E2AC73+3017699]
	GetHandleVerifier [0x00E3B93B+3086507]
	GetHandleVerifier [0x00E340F2+3055714]
	GetHandleVerifier [0x00BE5AF0+637536]
	(No symbol) [0x00AE0A5D]
	(No symbol) [0x00ADDA28]
	(No symbol) [0x00ADDBC5]
	(No symbol) [0x00AD07F0]
	BaseThreadInitThunk [0x771BFCC9+25]
	RtlGetAppContainerNamedObjectPath [0x77DD809E+286]
	RtlGetAppContainerNamedObjectPath [0x77DD806E+238]

INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 17:07:46 KST)" (scheduled at 2025-01-16 17:06:46.624698+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 17:07:46 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchWindowException: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x00B4FD53+23747]
	(No symbol) [0x00AD7D54]
	(No symbol) [0x009ABE53]
	(No symbol) [0x0098D91B]
	(No symbol) [0x00A17EFF]
	(No symbol) [0x00A2AD49]
	(No symbol) [0x00A11B96]
	(No symbol) [0x009E3F3C]
	(No symbol) [0x009E4EBD]
	GetHandleVerifier [0x00E2AC73+3017699]
	GetHandleVerifier [0x00E3B93B+3086507]
	GetHandleVerifier [0x00E340F2+3055714]
	GetHandleVerifier [0x00BE5AF0+637536]
	(No symbol) [0x00AE0A5D]
	(No symbol) [0x00ADDA28]
	(No symbol) [0x00ADDBC5]
	(No symbol) [0x00AD07F0]
	BaseThreadInitThunk [0x771BFCC9+25]
	RtlGetAppContainerNamedObjectPath [0x77DD809E+286]
	RtlGetAppContainerNamedObjectPath [0x77DD806E+238]

INFO:WDM:====== WebDriver manager ======
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 17:07:48 KST)" (scheduled at 2025-01-16 17:06:48.014593+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 17:07:48 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchWindowException: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x00B4FD53+23747]
	(No symbol) [0x00AD7D54]
	(No symbol) [0x009ABE53]
	(No symbol) [0x0098D91B]
	(No symbol) [0x00A17EFF]
	(No symbol) [0x00A2AD49]
	(No symbol) [0x00A11B96]
	(No symbol) [0x009E3F3C]
	(No symbol) [0x009E4EBD]
	GetHandleVerifier [0x00E2AC73+3017699]
	GetHandleVerifier [0x00E3B93B+3086507]
	GetHandleVerifier [0x00E340F2+3055714]
	GetHandleVerifier [0x00BE5AF0+637536]
	(No symbol) [0x00AE0A5D]
	(No symbol) [0x00ADDA28]
	(No symbol) [0x00ADDBC5]
	(No symbol) [0x00AD07F0]
	BaseThreadInitThunk [0x771BFCC9+25]
	RtlGetAppContainerNamedObjectPath [0x77DD809E+286]
	RtlGetAppContainerNamedObjectPath [0x77DD806E+238]

INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 17:07:48 KST)" (scheduled at 2025-01-16 17:06:48.547344+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 17:07:48 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchWindowException: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x00B4FD53+23747]
	(No symbol) [0x00AD7D54]
	(No symbol) [0x009ABE53]
	(No symbol) [0x0098D91B]
	(No symbol) [0x00A17EFF]
	(No symbol) [0x00A2AD49]
	(No symbol) [0x00A11B96]
	(No symbol) [0x009E3F3C]
	(No symbol) [0x009E4EBD]
	GetHandleVerifier [0x00E2AC73+3017699]
	GetHandleVerifier [0x00E3B93B+3086507]
	GetHandleVerifier [0x00E340F2+3055714]
	GetHandleVerifier [0x00BE5AF0+637536]
	(No symbol) [0x00AE0A5D]
	(No symbol) [0x00ADDA28]
	(No symbol) [0x00ADDBC5]
	(No symbol) [0x00AD07F0]
	BaseThreadInitThunk [0x771BFCC9+25]
	RtlGetAppContainerNamedObjectPath [0x77DD809E+286]
	RtlGetAppContainerNamedObjectPath [0x77DD806E+238]

INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\i\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawl_and_insert_data" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
INFO:werkzeug:[33mPress CTRL+C to quit[0m
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 17:07:53 KST)" (scheduled at 2025-01-16 17:06:53.060586+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 17:07:53 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: disconnected: not connected to DevTools
  (failed to check if window was closed: disconnected: not connected to DevTools)
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x00B4FD53+23747]
	(No symbol) [0x00AD7D54]
	(No symbol) [0x009ABE53]
	(No symbol) [0x0099C408]
	(No symbol) [0x0099C329]
	(No symbol) [0x009AE2E0]
	(No symbol) [0x00A2AD69]
	(No symbol) [0x00A11B96]
	(No symbol) [0x009E3F3C]
	(No symbol) [0x009E4EBD]
	GetHandleVerifier [0x00E2AC73+3017699]
	GetHandleVerifier [0x00E3B93B+3086507]
	GetHandleVerifier [0x00E340F2+3055714]
	GetHandleVerifier [0x00BE5AF0+637536]
	(No symbol) [0x00AE0A5D]
	(No symbol) [0x00ADDA28]
	(No symbol) [0x00ADDBC5]
	(No symbol) [0x00AD07F0]
	BaseThreadInitThunk [0x771BFCC9+25]
	RtlGetAppContainerNamedObjectPath [0x77DD809E+286]
	RtlGetAppContainerNamedObjectPath [0x77DD806E+238]

INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 17:07:54 KST)" (scheduled at 2025-01-16 17:06:54.146682+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 17:07:54 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchWindowException: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x00B4FD53+23747]
	(No symbol) [0x00AD7D54]
	(No symbol) [0x009ABE53]
	(No symbol) [0x0098D91B]
	(No symbol) [0x00A17EFF]
	(No symbol) [0x00A2AD49]
	(No symbol) [0x00A11B96]
	(No symbol) [0x009E3F3C]
	(No symbol) [0x009E4EBD]
	GetHandleVerifier [0x00E2AC73+3017699]
	GetHandleVerifier [0x00E3B93B+3086507]
	GetHandleVerifier [0x00E340F2+3055714]
	GetHandleVerifier [0x00BE5AF0+637536]
	(No symbol) [0x00AE0A5D]
	(No symbol) [0x00ADDA28]
	(No symbol) [0x00ADDBC5]
	(No symbol) [0x00AD07F0]
	BaseThreadInitThunk [0x771BFCC9+25]
	RtlGetAppContainerNamedObjectPath [0x77DD809E+286]
	RtlGetAppContainerNamedObjectPath [0x77DD806E+238]

INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\i\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawl_and_insert_data" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 569-178-434
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 17:07:57 KST)" (scheduled at 2025-01-16 17:06:57.954681+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 17:07:57 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchWindowException: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x00B4FD53+23747]
	(No symbol) [0x00AD7D54]
	(No symbol) [0x009ABE53]
	(No symbol) [0x0098D91B]
	(No symbol) [0x00A17EFF]
	(No symbol) [0x00A2AD49]
	(No symbol) [0x00A11B96]
	(No symbol) [0x009E3F3C]
	(No symbol) [0x009E4EBD]
	GetHandleVerifier [0x00E2AC73+3017699]
	GetHandleVerifier [0x00E3B93B+3086507]
	GetHandleVerifier [0x00E340F2+3055714]
	GetHandleVerifier [0x00BE5AF0+637536]
	(No symbol) [0x00AE0A5D]
	(No symbol) [0x00ADDA28]
	(No symbol) [0x00ADDBC5]
	(No symbol) [0x00AD07F0]
	BaseThreadInitThunk [0x771BFCC9+25]
	RtlGetAppContainerNamedObjectPath [0x77DD809E+286]
	RtlGetAppContainerNamedObjectPath [0x77DD806E+238]

INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 17:08:03 KST)" (scheduled at 2025-01-16 17:07:03.476262+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 17:08:03 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchWindowException: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x00B4FD53+23747]
	(No symbol) [0x00AD7D54]
	(No symbol) [0x009ABE53]
	(No symbol) [0x0098D91B]
	(No symbol) [0x00A17EFF]
	(No symbol) [0x00A2AD49]
	(No symbol) [0x00A11B96]
	(No symbol) [0x009E3F3C]
	(No symbol) [0x009E4EBD]
	GetHandleVerifier [0x00E2AC73+3017699]
	GetHandleVerifier [0x00E3B93B+3086507]
	GetHandleVerifier [0x00E340F2+3055714]
	GetHandleVerifier [0x00BE5AF0+637536]
	(No symbol) [0x00AE0A5D]
	(No symbol) [0x00ADDA28]
	(No symbol) [0x00ADDBC5]
	(No symbol) [0x00AD07F0]
	BaseThreadInitThunk [0x771BFCC9+25]
	RtlGetAppContainerNamedObjectPath [0x77DD809E+286]
	RtlGetAppContainerNamedObjectPath [0x77DD806E+238]

INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 17:08:18 KST)" (scheduled at 2025-01-16 17:07:18.427025+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 17:08:18 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchWindowException: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x00B4FD53+23747]
	(No symbol) [0x00AD7D54]
	(No symbol) [0x009ABE53]
	(No symbol) [0x0098D91B]
	(No symbol) [0x00A17EFF]
	(No symbol) [0x00A2AD49]
	(No symbol) [0x00A11B96]
	(No symbol) [0x009E3F3C]
	(No symbol) [0x009E4EBD]
	GetHandleVerifier [0x00E2AC73+3017699]
	GetHandleVerifier [0x00E3B93B+3086507]
	GetHandleVerifier [0x00E340F2+3055714]
	GetHandleVerifier [0x00BE5AF0+637536]
	(No symbol) [0x00AE0A5D]
	(No symbol) [0x00ADDA28]
	(No symbol) [0x00ADDBC5]
	(No symbol) [0x00AD07F0]
	BaseThreadInitThunk [0x771BFCC9+25]
	RtlGetAppContainerNamedObjectPath [0x77DD809E+286]
	RtlGetAppContainerNamedObjectPath [0x77DD806E+238]

INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 17:08:23 KST)" (scheduled at 2025-01-16 17:07:23.706019+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 17:08:23 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchWindowException: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x00B4FD53+23747]
	(No symbol) [0x00AD7D54]
	(No symbol) [0x009ABE53]
	(No symbol) [0x0098D91B]
	(No symbol) [0x00A17EFF]
	(No symbol) [0x00A2AD49]
	(No symbol) [0x00A11B96]
	(No symbol) [0x009E3F3C]
	(No symbol) [0x009E4EBD]
	GetHandleVerifier [0x00E2AC73+3017699]
	GetHandleVerifier [0x00E3B93B+3086507]
	GetHandleVerifier [0x00E340F2+3055714]
	GetHandleVerifier [0x00BE5AF0+637536]
	(No symbol) [0x00AE0A5D]
	(No symbol) [0x00ADDA28]
	(No symbol) [0x00ADDBC5]
	(No symbol) [0x00AD07F0]
	BaseThreadInitThunk [0x771BFCC9+25]
	RtlGetAppContainerNamedObjectPath [0x77DD809E+286]
	RtlGetAppContainerNamedObjectPath [0x77DD806E+238]

INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\i\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawl_and_insert_data" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
INFO:werkzeug:[33mPress CTRL+C to quit[0m
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\i\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
<<<<<<< HEAD
INFO:WDM:====== WebDriver manager ======
INFO:WDM:====== WebDriver manager ======
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:11:48 KST)" (scheduled at 2025-01-15 17:10:48.987824+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:11:07 KST)" executed successfully
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000179F82A3E80>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/6052896cbb80a7be4e12ca11c240f513/element
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
<<<<<<< HEAD
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawl_and_insert_data" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
INFO:werkzeug:[33mPress CTRL+C to quit[0m
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawl_and_insert_data" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 524-771-621
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:17:58 KST)" (scheduled at 2025-01-15 17:17:58.873742+09:00)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:18:04 KST)" (scheduled at 2025-01-15 17:18:04.537794+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:18:58 KST)" executed successfully
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:19:04 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:19:58 KST)" (scheduled at 2025-01-15 17:18:58.873742+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:19:58 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:20:04 KST)" (scheduled at 2025-01-15 17:19:04.537794+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:20:04 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:20:58 KST)" (scheduled at 2025-01-15 17:19:58.873742+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:20:58 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:21:04 KST)" (scheduled at 2025-01-15 17:20:04.537794+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:21:04 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:21:58 KST)" (scheduled at 2025-01-15 17:20:58.873742+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:21:58 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:22:04 KST)" (scheduled at 2025-01-15 17:21:04.537794+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:22:04 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:22:58 KST)" (scheduled at 2025-01-15 17:21:58.873742+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:22:58 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:23:04 KST)" (scheduled at 2025-01-15 17:22:04.537794+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:23:04 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:23:58 KST)" (scheduled at 2025-01-15 17:22:58.873742+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:23:58 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:24:04 KST)" (scheduled at 2025-01-15 17:23:04.537794+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:24:04 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:24:58 KST)" (scheduled at 2025-01-15 17:23:58.873742+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:24:58 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:25:04 KST)" (scheduled at 2025-01-15 17:24:04.537794+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:25:04 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:25:58 KST)" (scheduled at 2025-01-15 17:24:58.873742+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:25:58 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:26:04 KST)" (scheduled at 2025-01-15 17:25:04.537794+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:26:04 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:26:58 KST)" (scheduled at 2025-01-15 17:25:58.873742+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:26:58 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:27:04 KST)" (scheduled at 2025-01-15 17:26:04.537794+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:27:04 KST)" executed successfully
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawl_and_insert_data" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
INFO:werkzeug:[33mPress CTRL+C to quit[0m
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawl_and_insert_data" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 524-771-621
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:27:23 KST)" (scheduled at 2025-01-15 17:27:23.783306+09:00)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:27:29 KST)" (scheduled at 2025-01-15 17:27:29.396128+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:28:23 KST)" executed successfully
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:28:29 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:29:23 KST)" (scheduled at 2025-01-15 17:28:23.783306+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:29:23 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:29:29 KST)" (scheduled at 2025-01-15 17:28:29.396128+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:29:29 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:30:23 KST)" (scheduled at 2025-01-15 17:29:23.783306+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:30:23 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:30:29 KST)" (scheduled at 2025-01-15 17:29:29.396128+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:30:29 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:31:23 KST)" (scheduled at 2025-01-15 17:30:23.783306+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:31:23 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:31:29 KST)" (scheduled at 2025-01-15 17:30:29.396128+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:31:29 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:32:23 KST)" (scheduled at 2025-01-15 17:31:23.783306+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:32:23 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:32:29 KST)" (scheduled at 2025-01-15 17:31:29.396128+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:32:29 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:33:23 KST)" (scheduled at 2025-01-15 17:32:23.783306+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:33:23 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:33:29 KST)" (scheduled at 2025-01-15 17:32:29.396128+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:33:29 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:34:23 KST)" (scheduled at 2025-01-15 17:33:23.783306+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:34:23 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:34:29 KST)" (scheduled at 2025-01-15 17:33:29.396128+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:34:29 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:35:23 KST)" (scheduled at 2025-01-15 17:34:23.783306+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:35:23 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:35:29 KST)" (scheduled at 2025-01-15 17:34:29.396128+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:35:29 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:36:23 KST)" (scheduled at 2025-01-15 17:35:23.783306+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:36:23 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:36:29 KST)" (scheduled at 2025-01-15 17:35:29.396128+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:36:29 KST)" executed successfully
INFO:werkzeug: * Detected change in 'C:\\ProgramData\\Anaconda3\\Lib\\re.py', reloading
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawl_and_insert_data" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 524-771-621
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:37:23 KST)" (scheduled at 2025-01-15 17:36:23.783306+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:37:23 KST)" executed successfully
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawl_and_insert_data" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
INFO:werkzeug:[33mPress CTRL+C to quit[0m
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawl_and_insert_data" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 524-771-621
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:37:52 KST)" (scheduled at 2025-01-15 17:37:52.878096+09:00)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:37:57 KST)" (scheduled at 2025-01-15 17:37:57.838981+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:38:52 KST)" executed successfully
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:38:57 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:39:52 KST)" (scheduled at 2025-01-15 17:38:52.878096+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:39:52 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:39:57 KST)" (scheduled at 2025-01-15 17:38:57.838981+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:39:57 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:40:52 KST)" (scheduled at 2025-01-15 17:39:52.878096+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:40:52 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:40:57 KST)" (scheduled at 2025-01-15 17:39:57.838981+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:40:57 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:41:52 KST)" (scheduled at 2025-01-15 17:40:52.878096+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:41:52 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:41:57 KST)" (scheduled at 2025-01-15 17:40:57.838981+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:41:57 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:42:52 KST)" (scheduled at 2025-01-15 17:41:52.878096+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:42:52 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:42:57 KST)" (scheduled at 2025-01-15 17:41:57.838981+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:42:57 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:43:52 KST)" (scheduled at 2025-01-15 17:42:52.878096+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:43:52 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:43:57 KST)" (scheduled at 2025-01-15 17:42:57.838981+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:43:57 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:44:52 KST)" (scheduled at 2025-01-15 17:43:52.878096+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:44:52 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:44:57 KST)" (scheduled at 2025-01-15 17:43:57.838981+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:44:57 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:45:52 KST)" (scheduled at 2025-01-15 17:44:52.878096+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:45:52 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:45:57 KST)" (scheduled at 2025-01-15 17:44:57.838981+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:45:57 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:46:52 KST)" (scheduled at 2025-01-15 17:45:52.878096+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:46:52 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:46:57 KST)" (scheduled at 2025-01-15 17:45:57.838981+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:46:57 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:47:52 KST)" (scheduled at 2025-01-15 17:46:52.878096+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:47:52 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:47:57 KST)" (scheduled at 2025-01-15 17:46:57.838981+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:47:57 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:48:52 KST)" (scheduled at 2025-01-15 17:47:52.878096+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:48:52 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:48:57 KST)" (scheduled at 2025-01-15 17:47:57.838981+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:48:57 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:49:52 KST)" (scheduled at 2025-01-15 17:48:52.878096+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:49:52 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:49:57 KST)" (scheduled at 2025-01-15 17:48:57.838981+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:49:57 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:50:52 KST)" (scheduled at 2025-01-15 17:49:52.878096+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:50:52 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:50:57 KST)" (scheduled at 2025-01-15 17:49:57.838981+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:50:57 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:51:52 KST)" (scheduled at 2025-01-15 17:50:52.878096+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:51:52 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:51:57 KST)" (scheduled at 2025-01-15 17:50:57.838981+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:51:57 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:52:52 KST)" (scheduled at 2025-01-15 17:51:52.878096+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:52:52 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:52:57 KST)" (scheduled at 2025-01-15 17:51:57.838981+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:52:57 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:53:52 KST)" (scheduled at 2025-01-15 17:52:52.878096+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:53:52 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:53:57 KST)" (scheduled at 2025-01-15 17:52:57.838981+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:53:57 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:54:52 KST)" (scheduled at 2025-01-15 17:53:52.878096+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:54:52 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:54:57 KST)" (scheduled at 2025-01-15 17:53:57.838981+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:54:57 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:55:52 KST)" (scheduled at 2025-01-15 17:54:52.878096+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:55:52 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:55:57 KST)" (scheduled at 2025-01-15 17:54:57.838981+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:55:57 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:56:52 KST)" (scheduled at 2025-01-15 17:55:52.878096+09:00)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:56:57 KST)" (scheduled at 2025-01-15 17:55:57.838981+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:56:52 KST)" executed successfully
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:56:57 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:57:52 KST)" (scheduled at 2025-01-15 17:56:52.878096+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:57:52 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:57:57 KST)" (scheduled at 2025-01-15 17:56:57.838981+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:57:57 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:58:52 KST)" (scheduled at 2025-01-15 17:57:52.878096+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:58:52 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:58:57 KST)" (scheduled at 2025-01-15 17:57:57.838981+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:58:57 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:59:52 KST)" (scheduled at 2025-01-15 17:58:52.878096+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:59:52 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:59:57 KST)" (scheduled at 2025-01-15 17:58:57.838981+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 17:59:57 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 18:00:52 KST)" (scheduled at 2025-01-15 17:59:52.878096+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 18:00:52 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 18:00:57 KST)" (scheduled at 2025-01-15 17:59:57.838981+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 18:00:57 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 18:01:52 KST)" (scheduled at 2025-01-15 18:00:52.878096+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 18:01:52 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 18:01:57 KST)" (scheduled at 2025-01-15 18:00:57.838981+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 18:01:57 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 18:02:52 KST)" (scheduled at 2025-01-15 18:01:52.878096+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 18:02:52 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 18:02:57 KST)" (scheduled at 2025-01-15 18:01:57.838981+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 18:02:57 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 18:03:52 KST)" (scheduled at 2025-01-15 18:02:52.878096+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 18:03:52 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 18:03:57 KST)" (scheduled at 2025-01-15 18:02:57.838981+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 18:03:57 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 18:04:52 KST)" (scheduled at 2025-01-15 18:03:52.878096+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 18:04:52 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 18:04:57 KST)" (scheduled at 2025-01-15 18:03:57.838981+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 18:04:57 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 18:05:52 KST)" (scheduled at 2025-01-15 18:04:52.878096+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 18:05:52 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 18:05:57 KST)" (scheduled at 2025-01-15 18:04:57.838981+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 18:05:57 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 18:06:52 KST)" (scheduled at 2025-01-15 18:05:52.878096+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 18:06:52 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 18:06:57 KST)" (scheduled at 2025-01-15 18:05:57.838981+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 18:06:57 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 18:07:52 KST)" (scheduled at 2025-01-15 18:06:52.878096+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 18:07:52 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 18:07:57 KST)" (scheduled at 2025-01-15 18:06:57.838981+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 18:07:57 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 18:08:52 KST)" (scheduled at 2025-01-15 18:07:52.878096+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 18:08:52 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 18:08:57 KST)" (scheduled at 2025-01-15 18:07:57.838981+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 18:08:57 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 18:09:52 KST)" (scheduled at 2025-01-15 18:08:52.878096+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 18:09:52 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 18:09:57 KST)" (scheduled at 2025-01-15 18:08:57.838981+09:00)
INFO:werkzeug: * Detected change in 'C:\\Users\\soldesk\\AppData\\Roaming\\Python\\Python310\\site-packages\\selenium\\webdriver\\remote\\webdriver.py', reloading
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 18:09:57 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchWindowException: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x00FFFD53+23747]
	(No symbol) [0x00F87D54]
	(No symbol) [0x00E5BE53]
	(No symbol) [0x00E3D91B]
	(No symbol) [0x00EC7EFF]
	(No symbol) [0x00EDAD49]
	(No symbol) [0x00EC1B96]
	(No symbol) [0x00E93F3C]
	(No symbol) [0x00E94EBD]
	GetHandleVerifier [0x012DAC73+3017699]
	GetHandleVerifier [0x012EB93B+3086507]
	GetHandleVerifier [0x012E40F2+3055714]
	GetHandleVerifier [0x01095AF0+637536]
	(No symbol) [0x00F90A5D]
	(No symbol) [0x00F8DA28]
	(No symbol) [0x00F8DBC5]
	(No symbol) [0x00F807F0]
	BaseThreadInitThunk [0x76E2FCC9+25]
	RtlGetAppContainerNamedObjectPath [0x77B2809E+286]
	RtlGetAppContainerNamedObjectPath [0x77B2806E+238]

INFO:werkzeug: * Detected change in 'C:\\Users\\soldesk\\AppData\\Roaming\\Python\\Python310\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py', reloading
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawl_and_insert_data" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 524-771-621
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 18:10:52 KST)" (scheduled at 2025-01-15 18:09:52.878096+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 18:10:52 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchWindowException: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x00FFFD53+23747]
	(No symbol) [0x00F87D54]
	(No symbol) [0x00E5BE53]
	(No symbol) [0x00E3D91B]
	(No symbol) [0x00EC7EFF]
	(No symbol) [0x00EDAD49]
	(No symbol) [0x00EC1B96]
	(No symbol) [0x00E93F3C]
	(No symbol) [0x00E94EBD]
	GetHandleVerifier [0x012DAC73+3017699]
	GetHandleVerifier [0x012EB93B+3086507]
	GetHandleVerifier [0x012E40F2+3055714]
	GetHandleVerifier [0x01095AF0+637536]
	(No symbol) [0x00F90A5D]
	(No symbol) [0x00F8DA28]
	(No symbol) [0x00F8DBC5]
	(No symbol) [0x00F807F0]
	BaseThreadInitThunk [0x76E2FCC9+25]
	RtlGetAppContainerNamedObjectPath [0x77B2809E+286]
	RtlGetAppContainerNamedObjectPath [0x77B2806E+238]

INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 18:10:06 KST)" (scheduled at 2025-01-15 18:10:06.624809+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 18:11:06 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchWindowException: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x00FFFD53+23747]
	(No symbol) [0x00F87D54]
	(No symbol) [0x00E5BE53]
	(No symbol) [0x00E3D91B]
	(No symbol) [0x00EC7EFF]
	(No symbol) [0x00EDAD49]
	(No symbol) [0x00EC1B96]
	(No symbol) [0x00E93F3C]
	(No symbol) [0x00E94EBD]
	GetHandleVerifier [0x012DAC73+3017699]
	GetHandleVerifier [0x012EB93B+3086507]
	GetHandleVerifier [0x012E40F2+3055714]
	GetHandleVerifier [0x01095AF0+637536]
	(No symbol) [0x00F90A5D]
	(No symbol) [0x00F8DA28]
	(No symbol) [0x00F8DBC5]
	(No symbol) [0x00F807F0]
	BaseThreadInitThunk [0x76E2FCC9+25]
	RtlGetAppContainerNamedObjectPath [0x77B2809E+286]
	RtlGetAppContainerNamedObjectPath [0x77B2806E+238]

INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 18:11:52 KST)" (scheduled at 2025-01-15 18:10:52.878096+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 18:11:52 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchWindowException: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x00FFFD53+23747]
	(No symbol) [0x00F87D54]
	(No symbol) [0x00E5BE53]
	(No symbol) [0x00E3D91B]
	(No symbol) [0x00EC7EFF]
	(No symbol) [0x00EDAD49]
	(No symbol) [0x00EC1B96]
	(No symbol) [0x00E93F3C]
	(No symbol) [0x00E94EBD]
	GetHandleVerifier [0x012DAC73+3017699]
	GetHandleVerifier [0x012EB93B+3086507]
	GetHandleVerifier [0x012E40F2+3055714]
	GetHandleVerifier [0x01095AF0+637536]
	(No symbol) [0x00F90A5D]
	(No symbol) [0x00F8DA28]
	(No symbol) [0x00F8DBC5]
	(No symbol) [0x00F807F0]
	BaseThreadInitThunk [0x76E2FCC9+25]
	RtlGetAppContainerNamedObjectPath [0x77B2809E+286]
	RtlGetAppContainerNamedObjectPath [0x77B2806E+238]

INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 18:12:06 KST)" (scheduled at 2025-01-15 18:11:06.624809+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 18:12:06 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchWindowException: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x00FFFD53+23747]
	(No symbol) [0x00F87D54]
	(No symbol) [0x00E5BE53]
	(No symbol) [0x00E3D91B]
	(No symbol) [0x00EC7EFF]
	(No symbol) [0x00EDAD49]
	(No symbol) [0x00EC1B96]
	(No symbol) [0x00E93F3C]
	(No symbol) [0x00E94EBD]
	GetHandleVerifier [0x012DAC73+3017699]
	GetHandleVerifier [0x012EB93B+3086507]
	GetHandleVerifier [0x012E40F2+3055714]
	GetHandleVerifier [0x01095AF0+637536]
	(No symbol) [0x00F90A5D]
	(No symbol) [0x00F8DA28]
	(No symbol) [0x00F8DBC5]
	(No symbol) [0x00F807F0]
	BaseThreadInitThunk [0x76E2FCC9+25]
	RtlGetAppContainerNamedObjectPath [0x77B2809E+286]
	RtlGetAppContainerNamedObjectPath [0x77B2806E+238]

INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 18:12:52 KST)" (scheduled at 2025-01-15 18:11:52.878096+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 18:12:52 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchWindowException: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x00FFFD53+23747]
	(No symbol) [0x00F87D54]
	(No symbol) [0x00E5BE53]
	(No symbol) [0x00E3D91B]
	(No symbol) [0x00EC7EFF]
	(No symbol) [0x00EDAD49]
	(No symbol) [0x00EC1B96]
	(No symbol) [0x00E93F3C]
	(No symbol) [0x00E94EBD]
	GetHandleVerifier [0x012DAC73+3017699]
	GetHandleVerifier [0x012EB93B+3086507]
	GetHandleVerifier [0x012E40F2+3055714]
	GetHandleVerifier [0x01095AF0+637536]
	(No symbol) [0x00F90A5D]
	(No symbol) [0x00F8DA28]
	(No symbol) [0x00F8DBC5]
	(No symbol) [0x00F807F0]
	BaseThreadInitThunk [0x76E2FCC9+25]
	RtlGetAppContainerNamedObjectPath [0x77B2809E+286]
	RtlGetAppContainerNamedObjectPath [0x77B2806E+238]

INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 18:13:06 KST)" (scheduled at 2025-01-15 18:12:06.624809+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 18:13:06 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchWindowException: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x00FFFD53+23747]
	(No symbol) [0x00F87D54]
	(No symbol) [0x00E5BE53]
	(No symbol) [0x00E3D91B]
	(No symbol) [0x00EC7EFF]
	(No symbol) [0x00EDAD49]
	(No symbol) [0x00EC1B96]
	(No symbol) [0x00E93F3C]
	(No symbol) [0x00E94EBD]
	GetHandleVerifier [0x012DAC73+3017699]
	GetHandleVerifier [0x012EB93B+3086507]
	GetHandleVerifier [0x012E40F2+3055714]
	GetHandleVerifier [0x01095AF0+637536]
	(No symbol) [0x00F90A5D]
	(No symbol) [0x00F8DA28]
	(No symbol) [0x00F8DBC5]
	(No symbol) [0x00F807F0]
	BaseThreadInitThunk [0x76E2FCC9+25]
	RtlGetAppContainerNamedObjectPath [0x77B2809E+286]
	RtlGetAppContainerNamedObjectPath [0x77B2806E+238]

INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 18:13:52 KST)" (scheduled at 2025-01-15 18:12:52.878096+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 18:13:52 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchWindowException: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x00FFFD53+23747]
	(No symbol) [0x00F87D54]
	(No symbol) [0x00E5BE53]
	(No symbol) [0x00E3D91B]
	(No symbol) [0x00EC7EFF]
	(No symbol) [0x00EDAD49]
	(No symbol) [0x00EC1B96]
	(No symbol) [0x00E93F3C]
	(No symbol) [0x00E94EBD]
	GetHandleVerifier [0x012DAC73+3017699]
	GetHandleVerifier [0x012EB93B+3086507]
	GetHandleVerifier [0x012E40F2+3055714]
	GetHandleVerifier [0x01095AF0+637536]
	(No symbol) [0x00F90A5D]
	(No symbol) [0x00F8DA28]
	(No symbol) [0x00F8DBC5]
	(No symbol) [0x00F807F0]
	BaseThreadInitThunk [0x76E2FCC9+25]
	RtlGetAppContainerNamedObjectPath [0x77B2809E+286]
	RtlGetAppContainerNamedObjectPath [0x77B2806E+238]

INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 18:14:06 KST)" (scheduled at 2025-01-15 18:13:06.624809+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 18:14:06 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchWindowException: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x00FFFD53+23747]
	(No symbol) [0x00F87D54]
	(No symbol) [0x00E5BE53]
	(No symbol) [0x00E3D91B]
	(No symbol) [0x00EC7EFF]
	(No symbol) [0x00EDAD49]
	(No symbol) [0x00EC1B96]
	(No symbol) [0x00E93F3C]
	(No symbol) [0x00E94EBD]
	GetHandleVerifier [0x012DAC73+3017699]
	GetHandleVerifier [0x012EB93B+3086507]
	GetHandleVerifier [0x012E40F2+3055714]
	GetHandleVerifier [0x01095AF0+637536]
	(No symbol) [0x00F90A5D]
	(No symbol) [0x00F8DA28]
	(No symbol) [0x00F8DBC5]
	(No symbol) [0x00F807F0]
	BaseThreadInitThunk [0x76E2FCC9+25]
	RtlGetAppContainerNamedObjectPath [0x77B2809E+286]
	RtlGetAppContainerNamedObjectPath [0x77B2806E+238]

INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 18:14:52 KST)" (scheduled at 2025-01-15 18:13:52.878096+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 18:14:52 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchWindowException: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x00FFFD53+23747]
	(No symbol) [0x00F87D54]
	(No symbol) [0x00E5BE53]
	(No symbol) [0x00E3D91B]
	(No symbol) [0x00EC7EFF]
	(No symbol) [0x00EDAD49]
	(No symbol) [0x00EC1B96]
	(No symbol) [0x00E93F3C]
	(No symbol) [0x00E94EBD]
	GetHandleVerifier [0x012DAC73+3017699]
	GetHandleVerifier [0x012EB93B+3086507]
	GetHandleVerifier [0x012E40F2+3055714]
	GetHandleVerifier [0x01095AF0+637536]
	(No symbol) [0x00F90A5D]
	(No symbol) [0x00F8DA28]
	(No symbol) [0x00F8DBC5]
	(No symbol) [0x00F807F0]
	BaseThreadInitThunk [0x76E2FCC9+25]
	RtlGetAppContainerNamedObjectPath [0x77B2809E+286]
	RtlGetAppContainerNamedObjectPath [0x77B2806E+238]

INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 18:15:06 KST)" (scheduled at 2025-01-15 18:14:06.624809+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 18:15:06 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchWindowException: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x00FFFD53+23747]
	(No symbol) [0x00F87D54]
	(No symbol) [0x00E5BE53]
	(No symbol) [0x00E3D91B]
	(No symbol) [0x00EC7EFF]
	(No symbol) [0x00EDAD49]
	(No symbol) [0x00EC1B96]
	(No symbol) [0x00E93F3C]
	(No symbol) [0x00E94EBD]
	GetHandleVerifier [0x012DAC73+3017699]
	GetHandleVerifier [0x012EB93B+3086507]
	GetHandleVerifier [0x012E40F2+3055714]
	GetHandleVerifier [0x01095AF0+637536]
	(No symbol) [0x00F90A5D]
	(No symbol) [0x00F8DA28]
	(No symbol) [0x00F8DBC5]
	(No symbol) [0x00F807F0]
	BaseThreadInitThunk [0x76E2FCC9+25]
	RtlGetAppContainerNamedObjectPath [0x77B2809E+286]
	RtlGetAppContainerNamedObjectPath [0x77B2806E+238]

INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 18:15:52 KST)" (scheduled at 2025-01-15 18:14:52.878096+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 18:15:52 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchWindowException: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x00FFFD53+23747]
	(No symbol) [0x00F87D54]
	(No symbol) [0x00E5BE53]
	(No symbol) [0x00E3D91B]
	(No symbol) [0x00EC7EFF]
	(No symbol) [0x00EDAD49]
	(No symbol) [0x00EC1B96]
	(No symbol) [0x00E93F3C]
	(No symbol) [0x00E94EBD]
	GetHandleVerifier [0x012DAC73+3017699]
	GetHandleVerifier [0x012EB93B+3086507]
	GetHandleVerifier [0x012E40F2+3055714]
	GetHandleVerifier [0x01095AF0+637536]
	(No symbol) [0x00F90A5D]
	(No symbol) [0x00F8DA28]
	(No symbol) [0x00F8DBC5]
	(No symbol) [0x00F807F0]
	BaseThreadInitThunk [0x76E2FCC9+25]
	RtlGetAppContainerNamedObjectPath [0x77B2809E+286]
	RtlGetAppContainerNamedObjectPath [0x77B2806E+238]

INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 18:16:06 KST)" (scheduled at 2025-01-15 18:15:06.624809+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 18:16:06 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchWindowException: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x00FFFD53+23747]
	(No symbol) [0x00F87D54]
	(No symbol) [0x00E5BE53]
	(No symbol) [0x00E3D91B]
	(No symbol) [0x00EC7EFF]
	(No symbol) [0x00EDAD49]
	(No symbol) [0x00EC1B96]
	(No symbol) [0x00E93F3C]
	(No symbol) [0x00E94EBD]
	GetHandleVerifier [0x012DAC73+3017699]
	GetHandleVerifier [0x012EB93B+3086507]
	GetHandleVerifier [0x012E40F2+3055714]
	GetHandleVerifier [0x01095AF0+637536]
	(No symbol) [0x00F90A5D]
	(No symbol) [0x00F8DA28]
	(No symbol) [0x00F8DBC5]
	(No symbol) [0x00F807F0]
	BaseThreadInitThunk [0x76E2FCC9+25]
	RtlGetAppContainerNamedObjectPath [0x77B2809E+286]
	RtlGetAppContainerNamedObjectPath [0x77B2806E+238]

INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 18:16:52 KST)" (scheduled at 2025-01-15 18:15:52.878096+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 18:16:52 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchWindowException: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x00FFFD53+23747]
	(No symbol) [0x00F87D54]
	(No symbol) [0x00E5BE53]
	(No symbol) [0x00E3D91B]
	(No symbol) [0x00EC7EFF]
	(No symbol) [0x00EDAD49]
	(No symbol) [0x00EC1B96]
	(No symbol) [0x00E93F3C]
	(No symbol) [0x00E94EBD]
	GetHandleVerifier [0x012DAC73+3017699]
	GetHandleVerifier [0x012EB93B+3086507]
	GetHandleVerifier [0x012E40F2+3055714]
	GetHandleVerifier [0x01095AF0+637536]
	(No symbol) [0x00F90A5D]
	(No symbol) [0x00F8DA28]
	(No symbol) [0x00F8DBC5]
	(No symbol) [0x00F807F0]
	BaseThreadInitThunk [0x76E2FCC9+25]
	RtlGetAppContainerNamedObjectPath [0x77B2809E+286]
	RtlGetAppContainerNamedObjectPath [0x77B2806E+238]

INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 18:17:06 KST)" (scheduled at 2025-01-15 18:16:06.624809+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 18:17:06 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchWindowException: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x00FFFD53+23747]
	(No symbol) [0x00F87D54]
	(No symbol) [0x00E5BE53]
	(No symbol) [0x00E3D91B]
	(No symbol) [0x00EC7EFF]
	(No symbol) [0x00EDAD49]
	(No symbol) [0x00EC1B96]
	(No symbol) [0x00E93F3C]
	(No symbol) [0x00E94EBD]
	GetHandleVerifier [0x012DAC73+3017699]
	GetHandleVerifier [0x012EB93B+3086507]
	GetHandleVerifier [0x012E40F2+3055714]
	GetHandleVerifier [0x01095AF0+637536]
	(No symbol) [0x00F90A5D]
	(No symbol) [0x00F8DA28]
	(No symbol) [0x00F8DBC5]
	(No symbol) [0x00F807F0]
	BaseThreadInitThunk [0x76E2FCC9+25]
	RtlGetAppContainerNamedObjectPath [0x77B2809E+286]
	RtlGetAppContainerNamedObjectPath [0x77B2806E+238]

INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 18:17:52 KST)" (scheduled at 2025-01-15 18:16:52.878096+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 18:17:52 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchWindowException: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x00FFFD53+23747]
	(No symbol) [0x00F87D54]
	(No symbol) [0x00E5BE53]
	(No symbol) [0x00E3D91B]
	(No symbol) [0x00EC7EFF]
	(No symbol) [0x00EDAD49]
	(No symbol) [0x00EC1B96]
	(No symbol) [0x00E93F3C]
	(No symbol) [0x00E94EBD]
	GetHandleVerifier [0x012DAC73+3017699]
	GetHandleVerifier [0x012EB93B+3086507]
	GetHandleVerifier [0x012E40F2+3055714]
	GetHandleVerifier [0x01095AF0+637536]
	(No symbol) [0x00F90A5D]
	(No symbol) [0x00F8DA28]
	(No symbol) [0x00F8DBC5]
	(No symbol) [0x00F807F0]
	BaseThreadInitThunk [0x76E2FCC9+25]
	RtlGetAppContainerNamedObjectPath [0x77B2809E+286]
	RtlGetAppContainerNamedObjectPath [0x77B2806E+238]

INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 18:18:06 KST)" (scheduled at 2025-01-15 18:17:06.624809+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 18:18:06 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchWindowException: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x00FFFD53+23747]
	(No symbol) [0x00F87D54]
	(No symbol) [0x00E5BE53]
	(No symbol) [0x00E3D91B]
	(No symbol) [0x00EC7EFF]
	(No symbol) [0x00EDAD49]
	(No symbol) [0x00EC1B96]
	(No symbol) [0x00E93F3C]
	(No symbol) [0x00E94EBD]
	GetHandleVerifier [0x012DAC73+3017699]
	GetHandleVerifier [0x012EB93B+3086507]
	GetHandleVerifier [0x012E40F2+3055714]
	GetHandleVerifier [0x01095AF0+637536]
	(No symbol) [0x00F90A5D]
	(No symbol) [0x00F8DA28]
	(No symbol) [0x00F8DBC5]
	(No symbol) [0x00F807F0]
	BaseThreadInitThunk [0x76E2FCC9+25]
	RtlGetAppContainerNamedObjectPath [0x77B2809E+286]
	RtlGetAppContainerNamedObjectPath [0x77B2806E+238]

INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 18:18:52 KST)" (scheduled at 2025-01-15 18:17:52.878096+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 18:18:52 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchWindowException: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x00FFFD53+23747]
	(No symbol) [0x00F87D54]
	(No symbol) [0x00E5BE53]
	(No symbol) [0x00E3D91B]
	(No symbol) [0x00EC7EFF]
	(No symbol) [0x00EDAD49]
	(No symbol) [0x00EC1B96]
	(No symbol) [0x00E93F3C]
	(No symbol) [0x00E94EBD]
	GetHandleVerifier [0x012DAC73+3017699]
	GetHandleVerifier [0x012EB93B+3086507]
	GetHandleVerifier [0x012E40F2+3055714]
	GetHandleVerifier [0x01095AF0+637536]
	(No symbol) [0x00F90A5D]
	(No symbol) [0x00F8DA28]
	(No symbol) [0x00F8DBC5]
	(No symbol) [0x00F807F0]
	BaseThreadInitThunk [0x76E2FCC9+25]
	RtlGetAppContainerNamedObjectPath [0x77B2809E+286]
	RtlGetAppContainerNamedObjectPath [0x77B2806E+238]

INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 18:19:06 KST)" (scheduled at 2025-01-15 18:18:06.624809+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 18:19:06 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchWindowException: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x00FFFD53+23747]
	(No symbol) [0x00F87D54]
	(No symbol) [0x00E5BE53]
	(No symbol) [0x00E3D91B]
	(No symbol) [0x00EC7EFF]
	(No symbol) [0x00EDAD49]
	(No symbol) [0x00EC1B96]
	(No symbol) [0x00E93F3C]
	(No symbol) [0x00E94EBD]
	GetHandleVerifier [0x012DAC73+3017699]
	GetHandleVerifier [0x012EB93B+3086507]
	GetHandleVerifier [0x012E40F2+3055714]
	GetHandleVerifier [0x01095AF0+637536]
	(No symbol) [0x00F90A5D]
	(No symbol) [0x00F8DA28]
	(No symbol) [0x00F8DBC5]
	(No symbol) [0x00F807F0]
	BaseThreadInitThunk [0x76E2FCC9+25]
	RtlGetAppContainerNamedObjectPath [0x77B2809E+286]
	RtlGetAppContainerNamedObjectPath [0x77B2806E+238]

INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 18:19:52 KST)" (scheduled at 2025-01-15 18:18:52.878096+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 18:19:52 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchWindowException: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x00FFFD53+23747]
	(No symbol) [0x00F87D54]
	(No symbol) [0x00E5BE53]
	(No symbol) [0x00E3D91B]
	(No symbol) [0x00EC7EFF]
	(No symbol) [0x00EDAD49]
	(No symbol) [0x00EC1B96]
	(No symbol) [0x00E93F3C]
	(No symbol) [0x00E94EBD]
	GetHandleVerifier [0x012DAC73+3017699]
	GetHandleVerifier [0x012EB93B+3086507]
	GetHandleVerifier [0x012E40F2+3055714]
	GetHandleVerifier [0x01095AF0+637536]
	(No symbol) [0x00F90A5D]
	(No symbol) [0x00F8DA28]
	(No symbol) [0x00F8DBC5]
	(No symbol) [0x00F807F0]
	BaseThreadInitThunk [0x76E2FCC9+25]
	RtlGetAppContainerNamedObjectPath [0x77B2809E+286]
	RtlGetAppContainerNamedObjectPath [0x77B2806E+238]

INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 18:20:06 KST)" (scheduled at 2025-01-15 18:19:06.624809+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 18:20:06 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchWindowException: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x00FFFD53+23747]
	(No symbol) [0x00F87D54]
	(No symbol) [0x00E5BE53]
	(No symbol) [0x00E3D91B]
	(No symbol) [0x00EC7EFF]
	(No symbol) [0x00EDAD49]
	(No symbol) [0x00EC1B96]
	(No symbol) [0x00E93F3C]
	(No symbol) [0x00E94EBD]
	GetHandleVerifier [0x012DAC73+3017699]
	GetHandleVerifier [0x012EB93B+3086507]
	GetHandleVerifier [0x012E40F2+3055714]
	GetHandleVerifier [0x01095AF0+637536]
	(No symbol) [0x00F90A5D]
	(No symbol) [0x00F8DA28]
	(No symbol) [0x00F8DBC5]
	(No symbol) [0x00F807F0]
	BaseThreadInitThunk [0x76E2FCC9+25]
	RtlGetAppContainerNamedObjectPath [0x77B2809E+286]
	RtlGetAppContainerNamedObjectPath [0x77B2806E+238]

INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 18:20:52 KST)" (scheduled at 2025-01-15 18:19:52.878096+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 18:20:52 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchWindowException: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x00FFFD53+23747]
	(No symbol) [0x00F87D54]
	(No symbol) [0x00E5BE53]
	(No symbol) [0x00E3D91B]
	(No symbol) [0x00EC7EFF]
	(No symbol) [0x00EDAD49]
	(No symbol) [0x00EC1B96]
	(No symbol) [0x00E93F3C]
	(No symbol) [0x00E94EBD]
	GetHandleVerifier [0x012DAC73+3017699]
	GetHandleVerifier [0x012EB93B+3086507]
	GetHandleVerifier [0x012E40F2+3055714]
	GetHandleVerifier [0x01095AF0+637536]
	(No symbol) [0x00F90A5D]
	(No symbol) [0x00F8DA28]
	(No symbol) [0x00F8DBC5]
	(No symbol) [0x00F807F0]
	BaseThreadInitThunk [0x76E2FCC9+25]
	RtlGetAppContainerNamedObjectPath [0x77B2809E+286]
	RtlGetAppContainerNamedObjectPath [0x77B2806E+238]

INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 18:21:06 KST)" (scheduled at 2025-01-15 18:20:06.624809+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 18:21:06 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchWindowException: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x00FFFD53+23747]
	(No symbol) [0x00F87D54]
	(No symbol) [0x00E5BE53]
	(No symbol) [0x00E3D91B]
	(No symbol) [0x00EC7EFF]
	(No symbol) [0x00EDAD49]
	(No symbol) [0x00EC1B96]
	(No symbol) [0x00E93F3C]
	(No symbol) [0x00E94EBD]
	GetHandleVerifier [0x012DAC73+3017699]
	GetHandleVerifier [0x012EB93B+3086507]
	GetHandleVerifier [0x012E40F2+3055714]
	GetHandleVerifier [0x01095AF0+637536]
	(No symbol) [0x00F90A5D]
	(No symbol) [0x00F8DA28]
	(No symbol) [0x00F8DBC5]
	(No symbol) [0x00F807F0]
	BaseThreadInitThunk [0x76E2FCC9+25]
	RtlGetAppContainerNamedObjectPath [0x77B2809E+286]
	RtlGetAppContainerNamedObjectPath [0x77B2806E+238]

INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 18:21:52 KST)" (scheduled at 2025-01-15 18:20:52.878096+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 18:21:52 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchWindowException: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x00FFFD53+23747]
	(No symbol) [0x00F87D54]
	(No symbol) [0x00E5BE53]
	(No symbol) [0x00E3D91B]
	(No symbol) [0x00EC7EFF]
	(No symbol) [0x00EDAD49]
	(No symbol) [0x00EC1B96]
	(No symbol) [0x00E93F3C]
	(No symbol) [0x00E94EBD]
	GetHandleVerifier [0x012DAC73+3017699]
	GetHandleVerifier [0x012EB93B+3086507]
	GetHandleVerifier [0x012E40F2+3055714]
	GetHandleVerifier [0x01095AF0+637536]
	(No symbol) [0x00F90A5D]
	(No symbol) [0x00F8DA28]
	(No symbol) [0x00F8DBC5]
	(No symbol) [0x00F807F0]
	BaseThreadInitThunk [0x76E2FCC9+25]
	RtlGetAppContainerNamedObjectPath [0x77B2809E+286]
	RtlGetAppContainerNamedObjectPath [0x77B2806E+238]

INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 18:22:06 KST)" (scheduled at 2025-01-15 18:21:06.624809+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 18:22:06 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchWindowException: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x00FFFD53+23747]
	(No symbol) [0x00F87D54]
	(No symbol) [0x00E5BE53]
	(No symbol) [0x00E3D91B]
	(No symbol) [0x00EC7EFF]
	(No symbol) [0x00EDAD49]
	(No symbol) [0x00EC1B96]
	(No symbol) [0x00E93F3C]
	(No symbol) [0x00E94EBD]
	GetHandleVerifier [0x012DAC73+3017699]
	GetHandleVerifier [0x012EB93B+3086507]
	GetHandleVerifier [0x012E40F2+3055714]
	GetHandleVerifier [0x01095AF0+637536]
	(No symbol) [0x00F90A5D]
	(No symbol) [0x00F8DA28]
	(No symbol) [0x00F8DBC5]
	(No symbol) [0x00F807F0]
	BaseThreadInitThunk [0x76E2FCC9+25]
	RtlGetAppContainerNamedObjectPath [0x77B2809E+286]
	RtlGetAppContainerNamedObjectPath [0x77B2806E+238]

INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 18:22:52 KST)" (scheduled at 2025-01-15 18:21:52.878096+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 18:22:52 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchWindowException: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x00FFFD53+23747]
	(No symbol) [0x00F87D54]
	(No symbol) [0x00E5BE53]
	(No symbol) [0x00E3D91B]
	(No symbol) [0x00EC7EFF]
	(No symbol) [0x00EDAD49]
	(No symbol) [0x00EC1B96]
	(No symbol) [0x00E93F3C]
	(No symbol) [0x00E94EBD]
	GetHandleVerifier [0x012DAC73+3017699]
	GetHandleVerifier [0x012EB93B+3086507]
	GetHandleVerifier [0x012E40F2+3055714]
	GetHandleVerifier [0x01095AF0+637536]
	(No symbol) [0x00F90A5D]
	(No symbol) [0x00F8DA28]
	(No symbol) [0x00F8DBC5]
	(No symbol) [0x00F807F0]
	BaseThreadInitThunk [0x76E2FCC9+25]
	RtlGetAppContainerNamedObjectPath [0x77B2809E+286]
	RtlGetAppContainerNamedObjectPath [0x77B2806E+238]

INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 18:23:06 KST)" (scheduled at 2025-01-15 18:22:06.624809+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 18:23:06 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchWindowException: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x00FFFD53+23747]
	(No symbol) [0x00F87D54]
	(No symbol) [0x00E5BE53]
	(No symbol) [0x00E3D91B]
	(No symbol) [0x00EC7EFF]
	(No symbol) [0x00EDAD49]
	(No symbol) [0x00EC1B96]
	(No symbol) [0x00E93F3C]
	(No symbol) [0x00E94EBD]
	GetHandleVerifier [0x012DAC73+3017699]
	GetHandleVerifier [0x012EB93B+3086507]
	GetHandleVerifier [0x012E40F2+3055714]
	GetHandleVerifier [0x01095AF0+637536]
	(No symbol) [0x00F90A5D]
	(No symbol) [0x00F8DA28]
	(No symbol) [0x00F8DBC5]
	(No symbol) [0x00F807F0]
	BaseThreadInitThunk [0x76E2FCC9+25]
	RtlGetAppContainerNamedObjectPath [0x77B2809E+286]
	RtlGetAppContainerNamedObjectPath [0x77B2806E+238]

INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 18:23:52 KST)" (scheduled at 2025-01-15 18:22:52.878096+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 18:23:52 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchWindowException: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x00FFFD53+23747]
	(No symbol) [0x00F87D54]
	(No symbol) [0x00E5BE53]
	(No symbol) [0x00E3D91B]
	(No symbol) [0x00EC7EFF]
	(No symbol) [0x00EDAD49]
	(No symbol) [0x00EC1B96]
	(No symbol) [0x00E93F3C]
	(No symbol) [0x00E94EBD]
	GetHandleVerifier [0x012DAC73+3017699]
	GetHandleVerifier [0x012EB93B+3086507]
	GetHandleVerifier [0x012E40F2+3055714]
	GetHandleVerifier [0x01095AF0+637536]
	(No symbol) [0x00F90A5D]
	(No symbol) [0x00F8DA28]
	(No symbol) [0x00F8DBC5]
	(No symbol) [0x00F807F0]
	BaseThreadInitThunk [0x76E2FCC9+25]
	RtlGetAppContainerNamedObjectPath [0x77B2809E+286]
	RtlGetAppContainerNamedObjectPath [0x77B2806E+238]

INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 18:24:06 KST)" (scheduled at 2025-01-15 18:23:06.624809+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 18:24:06 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchWindowException: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x00FFFD53+23747]
	(No symbol) [0x00F87D54]
	(No symbol) [0x00E5BE53]
	(No symbol) [0x00E3D91B]
	(No symbol) [0x00EC7EFF]
	(No symbol) [0x00EDAD49]
	(No symbol) [0x00EC1B96]
	(No symbol) [0x00E93F3C]
	(No symbol) [0x00E94EBD]
	GetHandleVerifier [0x012DAC73+3017699]
	GetHandleVerifier [0x012EB93B+3086507]
	GetHandleVerifier [0x012E40F2+3055714]
	GetHandleVerifier [0x01095AF0+637536]
	(No symbol) [0x00F90A5D]
	(No symbol) [0x00F8DA28]
	(No symbol) [0x00F8DBC5]
	(No symbol) [0x00F807F0]
	BaseThreadInitThunk [0x76E2FCC9+25]
	RtlGetAppContainerNamedObjectPath [0x77B2809E+286]
	RtlGetAppContainerNamedObjectPath [0x77B2806E+238]

INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 18:24:52 KST)" (scheduled at 2025-01-15 18:23:52.878096+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 18:24:52 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchWindowException: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x00FFFD53+23747]
	(No symbol) [0x00F87D54]
	(No symbol) [0x00E5BE53]
	(No symbol) [0x00E3D91B]
	(No symbol) [0x00EC7EFF]
	(No symbol) [0x00EDAD49]
	(No symbol) [0x00EC1B96]
	(No symbol) [0x00E93F3C]
	(No symbol) [0x00E94EBD]
	GetHandleVerifier [0x012DAC73+3017699]
	GetHandleVerifier [0x012EB93B+3086507]
	GetHandleVerifier [0x012E40F2+3055714]
	GetHandleVerifier [0x01095AF0+637536]
	(No symbol) [0x00F90A5D]
	(No symbol) [0x00F8DA28]
	(No symbol) [0x00F8DBC5]
	(No symbol) [0x00F807F0]
	BaseThreadInitThunk [0x76E2FCC9+25]
	RtlGetAppContainerNamedObjectPath [0x77B2809E+286]
	RtlGetAppContainerNamedObjectPath [0x77B2806E+238]

INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 18:25:06 KST)" (scheduled at 2025-01-15 18:24:06.624809+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 18:25:06 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchWindowException: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x00FFFD53+23747]
	(No symbol) [0x00F87D54]
	(No symbol) [0x00E5BE53]
	(No symbol) [0x00E3D91B]
	(No symbol) [0x00EC7EFF]
	(No symbol) [0x00EDAD49]
	(No symbol) [0x00EC1B96]
	(No symbol) [0x00E93F3C]
	(No symbol) [0x00E94EBD]
	GetHandleVerifier [0x012DAC73+3017699]
	GetHandleVerifier [0x012EB93B+3086507]
	GetHandleVerifier [0x012E40F2+3055714]
	GetHandleVerifier [0x01095AF0+637536]
	(No symbol) [0x00F90A5D]
	(No symbol) [0x00F8DA28]
	(No symbol) [0x00F8DBC5]
	(No symbol) [0x00F807F0]
	BaseThreadInitThunk [0x76E2FCC9+25]
	RtlGetAppContainerNamedObjectPath [0x77B2809E+286]
	RtlGetAppContainerNamedObjectPath [0x77B2806E+238]

INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 18:25:52 KST)" (scheduled at 2025-01-15 18:24:52.878096+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 18:25:52 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchWindowException: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x00FFFD53+23747]
	(No symbol) [0x00F87D54]
	(No symbol) [0x00E5BE53]
	(No symbol) [0x00E3D91B]
	(No symbol) [0x00EC7EFF]
	(No symbol) [0x00EDAD49]
	(No symbol) [0x00EC1B96]
	(No symbol) [0x00E93F3C]
	(No symbol) [0x00E94EBD]
	GetHandleVerifier [0x012DAC73+3017699]
	GetHandleVerifier [0x012EB93B+3086507]
	GetHandleVerifier [0x012E40F2+3055714]
	GetHandleVerifier [0x01095AF0+637536]
	(No symbol) [0x00F90A5D]
	(No symbol) [0x00F8DA28]
	(No symbol) [0x00F8DBC5]
	(No symbol) [0x00F807F0]
	BaseThreadInitThunk [0x76E2FCC9+25]
	RtlGetAppContainerNamedObjectPath [0x77B2809E+286]
	RtlGetAppContainerNamedObjectPath [0x77B2806E+238]

INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 18:26:06 KST)" (scheduled at 2025-01-15 18:25:06.624809+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 18:26:06 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchWindowException: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x00FFFD53+23747]
	(No symbol) [0x00F87D54]
	(No symbol) [0x00E5BE53]
	(No symbol) [0x00E3D91B]
	(No symbol) [0x00EC7EFF]
	(No symbol) [0x00EDAD49]
	(No symbol) [0x00EC1B96]
	(No symbol) [0x00E93F3C]
	(No symbol) [0x00E94EBD]
	GetHandleVerifier [0x012DAC73+3017699]
	GetHandleVerifier [0x012EB93B+3086507]
	GetHandleVerifier [0x012E40F2+3055714]
	GetHandleVerifier [0x01095AF0+637536]
	(No symbol) [0x00F90A5D]
	(No symbol) [0x00F8DA28]
	(No symbol) [0x00F8DBC5]
	(No symbol) [0x00F807F0]
	BaseThreadInitThunk [0x76E2FCC9+25]
	RtlGetAppContainerNamedObjectPath [0x77B2809E+286]
	RtlGetAppContainerNamedObjectPath [0x77B2806E+238]

INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 18:26:52 KST)" (scheduled at 2025-01-15 18:25:52.878096+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 18:26:52 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchWindowException: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x00FFFD53+23747]
	(No symbol) [0x00F87D54]
	(No symbol) [0x00E5BE53]
	(No symbol) [0x00E3D91B]
	(No symbol) [0x00EC7EFF]
	(No symbol) [0x00EDAD49]
	(No symbol) [0x00EC1B96]
	(No symbol) [0x00E93F3C]
	(No symbol) [0x00E94EBD]
	GetHandleVerifier [0x012DAC73+3017699]
	GetHandleVerifier [0x012EB93B+3086507]
	GetHandleVerifier [0x012E40F2+3055714]
	GetHandleVerifier [0x01095AF0+637536]
	(No symbol) [0x00F90A5D]
	(No symbol) [0x00F8DA28]
	(No symbol) [0x00F8DBC5]
	(No symbol) [0x00F807F0]
	BaseThreadInitThunk [0x76E2FCC9+25]
	RtlGetAppContainerNamedObjectPath [0x77B2809E+286]
	RtlGetAppContainerNamedObjectPath [0x77B2806E+238]

INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 18:27:06 KST)" (scheduled at 2025-01-15 18:26:06.624809+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-15 18:27:06 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchWindowException: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x00FFFD53+23747]
	(No symbol) [0x00F87D54]
	(No symbol) [0x00E5BE53]
	(No symbol) [0x00E3D91B]
	(No symbol) [0x00EC7EFF]
	(No symbol) [0x00EDAD49]
	(No symbol) [0x00EC1B96]
	(No symbol) [0x00E93F3C]
	(No symbol) [0x00E94EBD]
	GetHandleVerifier [0x012DAC73+3017699]
	GetHandleVerifier [0x012EB93B+3086507]
	GetHandleVerifier [0x012E40F2+3055714]
	GetHandleVerifier [0x01095AF0+637536]
	(No symbol) [0x00F90A5D]
	(No symbol) [0x00F8DA28]
	(No symbol) [0x00F8DBC5]
	(No symbol) [0x00F807F0]
	BaseThreadInitThunk [0x76E2FCC9+25]
	RtlGetAppContainerNamedObjectPath [0x77B2809E+286]
	RtlGetAppContainerNamedObjectPath [0x77B2806E+238]

INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:WebDriver version 131.0.6778.264 selected
INFO:WDM:Modern chrome version https://storage.googleapis.com/chrome-for-testing-public/131.0.6778.264/win32/chromedriver-win32.zip
INFO:WDM:About to download new driver from https://storage.googleapis.com/chrome-for-testing-public/131.0.6778.264/win32/chromedriver-win32.zip
INFO:WDM:Driver downloading response is 200
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver has been saved in cache [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264]
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawl_and_insert_data" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
INFO:werkzeug:[33mPress CTRL+C to quit[0m
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawl_and_insert_data" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 524-771-621
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 09:43:51 KST)" (scheduled at 2025-01-16 09:43:51.214435+09:00)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 09:43:59 KST)" (scheduled at 2025-01-16 09:43:59.096354+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 09:44:59 KST)" executed successfully
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 09:44:51 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 09:45:51 KST)" (scheduled at 2025-01-16 09:44:51.214435+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022102B935E0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 09:45:59 KST)" (scheduled at 2025-01-16 09:44:59.096354+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000002210287F6D0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105366A10>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 09:45:59 KST)" executed successfully
INFO:werkzeug: * Detected change in 'C:\\Users\\soldesk\\AppData\\Roaming\\Python\\Python310\\site-packages\\apscheduler\\executors\\base.py', reloading
INFO:werkzeug: * Detected change in 'C:\\Users\\soldesk\\AppData\\Roaming\\Python\\Python310\\site-packages\\selenium\\webdriver\\remote\\webdriver.py', reloading
INFO:werkzeug: * Detected change in 'C:\\Users\\soldesk\\AppData\\Roaming\\Python\\Python310\\site-packages\\selenium\\webdriver\\remote\\remote_connection.py', reloading
INFO:werkzeug: * Detected change in 'C:\\ProgramData\\Anaconda3\\Lib\\site-packages\\urllib3\\request.py', reloading
INFO:werkzeug: * Detected change in 'C:\\ProgramData\\Anaconda3\\Lib\\site-packages\\urllib3\\poolmanager.py', reloading
INFO:werkzeug: * Detected change in 'C:\\ProgramData\\Anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py', reloading
INFO:werkzeug: * Detected change in 'C:\\ProgramData\\Anaconda3\\Lib\\site-packages\\urllib3\\util\\retry.py', reloading
INFO:werkzeug: * Detected change in 'C:\\ProgramData\\Anaconda3\\Lib\\site-packages\\urllib3\\connection.py', reloading
INFO:werkzeug: * Detected change in 'C:\\ProgramData\\Anaconda3\\Lib\\http\\client.py', reloading
INFO:werkzeug: * Detected change in 'C:\\ProgramData\\Anaconda3\\Lib\\site-packages\\urllib3\\util\\connection.py', reloading
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 09:45:51 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000022105366B00>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=50002): Max retries exceeded with url: /session/d887fac72ff9a8f53556ebae5c04ee3b/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105366B00>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawl_and_insert_data" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 524-771-621
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 09:46:51 KST)" (scheduled at 2025-01-16 09:45:51.214435+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221053667A0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105365E70>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105366260>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 09:46:51 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000022105366380>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=50002): Max retries exceeded with url: /session/d887fac72ff9a8f53556ebae5c04ee3b/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105366380>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 09:46:21 KST)" (scheduled at 2025-01-16 09:46:21.249891+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 09:47:21 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 09:47:51 KST)" (scheduled at 2025-01-16 09:46:51.214435+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105365FF0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221053665F0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105365720>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 09:47:51 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000022105365630>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=50002): Max retries exceeded with url: /session/d887fac72ff9a8f53556ebae5c04ee3b/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105365630>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 09:48:21 KST)" (scheduled at 2025-01-16 09:47:21.249891+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 09:48:21 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 09:48:51 KST)" (scheduled at 2025-01-16 09:47:51.214435+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221053654B0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105365690>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105365A20>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 09:48:51 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000022105365B70>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=50002): Max retries exceeded with url: /session/d887fac72ff9a8f53556ebae5c04ee3b/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105365B70>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 09:49:21 KST)" (scheduled at 2025-01-16 09:48:21.249891+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 09:49:21 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 09:49:51 KST)" (scheduled at 2025-01-16 09:48:51.214435+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105366C50>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105364880>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221053655A0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 09:49:51 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000022105366560>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=50002): Max retries exceeded with url: /session/d887fac72ff9a8f53556ebae5c04ee3b/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105366560>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 09:50:21 KST)" (scheduled at 2025-01-16 09:49:21.249891+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 09:50:21 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 09:50:51 KST)" (scheduled at 2025-01-16 09:49:51.214435+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105366830>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221053663B0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105366290>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 09:50:51 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000022105366230>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=50002): Max retries exceeded with url: /session/d887fac72ff9a8f53556ebae5c04ee3b/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105366230>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 09:51:21 KST)" (scheduled at 2025-01-16 09:50:21.249891+09:00)
INFO:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 09:51:21 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 09:51:51 KST)" (scheduled at 2025-01-16 09:50:51.214435+09:00)
INFO:werkzeug: * Detected change in 'C:\\ProgramData\\Anaconda3\\Scripts\\conda-script.py', reloading
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105366A10>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105366D40>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105366EF0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawl_and_insert_data" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 524-771-621
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 09:51:51 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000022105366FB0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=50002): Max retries exceeded with url: /session/d887fac72ff9a8f53556ebae5c04ee3b/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105366FB0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
INFO:werkzeug: * Detected change in 'C:\\kd\\ws_java\\team4_v2sbm3c\\src\\main\\python\\crawling.py', reloading
INFO:werkzeug: * Detected change in 'C:\\kd\\ws_java\\team4_v2sbm3c\\src\\main\\python\\crawling.py', reloading
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 09:52:51 KST)" (scheduled at 2025-01-16 09:51:51.214435+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105367220>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105367340>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawl_and_insert_data" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 524-771-621
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105367460>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 09:52:51 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x00000221053675B0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=50002): Max retries exceeded with url: /session/d887fac72ff9a8f53556ebae5c04ee3b/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221053675B0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 09:53:51 KST)" (scheduled at 2025-01-16 09:52:51.214435+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221053677C0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105367940>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 09:53:00 KST)" (scheduled at 2025-01-16 09:53:00.721664+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000002210290B4C0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 09:54:00 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 269, in crawl_and_insert_data
    title = bs.select('#main-content > article > div:nth-child(1) > h1')[0].text
IndexError: list index out of range
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 09:53:51 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000022102B939D0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=50002): Max retries exceeded with url: /session/d887fac72ff9a8f53556ebae5c04ee3b/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022102B939D0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 09:54:51 KST)" (scheduled at 2025-01-16 09:53:51.214435+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FF880>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FF700>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 09:55:00 KST)" (scheduled at 2025-01-16 09:54:00.721664+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 09:55:00 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 269, in crawl_and_insert_data
    title = bs.select('#main-content > article > div:nth-child(1) > h1')[0].text
IndexError: list index out of range
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FF6A0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 09:54:51 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x00000221052FEDA0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=50002): Max retries exceeded with url: /session/d887fac72ff9a8f53556ebae5c04ee3b/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FEDA0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
INFO:werkzeug: * Detected change in 'C:\\kd\\ws_java\\team4_v2sbm3c\\src\\main\\python\\pernews.py', reloading
INFO:werkzeug: * Detected change in 'C:\\ProgramData\\Anaconda3\\Lib\\logging\\__init__.py', reloading
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawl_and_insert_data" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 524-771-621
INFO:werkzeug: * Detected change in 'C:\\ProgramData\\Anaconda3\\envs\\ai\\Lib\\site-packages\\tornado\\web.py', reloading
INFO:werkzeug: * Detected change in 'C:\\ProgramData\\Anaconda3\\envs\\ai\\Lib\\site-packages\\jupyter_server\\services\\kernels\\websocket.py', reloading
INFO:werkzeug: * Detected change in 'C:\\ProgramData\\Anaconda3\\envs\\ai\\Lib\\site-packages\\tornado\\websocket.py', reloading
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawl_and_insert_data" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 524-771-621
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 09:55:51 KST)" (scheduled at 2025-01-16 09:54:51.214435+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FDD20>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FE080>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FE2F0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 09:55:51 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x00000221052FDE70>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=50002): Max retries exceeded with url: /session/d887fac72ff9a8f53556ebae5c04ee3b/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FDE70>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
INFO:werkzeug: * Detected change in 'C:\\kd\\ws_java\\team4_v2sbm3c\\src\\main\\python\\crawling.py', reloading
INFO:werkzeug: * Detected change in 'C:\\kd\\ws_java\\team4_v2sbm3c\\src\\main\\python\\crawling.py', reloading
INFO:werkzeug: * Detected change in 'C:\\kd\\ws_java\\team4_v2sbm3c\\src\\main\\python\\crawling.py', reloading
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 09:55:37 KST)" (scheduled at 2025-01-16 09:55:37.402323+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 09:56:37 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 269, in crawl_and_insert_data
    title = bs.select('#main-content > article > div:nth-child(1) > h1')[0].text
IndexError: list index out of range
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 09:56:51 KST)" (scheduled at 2025-01-16 09:55:51.214435+09:00)
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawl_and_insert_data" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 524-771-621
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FE410>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FE470>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FE590>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 09:56:51 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x00000221052FF370>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=50002): Max retries exceeded with url: /session/d887fac72ff9a8f53556ebae5c04ee3b/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FF370>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 09:57:51 KST)" (scheduled at 2025-01-16 09:56:51.214435+09:00)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 09:56:52 KST)" (scheduled at 2025-01-16 09:56:52.399748+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FEFE0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001F95F6613F0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/2a644faa16b96c880afb2b872db9fd78/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FEF80>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001F95F6614E0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/2a644faa16b96c880afb2b872db9fd78/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FEEC0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001F95F6617B0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/2a644faa16b96c880afb2b872db9fd78/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 09:57:51 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x00000221052FE980>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=50002): Max retries exceeded with url: /session/d887fac72ff9a8f53556ebae5c04ee3b/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FE980>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 09:57:52 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001F95F661A80>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=52068): Max retries exceeded with url: /session/2a644faa16b96c880afb2b872db9fd78/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001F95F661A80>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 09:58:51 KST)" (scheduled at 2025-01-16 09:57:51.214435+09:00)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 09:58:52 KST)" (scheduled at 2025-01-16 09:57:52.399748+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FE890>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001F95F660700>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/2a644faa16b96c880afb2b872db9fd78/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FD870>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001F95F660100>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/2a644faa16b96c880afb2b872db9fd78/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FDA80>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001F95F6603A0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/2a644faa16b96c880afb2b872db9fd78/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 09:58:51 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x00000221052FD060>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=50002): Max retries exceeded with url: /session/d887fac72ff9a8f53556ebae5c04ee3b/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FD060>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 09:58:52 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001F95F662260>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=52068): Max retries exceeded with url: /session/2a644faa16b96c880afb2b872db9fd78/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001F95F662260>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
INFO:werkzeug: * Detected change in 'C:\\Users\\soldesk\\AppData\\Roaming\\Python\\Python310\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py', reloading
INFO:werkzeug: * Detected change in 'C:\\ProgramData\\Anaconda3\\envs\\ai\\Lib\\site-packages\\IPython\\core\\interactiveshell.py', reloading
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 09:59:51 KST)" (scheduled at 2025-01-16 09:58:51.214435+09:00)
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022102B93430>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
INFO:apscheduler.scheduler:Added job "crawl_and_insert_data" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 524-771-621
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FC490>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FF160>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 09:59:51 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x00000221052FE860>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=50002): Max retries exceeded with url: /session/d887fac72ff9a8f53556ebae5c04ee3b/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FE860>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:00:51 KST)" (scheduled at 2025-01-16 09:59:51.214435+09:00)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 09:59:54 KST)" (scheduled at 2025-01-16 09:59:54.994529+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FF040>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000017C0CAE4F70>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/75bd71b76a91d44728114b3bdd86565b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FE4A0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000017C0CAE5060>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/75bd71b76a91d44728114b3bdd86565b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FF7C0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000017C0CAE53C0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/75bd71b76a91d44728114b3bdd86565b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:00:51 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x00000221052FF1C0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=50002): Max retries exceeded with url: /session/d887fac72ff9a8f53556ebae5c04ee3b/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FF1C0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:00:54 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000017C0CAE5660>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=52508): Max retries exceeded with url: /session/75bd71b76a91d44728114b3bdd86565b/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000017C0CAE5660>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:01:51 KST)" (scheduled at 2025-01-16 10:00:51.214435+09:00)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:01:54 KST)" (scheduled at 2025-01-16 10:00:54.994529+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FE3E0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000017C0CAE4700>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/75bd71b76a91d44728114b3bdd86565b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FE170>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000017C0CAE45B0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/75bd71b76a91d44728114b3bdd86565b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FE020>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000017C0CAE4340>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/75bd71b76a91d44728114b3bdd86565b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:01:51 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x00000221052FE320>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=50002): Max retries exceeded with url: /session/d887fac72ff9a8f53556ebae5c04ee3b/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FE320>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:01:54 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000017C0CAE5E40>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=52508): Max retries exceeded with url: /session/75bd71b76a91d44728114b3bdd86565b/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000017C0CAE5E40>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:02:51 KST)" (scheduled at 2025-01-16 10:01:51.214435+09:00)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:02:54 KST)" (scheduled at 2025-01-16 10:01:54.994529+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FDD20>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000017C0CAE73A0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/75bd71b76a91d44728114b3bdd86565b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FF520>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000017C0CAA7E50>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/75bd71b76a91d44728114b3bdd86565b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FEDA0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000017C0CAA7EE0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/75bd71b76a91d44728114b3bdd86565b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:02:51 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x00000221052FF580>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=50002): Max retries exceeded with url: /session/d887fac72ff9a8f53556ebae5c04ee3b/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FF580>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:02:54 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000017C0CAE7430>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=52508): Max retries exceeded with url: /session/75bd71b76a91d44728114b3bdd86565b/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000017C0CAE7430>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:03:51 KST)" (scheduled at 2025-01-16 10:02:51.214435+09:00)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:03:54 KST)" (scheduled at 2025-01-16 10:02:54.994529+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FC520>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000017C0CAE5E70>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/75bd71b76a91d44728114b3bdd86565b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FC4F0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000017C0CAE43A0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/75bd71b76a91d44728114b3bdd86565b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FD030>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000017C0CAE4400>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/75bd71b76a91d44728114b3bdd86565b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:03:51 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x00000221052FD0C0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=50002): Max retries exceeded with url: /session/d887fac72ff9a8f53556ebae5c04ee3b/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FD0C0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:03:54 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000017C0CAE4910>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=52508): Max retries exceeded with url: /session/75bd71b76a91d44728114b3bdd86565b/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000017C0CAE4910>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:04:51 KST)" (scheduled at 2025-01-16 10:03:51.214435+09:00)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:04:54 KST)" (scheduled at 2025-01-16 10:03:54.994529+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000002210290B4C0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000017C0CAA7C10>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/75bd71b76a91d44728114b3bdd86565b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FD600>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000017C0CAE7C40>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/75bd71b76a91d44728114b3bdd86565b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FE1D0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000017C0CAE7A30>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/75bd71b76a91d44728114b3bdd86565b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:04:51 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x00000221052FF760>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=50002): Max retries exceeded with url: /session/d887fac72ff9a8f53556ebae5c04ee3b/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FF760>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:04:54 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000017C0CAE7850>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=52508): Max retries exceeded with url: /session/75bd71b76a91d44728114b3bdd86565b/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000017C0CAE7850>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:05:51 KST)" (scheduled at 2025-01-16 10:04:51.214435+09:00)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:05:54 KST)" (scheduled at 2025-01-16 10:04:54.994529+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FDC60>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000017C0CAE72B0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/75bd71b76a91d44728114b3bdd86565b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FE230>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000017C0CAE6290>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/75bd71b76a91d44728114b3bdd86565b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FE590>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000017C0CAE47F0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/75bd71b76a91d44728114b3bdd86565b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:05:51 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x00000221052FE110>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=50002): Max retries exceeded with url: /session/d887fac72ff9a8f53556ebae5c04ee3b/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FE110>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:05:54 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000017C0CAE6560>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=52508): Max retries exceeded with url: /session/75bd71b76a91d44728114b3bdd86565b/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000017C0CAE6560>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:06:51 KST)" (scheduled at 2025-01-16 10:05:51.214435+09:00)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:06:54 KST)" (scheduled at 2025-01-16 10:05:54.994529+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FE5C0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000017C0CAE7DF0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/75bd71b76a91d44728114b3bdd86565b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FE0E0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000017C0CAE4280>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/75bd71b76a91d44728114b3bdd86565b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FE440>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000017C0CAE7010>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/75bd71b76a91d44728114b3bdd86565b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:06:51 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x00000221052FF220>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=50002): Max retries exceeded with url: /session/d887fac72ff9a8f53556ebae5c04ee3b/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FF220>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:06:54 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000017C0CAE6C20>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=52508): Max retries exceeded with url: /session/75bd71b76a91d44728114b3bdd86565b/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000017C0CAE6C20>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
INFO:werkzeug: * Detected change in 'C:\\ProgramData\\Anaconda3\\envs\\ai\\Lib\\site-packages\\pandas\\core\\indexing.py', reloading
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawl_and_insert_data" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 524-771-621
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:07:51 KST)" (scheduled at 2025-01-16 10:06:51.214435+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FEFE0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FEEC0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FE860>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:07:51 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x00000221052FE980>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=50002): Max retries exceeded with url: /session/d887fac72ff9a8f53556ebae5c04ee3b/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FE980>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:07:39 KST)" (scheduled at 2025-01-16 10:07:39.820734+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE5060>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE5150>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:08:51 KST)" (scheduled at 2025-01-16 10:07:51.214435+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE5420>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FD2A0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:08:39 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000029D46AE56F0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=54721): Max retries exceeded with url: /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE56F0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FCF10>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FD450>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:08:51 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x00000221052FD7E0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=50002): Max retries exceeded with url: /session/d887fac72ff9a8f53556ebae5c04ee3b/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FD7E0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:09:39 KST)" (scheduled at 2025-01-16 10:08:39.820734+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE4640>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE45B0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:09:51 KST)" (scheduled at 2025-01-16 10:08:51.214435+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE41C0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FD3C0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:09:39 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000029D46AE5F60>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=54721): Max retries exceeded with url: /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE5F60>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FD390>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FC490>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:09:51 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x00000221052FF190>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=50002): Max retries exceeded with url: /session/d887fac72ff9a8f53556ebae5c04ee3b/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FF190>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:10:39 KST)" (scheduled at 2025-01-16 10:09:39.820734+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE7490>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AA7F10>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:10:51 KST)" (scheduled at 2025-01-16 10:09:51.214435+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE7280>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FD8A0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:10:39 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000029D46AE7250>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=54721): Max retries exceeded with url: /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE7250>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FF7C0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FF1F0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:10:51 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x00000221052FF400>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=50002): Max retries exceeded with url: /session/d887fac72ff9a8f53556ebae5c04ee3b/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FF400>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:11:39 KST)" (scheduled at 2025-01-16 10:10:39.820734+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE44F0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE43D0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:11:51 KST)" (scheduled at 2025-01-16 10:10:51.214435+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE4070>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FE4D0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:11:39 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000029D46AE4880>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=54721): Max retries exceeded with url: /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE4880>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FDE70>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FE110>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:11:51 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x00000221052FE200>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=50002): Max retries exceeded with url: /session/d887fac72ff9a8f53556ebae5c04ee3b/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FE200>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:12:39 KST)" (scheduled at 2025-01-16 10:11:39.820734+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AA7F70>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE7D00>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:12:51 KST)" (scheduled at 2025-01-16 10:11:51.214435+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE7B80>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FCDF0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:12:39 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000029D46AE7910>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=54721): Max retries exceeded with url: /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE7910>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FE050>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FF460>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:12:51 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x00000221052FD090>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=50002): Max retries exceeded with url: /session/d887fac72ff9a8f53556ebae5c04ee3b/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FD090>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:13:39 KST)" (scheduled at 2025-01-16 10:12:39.820734+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE71F0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE5ED0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:13:51 KST)" (scheduled at 2025-01-16 10:12:51.214435+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE4F70>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FCA00>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:13:39 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000029D46AE6320>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=54721): Max retries exceeded with url: /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE6320>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FCB20>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105367970>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:13:51 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000022105367100>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=50002): Max retries exceeded with url: /session/d887fac72ff9a8f53556ebae5c04ee3b/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105367100>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:14:39 KST)" (scheduled at 2025-01-16 10:13:39.820734+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE7F10>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE7E80>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:14:51 KST)" (scheduled at 2025-01-16 10:13:51.214435+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE7070>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FCAF0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:14:39 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000029D46AE6D70>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=54721): Max retries exceeded with url: /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE6D70>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FDF00>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FC460>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:14:51 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x00000221052FC370>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=50002): Max retries exceeded with url: /session/d887fac72ff9a8f53556ebae5c04ee3b/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FC370>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:15:39 KST)" (scheduled at 2025-01-16 10:14:39.820734+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE4910>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE4AC0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:15:51 KST)" (scheduled at 2025-01-16 10:14:51.214435+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE5660>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FF580>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:15:39 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000029D46AE5390>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=54721): Max retries exceeded with url: /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE5390>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FF670>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FDD20>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:15:51 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x00000221052FE380>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=50002): Max retries exceeded with url: /session/d887fac72ff9a8f53556ebae5c04ee3b/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FE380>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:16:39 KST)" (scheduled at 2025-01-16 10:15:39.820734+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE76D0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE7970>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:16:51 KST)" (scheduled at 2025-01-16 10:15:51.214435+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE4820>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FF2B0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:16:39 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000029D46AE7850>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=54721): Max retries exceeded with url: /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE7850>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FE440>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FDE40>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:16:51 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x00000221052FDF60>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=50002): Max retries exceeded with url: /session/d887fac72ff9a8f53556ebae5c04ee3b/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FDF60>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:17:39 KST)" (scheduled at 2025-01-16 10:16:39.820734+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE6950>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE68C0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:17:51 KST)" (scheduled at 2025-01-16 10:16:51.214435+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE7580>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FCEE0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:17:39 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000029D46AE6AD0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=54721): Max retries exceeded with url: /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE6AD0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FEEC0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FD1B0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:17:51 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x00000221052FC640>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=50002): Max retries exceeded with url: /session/d887fac72ff9a8f53556ebae5c04ee3b/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FC640>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:18:39 KST)" (scheduled at 2025-01-16 10:17:39.820734+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE7430>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE7EB0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:18:51 KST)" (scheduled at 2025-01-16 10:17:51.214435+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE6680>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105367580>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:18:39 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000029D46AE7040>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=54721): Max retries exceeded with url: /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE7040>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221053671C0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105366D10>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:18:51 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000022105366140>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=50002): Max retries exceeded with url: /session/d887fac72ff9a8f53556ebae5c04ee3b/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105366140>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:19:39 KST)" (scheduled at 2025-01-16 10:18:39.820734+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE5450>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE4880>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:19:51 KST)" (scheduled at 2025-01-16 10:18:51.214435+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE7E20>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FD390>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:19:39 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000029D46AE5C00>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=54721): Max retries exceeded with url: /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE5C00>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FDA20>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FF2E0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:19:51 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x00000221052FE5C0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=50002): Max retries exceeded with url: /session/d887fac72ff9a8f53556ebae5c04ee3b/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FE5C0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:20:39 KST)" (scheduled at 2025-01-16 10:19:39.820734+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE50F0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE5DE0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:20:51 KST)" (scheduled at 2025-01-16 10:19:51.214435+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE6860>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FF3D0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:20:39 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000029D46AE5270>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=54721): Max retries exceeded with url: /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE5270>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FEB30>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FEE90>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:20:51 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x00000221052FD9C0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=50002): Max retries exceeded with url: /session/d887fac72ff9a8f53556ebae5c04ee3b/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FD9C0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:21:39 KST)" (scheduled at 2025-01-16 10:20:39.820734+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE6A70>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE6950>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:21:51 KST)" (scheduled at 2025-01-16 10:20:51.214435+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE6830>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FE200>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:21:39 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000029D46AE6680>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=54721): Max retries exceeded with url: /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE6680>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FDF90>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FD150>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:21:51 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x00000221052FE050>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=50002): Max retries exceeded with url: /session/d887fac72ff9a8f53556ebae5c04ee3b/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FE050>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:22:39 KST)" (scheduled at 2025-01-16 10:21:39.820734+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE7E80>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE67D0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:22:51 KST)" (scheduled at 2025-01-16 10:21:51.214435+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE7EB0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FD270>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:22:39 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000029D46AE6DD0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=54721): Max retries exceeded with url: /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE6DD0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FD600>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000002210287DE10>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:22:51 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000022105367130>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=50002): Max retries exceeded with url: /session/d887fac72ff9a8f53556ebae5c04ee3b/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105367130>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:23:39 KST)" (scheduled at 2025-01-16 10:22:39.820734+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE5870>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE6140>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:23:51 KST)" (scheduled at 2025-01-16 10:22:51.214435+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE4A30>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105366E90>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:23:39 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000029D46AE4490>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=54721): Max retries exceeded with url: /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE4490>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105366CB0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105366440>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:23:51 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000022105366500>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=50002): Max retries exceeded with url: /session/d887fac72ff9a8f53556ebae5c04ee3b/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105366500>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:24:39 KST)" (scheduled at 2025-01-16 10:23:39.820734+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE69E0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE7610>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:24:51 KST)" (scheduled at 2025-01-16 10:23:51.214435+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE57E0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FC850>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:24:39 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000029D46AE7910>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=54721): Max retries exceeded with url: /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE7910>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FEEF0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FC640>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:24:51 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x00000221052FF6D0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=50002): Max retries exceeded with url: /session/d887fac72ff9a8f53556ebae5c04ee3b/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FF6D0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:25:39 KST)" (scheduled at 2025-01-16 10:24:39.820734+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE7040>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE6F20>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:25:51 KST)" (scheduled at 2025-01-16 10:24:51.214435+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE4190>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FC970>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:25:39 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000029D46AE6BC0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=54721): Max retries exceeded with url: /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE6BC0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FE290>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FF280>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:25:51 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x00000221052FE4D0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=50002): Max retries exceeded with url: /session/d887fac72ff9a8f53556ebae5c04ee3b/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FE4D0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:26:39 KST)" (scheduled at 2025-01-16 10:25:39.820734+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE66E0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE6E30>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:26:51 KST)" (scheduled at 2025-01-16 10:25:51.214435+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE6620>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FDE40>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:26:39 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000029D46AE60B0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=54721): Max retries exceeded with url: /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE60B0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FF040>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FE9B0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:26:51 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x00000221052FD8A0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=50002): Max retries exceeded with url: /session/d887fac72ff9a8f53556ebae5c04ee3b/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FD8A0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:27:39 KST)" (scheduled at 2025-01-16 10:26:39.820734+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE6B00>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE5180>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:27:51 KST)" (scheduled at 2025-01-16 10:26:51.214435+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE5450>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FD390>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:27:39 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000029D46AE46D0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=54721): Max retries exceeded with url: /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE46D0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FC9D0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221053669E0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:27:51 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000022105366410>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=50002): Max retries exceeded with url: /session/d887fac72ff9a8f53556ebae5c04ee3b/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105366410>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:28:39 KST)" (scheduled at 2025-01-16 10:27:39.820734+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE6C50>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE7AC0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:28:51 KST)" (scheduled at 2025-01-16 10:27:51.214435+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE7610>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105365F30>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:28:39 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000029D46AE4A90>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=54721): Max retries exceeded with url: /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE4A90>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105365ED0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105365750>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:28:51 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x00000221053649A0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=50002): Max retries exceeded with url: /session/d887fac72ff9a8f53556ebae5c04ee3b/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221053649A0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:29:39 KST)" (scheduled at 2025-01-16 10:28:39.820734+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE6F50>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE61A0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:29:51 KST)" (scheduled at 2025-01-16 10:28:51.214435+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE6F20>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FD3C0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:29:39 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000029D46AE6C20>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=54721): Max retries exceeded with url: /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE6C20>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FE500>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FF130>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:29:51 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x00000221052FE9B0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=50002): Max retries exceeded with url: /session/d887fac72ff9a8f53556ebae5c04ee3b/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FE9B0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:30:39 KST)" (scheduled at 2025-01-16 10:29:39.820734+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE5B10>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE70A0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:30:51 KST)" (scheduled at 2025-01-16 10:29:51.214435+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE6CE0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FE440>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:30:39 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000029D46AE7070>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=54721): Max retries exceeded with url: /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE7070>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FF430>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FDE70>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:30:51 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x00000221052FF280>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=50002): Max retries exceeded with url: /session/d887fac72ff9a8f53556ebae5c04ee3b/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FF280>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:31:39 KST)" (scheduled at 2025-01-16 10:30:39.820734+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE4820>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE75E0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:31:51 KST)" (scheduled at 2025-01-16 10:30:51.214435+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE43D0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FDEA0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:31:39 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000029D46AE4A30>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=54721): Max retries exceeded with url: /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE4A30>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FDD20>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FDF90>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:31:51 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x00000221052FF790>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=50002): Max retries exceeded with url: /session/d887fac72ff9a8f53556ebae5c04ee3b/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FF790>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:32:39 KST)" (scheduled at 2025-01-16 10:31:39.820734+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE7B50>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE7A60>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:32:51 KST)" (scheduled at 2025-01-16 10:31:51.214435+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE5DE0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022102B935E0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:32:39 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000029D46AE57E0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=54721): Max retries exceeded with url: /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE57E0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105366530>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105367A00>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:32:51 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x00000221053673A0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=50002): Max retries exceeded with url: /session/d887fac72ff9a8f53556ebae5c04ee3b/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221053673A0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:33:39 KST)" (scheduled at 2025-01-16 10:32:39.820734+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE6770>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE6020>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:33:51 KST)" (scheduled at 2025-01-16 10:32:51.214435+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE7EE0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105365630>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:33:39 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000029D46AE4190>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=54721): Max retries exceeded with url: /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE4190>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221053654E0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105365510>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:33:51 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000022105365BA0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=50002): Max retries exceeded with url: /session/d887fac72ff9a8f53556ebae5c04ee3b/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105365BA0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:34:39 KST)" (scheduled at 2025-01-16 10:33:39.820734+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE6800>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE6B60>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:34:51 KST)" (scheduled at 2025-01-16 10:33:51.214435+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE7730>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FDFF0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:34:39 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000029D46AE68F0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=54721): Max retries exceeded with url: /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE68F0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FC850>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FF1F0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:34:51 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x00000221052FDD20>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=50002): Max retries exceeded with url: /session/d887fac72ff9a8f53556ebae5c04ee3b/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FDD20>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:35:39 KST)" (scheduled at 2025-01-16 10:34:39.820734+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE5BD0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE6DA0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:35:51 KST)" (scheduled at 2025-01-16 10:34:51.214435+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE4820>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FE380>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:35:39 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000029D46AE7CD0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=54721): Max retries exceeded with url: /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE7CD0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FE200>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FE170>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:35:51 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x00000221052FF430>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=50002): Max retries exceeded with url: /session/d887fac72ff9a8f53556ebae5c04ee3b/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FF430>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:36:39 KST)" (scheduled at 2025-01-16 10:35:39.820734+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE7AF0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE5E10>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:36:51 KST)" (scheduled at 2025-01-16 10:35:51.214435+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE7A60>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FD9F0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:36:39 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000029D46AE6FB0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=54721): Max retries exceeded with url: /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE6FB0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FE920>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FD8A0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:36:51 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x00000221052FEE30>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=50002): Max retries exceeded with url: /session/d887fac72ff9a8f53556ebae5c04ee3b/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FEE30>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:37:39 KST)" (scheduled at 2025-01-16 10:36:39.820734+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE5390>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE6920>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:37:51 KST)" (scheduled at 2025-01-16 10:36:51.214435+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE7280>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105366710>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:37:39 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000029D46AE7340>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=54721): Max retries exceeded with url: /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE7340>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105365F90>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221053661A0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:37:51 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000022105366410>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=50002): Max retries exceeded with url: /session/d887fac72ff9a8f53556ebae5c04ee3b/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105366410>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:38:39 KST)" (scheduled at 2025-01-16 10:37:39.820734+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE7670>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE6AA0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:38:51 KST)" (scheduled at 2025-01-16 10:37:51.214435+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE41F0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105365540>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:38:39 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000029D46AE74C0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=54721): Max retries exceeded with url: /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE74C0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105366B90>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105366650>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:38:51 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000022105366B60>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=50002): Max retries exceeded with url: /session/d887fac72ff9a8f53556ebae5c04ee3b/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105366B60>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:39:39 KST)" (scheduled at 2025-01-16 10:38:39.820734+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE5870>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE6DA0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:39:51 KST)" (scheduled at 2025-01-16 10:38:51.214435+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE6DD0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FEF80>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:39:39 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000029D46AE47C0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=54721): Max retries exceeded with url: /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE47C0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FE1D0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FD8A0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:39:51 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x00000221052FF2B0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=50002): Max retries exceeded with url: /session/d887fac72ff9a8f53556ebae5c04ee3b/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FF2B0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:40:39 KST)" (scheduled at 2025-01-16 10:39:39.820734+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE7010>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE4850>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:40:51 KST)" (scheduled at 2025-01-16 10:39:51.214435+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE5E40>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FF6A0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:40:39 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000029D46AE4460>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=54721): Max retries exceeded with url: /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE4460>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FF430>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FE170>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:40:51 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x00000221052FF280>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=50002): Max retries exceeded with url: /session/d887fac72ff9a8f53556ebae5c04ee3b/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FF280>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:41:39 KST)" (scheduled at 2025-01-16 10:40:39.820734+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE61D0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE7A30>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:41:51 KST)" (scheduled at 2025-01-16 10:40:51.214435+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46C88640>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FC730>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:41:39 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000029D46AE52A0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=54721): Max retries exceeded with url: /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE52A0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FF760>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FF460>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:41:51 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x00000221052FC970>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=50002): Max retries exceeded with url: /session/d887fac72ff9a8f53556ebae5c04ee3b/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FC970>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:42:39 KST)" (scheduled at 2025-01-16 10:41:39.820734+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE66B0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE6EF0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:42:51 KST)" (scheduled at 2025-01-16 10:41:51.214435+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE6410>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105366920>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:42:39 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000029D46AE5F00>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=54721): Max retries exceeded with url: /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE5F00>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105365960>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105367430>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:42:51 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000022105365F90>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=50002): Max retries exceeded with url: /session/d887fac72ff9a8f53556ebae5c04ee3b/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105365F90>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:43:39 KST)" (scheduled at 2025-01-16 10:42:39.820734+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46C88160>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46C88760>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:43:51 KST)" (scheduled at 2025-01-16 10:42:51.214435+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AA7DF0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105365CF0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:43:39 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000029D463AE290>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=54721): Max retries exceeded with url: /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D463AE290>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105365660>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105367B80>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:43:51 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000022105367CD0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=50002): Max retries exceeded with url: /session/d887fac72ff9a8f53556ebae5c04ee3b/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105367CD0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:44:39 KST)" (scheduled at 2025-01-16 10:43:39.820734+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE6350>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE7EB0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:44:51 KST)" (scheduled at 2025-01-16 10:43:51.214435+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE4A00>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FF220>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:44:39 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000029D46AE6110>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=54721): Max retries exceeded with url: /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE6110>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FCDF0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FF640>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:44:51 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x00000221052FC730>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=50002): Max retries exceeded with url: /session/d887fac72ff9a8f53556ebae5c04ee3b/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FC730>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:45:39 KST)" (scheduled at 2025-01-16 10:44:39.820734+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46C88D90>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46C88E80>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:45:51 KST)" (scheduled at 2025-01-16 10:44:51.214435+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE64A0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FDF90>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:45:39 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000029D46AE6800>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=54721): Max retries exceeded with url: /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE6800>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FE380>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FD9C0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:45:51 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x00000221052FF6A0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=50002): Max retries exceeded with url: /session/d887fac72ff9a8f53556ebae5c04ee3b/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FF6A0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:46:39 KST)" (scheduled at 2025-01-16 10:45:39.820734+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE64D0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE4130>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:46:51 KST)" (scheduled at 2025-01-16 10:45:51.214435+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE7640>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FCFA0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:46:39 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000029D46AE60E0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=54721): Max retries exceeded with url: /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE60E0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FE8C0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FEE30>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:46:51 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x00000221052FD3C0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=50002): Max retries exceeded with url: /session/d887fac72ff9a8f53556ebae5c04ee3b/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FD3C0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:47:39 KST)" (scheduled at 2025-01-16 10:46:39.820734+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46C89180>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46C892A0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:47:51 KST)" (scheduled at 2025-01-16 10:46:51.214435+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AA7EB0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105367B20>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:47:39 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000029D46AE6EF0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=54721): Max retries exceeded with url: /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE6EF0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221053673A0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221053661D0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:47:51 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000022105366530>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=50002): Max retries exceeded with url: /session/d887fac72ff9a8f53556ebae5c04ee3b/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105366530>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:48:39 KST)" (scheduled at 2025-01-16 10:47:39.820734+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE6830>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE6920>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:48:51 KST)" (scheduled at 2025-01-16 10:47:51.214435+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE7460>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105367F40>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:48:39 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000029D46AE6110>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=54721): Max retries exceeded with url: /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE6110>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000002210547C070>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000002210547C1C0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:48:51 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000002210547C310>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=50002): Max retries exceeded with url: /session/d887fac72ff9a8f53556ebae5c04ee3b/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000002210547C310>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:49:39 KST)" (scheduled at 2025-01-16 10:48:39.820734+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46C896C0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46C89720>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:49:51 KST)" (scheduled at 2025-01-16 10:48:51.214435+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE7F40>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FE440>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:49:39 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000029D46AE7520>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=54721): Max retries exceeded with url: /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE7520>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FEB30>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FE8C0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:49:51 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x00000221052FD630>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=50002): Max retries exceeded with url: /session/d887fac72ff9a8f53556ebae5c04ee3b/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FD630>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:50:39 KST)" (scheduled at 2025-01-16 10:49:39.820734+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE7880>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE7130>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:50:51 KST)" (scheduled at 2025-01-16 10:49:51.214435+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE4E50>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FC640>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:50:39 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000029D46AE46D0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=54721): Max retries exceeded with url: /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE46D0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FDEA0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FE380>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:50:51 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x00000221052FD150>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=50002): Max retries exceeded with url: /session/d887fac72ff9a8f53556ebae5c04ee3b/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FD150>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:51:39 KST)" (scheduled at 2025-01-16 10:50:39.820734+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46C892A0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46C89B40>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:51:51 KST)" (scheduled at 2025-01-16 10:50:51.214435+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AA7E20>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FC730>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:51:39 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000029D46AE64D0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=54721): Max retries exceeded with url: /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE64D0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FF640>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FC850>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:51:51 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x00000221052FF580>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=50002): Max retries exceeded with url: /session/d887fac72ff9a8f53556ebae5c04ee3b/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FF580>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:52:39 KST)" (scheduled at 2025-01-16 10:51:39.820734+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE5FC0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE4A00>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:52:51 KST)" (scheduled at 2025-01-16 10:51:51.214435+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE6740>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105367E20>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:52:39 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000029D46AE6CB0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=54721): Max retries exceeded with url: /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE6CB0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105365960>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105365D20>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:52:51 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000022105367A60>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=50002): Max retries exceeded with url: /session/d887fac72ff9a8f53556ebae5c04ee3b/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105367A60>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:53:39 KST)" (scheduled at 2025-01-16 10:52:39.820734+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46C89ED0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46C89FC0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:53:51 KST)" (scheduled at 2025-01-16 10:52:51.214435+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE74F0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000002210547C580>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:53:39 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000029D46AE6110>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=54721): Max retries exceeded with url: /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE6110>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000002210547C6A0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000002210547C7C0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:53:51 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000002210547C910>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=50002): Max retries exceeded with url: /session/d887fac72ff9a8f53556ebae5c04ee3b/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000002210547C910>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:54:39 KST)" (scheduled at 2025-01-16 10:53:39.820734+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE6470>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE7CA0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:54:51 KST)" (scheduled at 2025-01-16 10:53:51.214435+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE5270>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105366E60>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:54:39 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000029D46AA7FA0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=54721): Max retries exceeded with url: /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AA7FA0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105365C30>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105367E20>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:54:51 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000022105367EB0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=50002): Max retries exceeded with url: /session/d887fac72ff9a8f53556ebae5c04ee3b/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105367EB0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:55:39 KST)" (scheduled at 2025-01-16 10:54:39.820734+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46C8A2C0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46C8A470>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:55:51 KST)" (scheduled at 2025-01-16 10:54:51.214435+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AA7DF0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105366DA0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:55:39 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000029D46AE75E0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=54721): Max retries exceeded with url: /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE75E0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105365CF0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105367C40>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:55:51 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000022105367DF0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=50002): Max retries exceeded with url: /session/d887fac72ff9a8f53556ebae5c04ee3b/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105367DF0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:56:39 KST)" (scheduled at 2025-01-16 10:55:39.820734+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE6260>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE6C80>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:56:51 KST)" (scheduled at 2025-01-16 10:55:51.214435+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE7C10>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105365570>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:56:39 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000029D46AE6A70>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=54721): Max retries exceeded with url: /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE6A70>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105365690>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105366650>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:56:51 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000022105366B60>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=50002): Max retries exceeded with url: /session/d887fac72ff9a8f53556ebae5c04ee3b/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105366B60>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:57:39 KST)" (scheduled at 2025-01-16 10:56:39.820734+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE52D0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE5E10>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:57:51 KST)" (scheduled at 2025-01-16 10:56:51.214435+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46C8A380>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105365630>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:57:39 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000029D46AE5240>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=54721): Max retries exceeded with url: /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE5240>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105365870>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221053660B0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:57:51 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000022105366F50>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=50002): Max retries exceeded with url: /session/d887fac72ff9a8f53556ebae5c04ee3b/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105366F50>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:58:39 KST)" (scheduled at 2025-01-16 10:57:39.820734+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE6380>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE69E0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:58:51 KST)" (scheduled at 2025-01-16 10:57:51.214435+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE4250>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105365ED0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:58:39 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000029D46AE57E0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=54721): Max retries exceeded with url: /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE57E0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105366830>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221053649A0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:58:51 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000022105366F80>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=50002): Max retries exceeded with url: /session/d887fac72ff9a8f53556ebae5c04ee3b/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105366F80>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:59:39 KST)" (scheduled at 2025-01-16 10:58:39.820734+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AA7D90>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46C89D50>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:59:51 KST)" (scheduled at 2025-01-16 10:58:51.214435+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46C89E40>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221053665C0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:59:39 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000029D46AA7E80>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=54721): Max retries exceeded with url: /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AA7E80>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221053669B0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221053663B0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 10:59:51 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000022105365510>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=50002): Max retries exceeded with url: /session/d887fac72ff9a8f53556ebae5c04ee3b/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105365510>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 11:00:39 KST)" (scheduled at 2025-01-16 10:59:39.820734+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE4910>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE6020>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 11:00:51 KST)" (scheduled at 2025-01-16 10:59:51.214435+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE7550>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221053668F0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 11:00:39 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000029D46AE6AA0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=54721): Max retries exceeded with url: /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE6AA0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105365990>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221053675E0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 11:00:51 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000022105366770>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=50002): Max retries exceeded with url: /session/d887fac72ff9a8f53556ebae5c04ee3b/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105366770>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 11:01:39 KST)" (scheduled at 2025-01-16 11:00:39.820734+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46C89450>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46C89CC0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 11:01:51 KST)" (scheduled at 2025-01-16 11:00:51.214435+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46C8A380>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105367C10>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 11:01:39 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000029D46C88280>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=54721): Max retries exceeded with url: /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46C88280>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105365EA0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105367CD0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 11:01:51 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000022105365DE0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=50002): Max retries exceeded with url: /session/d887fac72ff9a8f53556ebae5c04ee3b/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105365DE0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 11:02:39 KST)" (scheduled at 2025-01-16 11:01:39.820734+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE7550>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE72B0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 11:02:51 KST)" (scheduled at 2025-01-16 11:01:51.214435+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE6380>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105367EE0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 11:02:39 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000029D46AE71C0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=54721): Max retries exceeded with url: /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE71C0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105367EB0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105367E20>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 11:02:51 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x00000221053657B0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=50002): Max retries exceeded with url: /session/d887fac72ff9a8f53556ebae5c04ee3b/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221053657B0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 11:03:39 KST)" (scheduled at 2025-01-16 11:02:39.820734+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46C88B50>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46C88130>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 11:03:51 KST)" (scheduled at 2025-01-16 11:02:51.214435+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46C8A4D0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105366A10>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 11:03:39 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000029D46AE74F0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=54721): Max retries exceeded with url: /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE74F0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105366500>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221053673D0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 11:03:51 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000022105367340>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=50002): Max retries exceeded with url: /session/d887fac72ff9a8f53556ebae5c04ee3b/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105367340>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 11:04:39 KST)" (scheduled at 2025-01-16 11:03:39.820734+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE72B0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE6770>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 11:04:51 KST)" (scheduled at 2025-01-16 11:03:51.214435+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE60E0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221053667A0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 11:04:39 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000029D46AE6AA0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=54721): Max retries exceeded with url: /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE6AA0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105366DD0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105366E60>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 11:04:51 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000022105367430>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=50002): Max retries exceeded with url: /session/d887fac72ff9a8f53556ebae5c04ee3b/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105367430>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 11:05:39 KST)" (scheduled at 2025-01-16 11:04:39.820734+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46C88880>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46C8A110>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 11:05:51 KST)" (scheduled at 2025-01-16 11:04:51.214435+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE6A70>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105367E80>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 11:05:39 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000029D46AE7250>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=54721): Max retries exceeded with url: /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE7250>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221053659F0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105367B50>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 11:05:51 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000022105367AF0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=50002): Max retries exceeded with url: /session/d887fac72ff9a8f53556ebae5c04ee3b/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105367AF0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 11:06:39 KST)" (scheduled at 2025-01-16 11:05:39.820734+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE7340>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE4130>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 11:06:51 KST)" (scheduled at 2025-01-16 11:05:51.214435+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE4490>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105365540>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 11:06:39 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000029D46AE66B0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=54721): Max retries exceeded with url: /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE66B0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221053658D0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105366620>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 11:06:51 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000022105366B90>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=50002): Max retries exceeded with url: /session/d887fac72ff9a8f53556ebae5c04ee3b/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105366B90>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 11:07:39 KST)" (scheduled at 2025-01-16 11:06:39.820734+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46C89F00>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46C89A80>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 11:07:51 KST)" (scheduled at 2025-01-16 11:06:51.214435+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE4460>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105366290>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 11:07:39 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000029D46AE6CB0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=54721): Max retries exceeded with url: /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE6CB0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105365F60>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105367130>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 11:07:51 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000022105365F30>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=50002): Max retries exceeded with url: /session/d887fac72ff9a8f53556ebae5c04ee3b/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105365F30>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 11:08:39 KST)" (scheduled at 2025-01-16 11:07:39.820734+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE41F0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE6F50>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 11:08:51 KST)" (scheduled at 2025-01-16 11:07:51.214435+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE7700>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105367040>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 11:08:39 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000029D46AE6CE0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=54721): Max retries exceeded with url: /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE6CE0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105367910>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000002210290B4C0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 11:08:51 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x00000221052FE0E0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=50002): Max retries exceeded with url: /session/d887fac72ff9a8f53556ebae5c04ee3b/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FE0E0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 11:09:39 KST)" (scheduled at 2025-01-16 11:08:39.820734+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46C88EE0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46C88DF0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 11:09:51 KST)" (scheduled at 2025-01-16 11:08:51.214435+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE5B70>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105367E50>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 11:09:39 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000029D46AE7670>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=54721): Max retries exceeded with url: /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE7670>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105364970>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221053663B0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 11:09:51 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x00000221053660B0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=50002): Max retries exceeded with url: /session/d887fac72ff9a8f53556ebae5c04ee3b/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221053660B0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 11:10:39 KST)" (scheduled at 2025-01-16 11:09:39.820734+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE4250>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE7EB0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 11:10:51 KST)" (scheduled at 2025-01-16 11:09:51.214435+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE7070>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105367F70>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 11:10:39 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000029D46AE6620>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=54721): Max retries exceeded with url: /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE6620>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105365990>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105366650>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 11:10:51 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000022105367A00>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=50002): Max retries exceeded with url: /session/d887fac72ff9a8f53556ebae5c04ee3b/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105367A00>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 11:11:39 KST)" (scheduled at 2025-01-16 11:10:39.820734+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46C88B80>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46C88580>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 11:11:51 KST)" (scheduled at 2025-01-16 11:10:51.214435+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE64D0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221053666B0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 11:11:39 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000029D46AE4460>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=54721): Max retries exceeded with url: /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE4460>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105365EA0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105367D90>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 11:11:51 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000022105366DA0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=50002): Max retries exceeded with url: /session/d887fac72ff9a8f53556ebae5c04ee3b/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105366DA0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 11:12:39 KST)" (scheduled at 2025-01-16 11:11:39.820734+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE7D90>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE72E0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 11:12:51 KST)" (scheduled at 2025-01-16 11:11:51.214435+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE7310>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105367460>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 11:12:39 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000029D46AE6CE0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=54721): Max retries exceeded with url: /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE6CE0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105367F10>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105367BE0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 11:12:51 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000022105366C50>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=50002): Max retries exceeded with url: /session/d887fac72ff9a8f53556ebae5c04ee3b/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105366C50>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 11:13:39 KST)" (scheduled at 2025-01-16 11:12:39.820734+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46C8AA40>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46C8AB30>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 11:13:51 KST)" (scheduled at 2025-01-16 11:12:51.214435+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE7520>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FF490>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 11:13:39 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000029D46AE65C0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=54721): Max retries exceeded with url: /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE65C0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FC850>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FCDF0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 11:13:51 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x00000221052FEEF0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=50002): Max retries exceeded with url: /session/d887fac72ff9a8f53556ebae5c04ee3b/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FEEF0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 11:14:39 KST)" (scheduled at 2025-01-16 11:13:39.820734+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE6440>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE5B10>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 11:14:51 KST)" (scheduled at 2025-01-16 11:13:51.214435+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE62F0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105367E20>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 11:14:39 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000029D46AE6FE0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=54721): Max retries exceeded with url: /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE6FE0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105366020>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105367FA0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 11:14:51 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000022105365570>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=50002): Max retries exceeded with url: /session/d887fac72ff9a8f53556ebae5c04ee3b/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105365570>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 11:15:39 KST)" (scheduled at 2025-01-16 11:14:39.820734+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46C8AE30>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46C8AF50>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 11:15:51 KST)" (scheduled at 2025-01-16 11:14:51.214435+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE6EC0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105367B50>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 11:15:39 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000029D46AE58D0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=54721): Max retries exceeded with url: /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE58D0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105365EA0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105365960>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 11:15:51 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000022105365630>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=50002): Max retries exceeded with url: /session/d887fac72ff9a8f53556ebae5c04ee3b/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105365630>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 11:16:39 KST)" (scheduled at 2025-01-16 11:15:39.820734+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE6F50>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE5E40>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 11:16:51 KST)" (scheduled at 2025-01-16 11:15:51.214435+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE7820>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105366620>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 11:16:39 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000029D46AE5300>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=54721): Max retries exceeded with url: /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE5300>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105365990>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105365DB0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 11:16:51 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000022105366800>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=50002): Max retries exceeded with url: /session/d887fac72ff9a8f53556ebae5c04ee3b/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105366800>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 11:17:39 KST)" (scheduled at 2025-01-16 11:16:39.820734+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46C8B340>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46C8B430>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 11:17:51 KST)" (scheduled at 2025-01-16 11:16:51.214435+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE5BA0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105365F60>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 11:17:39 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000029D46AE5300>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=54721): Max retries exceeded with url: /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE5300>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105366FE0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022102B93130>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 11:17:51 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x00000221052FC970>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=50002): Max retries exceeded with url: /session/d887fac72ff9a8f53556ebae5c04ee3b/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FC970>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 11:18:39 KST)" (scheduled at 2025-01-16 11:17:39.820734+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE4130>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE45B0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 11:18:51 KST)" (scheduled at 2025-01-16 11:17:51.214435+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE64D0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FD150>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 11:18:39 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000029D46C8B3D0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=54721): Max retries exceeded with url: /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46C8B3D0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FE380>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FDF60>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 11:18:51 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x00000221052FDA20>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=50002): Max retries exceeded with url: /session/d887fac72ff9a8f53556ebae5c04ee3b/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FDA20>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 11:19:39 KST)" (scheduled at 2025-01-16 11:18:39.820734+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46C8B730>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46C8B850>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 11:19:51 KST)" (scheduled at 2025-01-16 11:18:51.214435+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AA7D60>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105367970>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 11:19:39 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000029D46AE48E0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=54721): Max retries exceeded with url: /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE48E0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105364970>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105365CC0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 11:19:51 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000022105366800>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=50002): Max retries exceeded with url: /session/d887fac72ff9a8f53556ebae5c04ee3b/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105366800>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 11:20:39 KST)" (scheduled at 2025-01-16 11:19:39.820734+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE7F70>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE7760>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 11:20:51 KST)" (scheduled at 2025-01-16 11:19:51.214435+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE46D0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221053656F0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 11:20:39 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000029D46AE6590>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=54721): Max retries exceeded with url: /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE6590>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105366680>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105367B20>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 11:20:51 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000022105365630>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=50002): Max retries exceeded with url: /session/d887fac72ff9a8f53556ebae5c04ee3b/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105365630>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 11:21:39 KST)" (scheduled at 2025-01-16 11:20:39.820734+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE4580>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46C8B010>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 11:21:51 KST)" (scheduled at 2025-01-16 11:20:51.214435+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46C8B9D0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105367BB0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 11:21:39 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000029D46AE6D70>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=54721): Max retries exceeded with url: /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE6D70>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105365930>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105366C80>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 11:21:51 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000022105367FD0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=50002): Max retries exceeded with url: /session/d887fac72ff9a8f53556ebae5c04ee3b/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105367FD0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 11:22:39 KST)" (scheduled at 2025-01-16 11:21:39.820734+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE7610>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE4370>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 11:22:51 KST)" (scheduled at 2025-01-16 11:21:51.214435+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE6890>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105365D20>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 11:22:39 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000029D46AE7E80>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=54721): Max retries exceeded with url: /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE7E80>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105367220>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FD390>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 11:22:51 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x00000221052FDFF0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=50002): Max retries exceeded with url: /session/d887fac72ff9a8f53556ebae5c04ee3b/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FDFF0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 11:23:39 KST)" (scheduled at 2025-01-16 11:22:39.820734+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46C8A9B0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46C8BA90>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 11:23:51 KST)" (scheduled at 2025-01-16 11:22:51.214435+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46C8A7D0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FC8B0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 11:23:39 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000029D46AA7D30>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=54721): Max retries exceeded with url: /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AA7D30>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FF2B0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FEF80>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 11:23:51 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x00000221052FE080>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=50002): Max retries exceeded with url: /session/d887fac72ff9a8f53556ebae5c04ee3b/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FE080>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 11:24:39 KST)" (scheduled at 2025-01-16 11:23:39.820734+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE5720>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE4280>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 11:24:51 KST)" (scheduled at 2025-01-16 11:23:51.214435+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE6E60>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105367F40>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 11:24:39 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000029D46AE4B20>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=54721): Max retries exceeded with url: /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE4B20>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105366F50>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105367E80>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 11:24:51 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000022105366C80>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=50002): Max retries exceeded with url: /session/d887fac72ff9a8f53556ebae5c04ee3b/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105366C80>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 11:25:39 KST)" (scheduled at 2025-01-16 11:24:39.820734+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46C88E80>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46C887F0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 11:25:51 KST)" (scheduled at 2025-01-16 11:24:51.214435+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46C88BB0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221053666B0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 11:25:39 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000029D46C8A230>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=54721): Max retries exceeded with url: /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46C8A230>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105365C60>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105367A90>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 11:25:51 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000022105367B20>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=50002): Max retries exceeded with url: /session/d887fac72ff9a8f53556ebae5c04ee3b/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105367B20>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 11:26:39 KST)" (scheduled at 2025-01-16 11:25:39.820734+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE7820>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE7EE0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 11:26:51 KST)" (scheduled at 2025-01-16 11:25:51.214435+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE6920>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105367F70>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 11:26:39 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000029D46AE7BE0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=54721): Max retries exceeded with url: /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AE7BE0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105367E50>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105366530>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 11:26:51 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x00000221053669E0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=50002): Max retries exceeded with url: /session/d887fac72ff9a8f53556ebae5c04ee3b/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221053669E0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 11:27:39 KST)" (scheduled at 2025-01-16 11:26:39.820734+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46C89AB0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46C890F0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 11:27:51 KST)" (scheduled at 2025-01-16 11:26:51.214435+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46C8A7A0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221053655D0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 11:27:39 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000029D46AA7E20>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=54721): Max retries exceeded with url: /session/4e4cb2b8b8b36248b9d789839bc3b8ae/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000029D46AA7E20>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FE9B0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FF4F0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 11:27:51 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x00000221052FC970>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=50002): Max retries exceeded with url: /session/d887fac72ff9a8f53556ebae5c04ee3b/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FC970>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
INFO:werkzeug: * Detected change in 'C:\\ProgramData\\Anaconda3\\Lib\\site-packages\\_pytest\\cacheprovider.py', reloading
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawl_and_insert_data" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 524-771-621
INFO:werkzeug: * Detected change in 'C:\\Users\\soldesk\\AppData\\Roaming\\Python\\Python310\\site-packages\\selenium\\webdriver\\common\\by.py', reloading
INFO:werkzeug: * Detected change in 'C:\\Users\\soldesk\\AppData\\Roaming\\Python\\Python310\\site-packages\\selenium\\webdriver\\remote\\webelement.py', reloading
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 11:28:51 KST)" (scheduled at 2025-01-16 11:27:51.214435+09:00)
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawl_and_insert_data" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 524-771-621
INFO:werkzeug: * Detected change in 'C:\\Users\\soldesk\\AppData\\Roaming\\Python\\Python310\\site-packages\\tzlocal\\__init__.py', reloading
INFO:werkzeug: * Detected change in 'C:\\Users\\soldesk\\AppData\\Roaming\\Python\\Python310\\site-packages\\tzlocal\\win32.py', reloading
INFO:werkzeug: * Detected change in 'C:\\Users\\soldesk\\AppData\\Roaming\\Python\\Python310\\site-packages\\apscheduler\\schedulers\\__init__.py', reloading
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FD4E0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FE9E0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FC490>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 11:28:51 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x00000221052FCA30>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=50002): Max retries exceeded with url: /session/d887fac72ff9a8f53556ebae5c04ee3b/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FCA30>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawl_and_insert_data" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 524-771-621
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 11:29:51 KST)" (scheduled at 2025-01-16 11:28:51.214435+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105366050>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105367BB0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105364970>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 11:29:51 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000022105365F60>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=50002): Max retries exceeded with url: /session/d887fac72ff9a8f53556ebae5c04ee3b/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105365F60>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 11:29:07 KST)" (scheduled at 2025-01-16 11:29:07.864354+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000012CE39851B0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/e8ce6cb30163844efe5dbf8a16578444/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000012CE39852A0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/e8ce6cb30163844efe5dbf8a16578444/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000012CE3985660>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/e8ce6cb30163844efe5dbf8a16578444/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 11:30:07 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000012CE3985600>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=62174): Max retries exceeded with url: /session/e8ce6cb30163844efe5dbf8a16578444/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000012CE3985600>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
INFO:werkzeug: * Detected change in 'C:\\Users\\soldesk\\AppData\\Roaming\\Python\\Python310\\site-packages\\apscheduler\\executors\\base.py', reloading
INFO:werkzeug: * Detected change in 'C:\\ProgramData\\Anaconda3\\Lib\\site-packages\\urllib3\\request.py', reloading
INFO:werkzeug: * Detected change in 'C:\\Users\\soldesk\\AppData\\Roaming\\Python\\Python310\\site-packages\\selenium\\webdriver\\remote\\webdriver.py', reloading
INFO:werkzeug: * Detected change in 'C:\\ProgramData\\Anaconda3\\Lib\\site-packages\\urllib3\\poolmanager.py', reloading
INFO:werkzeug: * Detected change in 'C:\\Users\\soldesk\\AppData\\Roaming\\Python\\Python310\\site-packages\\selenium\\webdriver\\remote\\remote_connection.py', reloading
INFO:werkzeug: * Detected change in 'C:\\ProgramData\\Anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py', reloading
INFO:werkzeug: * Detected change in 'C:\\ProgramData\\Anaconda3\\Lib\\site-packages\\urllib3\\util\\retry.py', reloading
INFO:werkzeug: * Detected change in 'C:\\ProgramData\\Anaconda3\\Lib\\site-packages\\urllib3\\connection.py', reloading
INFO:werkzeug: * Detected change in 'C:\\ProgramData\\Anaconda3\\Lib\\http\\client.py', reloading
INFO:werkzeug: * Detected change in 'C:\\ProgramData\\Anaconda3\\Lib\\site-packages\\urllib3\\util\\connection.py', reloading
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawling_BBC" to job store "default"
INFO:apscheduler.scheduler:Added job "crawling_FOX" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 524-771-621
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 11:30:51 KST)" (scheduled at 2025-01-16 11:29:51.214435+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105365F30>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105366620>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105365690>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 11:30:51 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x00000221053668F0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=50002): Max retries exceeded with url: /session/d887fac72ff9a8f53556ebae5c04ee3b/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221053668F0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 11:30:38 KST)" (scheduled at 2025-01-16 11:30:38.782317+09:00)
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 11:30:38 KST)" (scheduled at 2025-01-16 11:30:38.782317+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001FA7E6581C0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/377d9394911a69d0aad3a986545c4029/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001FA7E658700>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/377d9394911a69d0aad3a986545c4029/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001FA7E658AC0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/377d9394911a69d0aad3a986545c4029/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001FA7E658820>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/377d9394911a69d0aad3a986545c4029/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001FA7E658EE0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/377d9394911a69d0aad3a986545c4029/url
WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: localhost. Connection pool size: 1
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001FA7E658C10>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/377d9394911a69d0aad3a986545c4029/url
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 11:31:51 KST)" (scheduled at 2025-01-16 11:30:51.214435+09:00)
WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: localhost. Connection pool size: 1
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 11:31:38 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001FA7E62B970>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 447, in crawling_FOX
    load('https://www.foxnews.com/', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=62316): Max retries exceeded with url: /session/377d9394911a69d0aad3a986545c4029/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001FA7E62B970>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 11:31:38 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001FA7E62BAF0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawling_BBC
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=62316): Max retries exceeded with url: /session/377d9394911a69d0aad3a986545c4029/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001FA7E62BAF0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105367F10>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105367CD0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105367DF0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 11:31:51 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000022105366F50>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=50002): Max retries exceeded with url: /session/d887fac72ff9a8f53556ebae5c04ee3b/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105366F50>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 11:32:38 KST)" (scheduled at 2025-01-16 11:31:38.782317+09:00)
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 11:32:38 KST)" (scheduled at 2025-01-16 11:31:38.782317+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001FA7E6597E0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/377d9394911a69d0aad3a986545c4029/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001FA7E659900>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/377d9394911a69d0aad3a986545c4029/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001FA7E659A20>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/377d9394911a69d0aad3a986545c4029/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001FA7E659CF0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/377d9394911a69d0aad3a986545c4029/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001FA7E62B430>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/377d9394911a69d0aad3a986545c4029/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001FA7E62B1F0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/377d9394911a69d0aad3a986545c4029/url
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 11:32:51 KST)" (scheduled at 2025-01-16 11:31:51.214435+09:00)
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 11:32:38 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001FA7E62B400>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 447, in crawling_FOX
    load('https://www.foxnews.com/', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=62316): Max retries exceeded with url: /session/377d9394911a69d0aad3a986545c4029/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001FA7E62B400>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: localhost. Connection pool size: 1
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 11:32:38 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001FA7E62B0A0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawling_BBC
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=62316): Max retries exceeded with url: /session/377d9394911a69d0aad3a986545c4029/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001FA7E62B0A0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105367D00>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FE950>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FC970>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 11:32:51 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x00000221052FE3B0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=50002): Max retries exceeded with url: /session/d887fac72ff9a8f53556ebae5c04ee3b/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FE3B0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
INFO:werkzeug: * Detected change in 'C:\\kd\\ws_java\\team4_v2sbm3c\\src\\main\\python\\crawling.py', reloading
INFO:werkzeug: * Detected change in 'C:\\kd\\ws_java\\team4_v2sbm3c\\src\\main\\python\\crawling.py', reloading
INFO:werkzeug: * Detected change in 'C:\\kd\\ws_java\\team4_v2sbm3c\\src\\main\\python\\crawling.py', reloading
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawling_BBC" to job store "default"
INFO:apscheduler.scheduler:Added job "crawling_FOX" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 524-771-621
INFO:werkzeug: * Detected change in 'C:\\kd\\ws_java\\team4_v2sbm3c\\src\\main\\python\\crawling.py', reloading
INFO:werkzeug: * Detected change in 'C:\\kd\\ws_java\\team4_v2sbm3c\\src\\main\\python\\crawling.py', reloading
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 11:33:51 KST)" (scheduled at 2025-01-16 11:32:51.214435+09:00)
INFO:WDM:====== WebDriver manager ======
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FC6A0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FD2A0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
INFO:apscheduler.scheduler:Added job "crawling_BBC" to job store "default"
INFO:apscheduler.scheduler:Added job "crawling_FOX" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 524-771-621
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FD0F0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 11:33:51 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x00000221052FC790>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=50002): Max retries exceeded with url: /session/d887fac72ff9a8f53556ebae5c04ee3b/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FC790>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 11:34:51 KST)" (scheduled at 2025-01-16 11:33:51.214435+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105367CA0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 11:33:57 KST)" (scheduled at 2025-01-16 11:33:57.755097+09:00)
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 11:33:57 KST)" (scheduled at 2025-01-16 11:33:57.756094+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105366F50>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001D1388242E0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4a75c6153bb52bb00d34600f04e229f2/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001D138824490>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4a75c6153bb52bb00d34600f04e229f2/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105365C90>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001D1388245E0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4a75c6153bb52bb00d34600f04e229f2/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001D1388248B0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4a75c6153bb52bb00d34600f04e229f2/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 11:34:51 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000022105367BE0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=50002): Max retries exceeded with url: /session/d887fac72ff9a8f53556ebae5c04ee3b/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105367BE0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001D138824A00>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4a75c6153bb52bb00d34600f04e229f2/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001D138824CD0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4a75c6153bb52bb00d34600f04e229f2/url
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 11:34:57 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001D13880B6A0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 447, in crawling_FOX
    load('https://www.foxnews.com/', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=62605): Max retries exceeded with url: /session/4a75c6153bb52bb00d34600f04e229f2/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001D13880B6A0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: localhost. Connection pool size: 1
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 11:34:57 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001D13880B9D0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawling_BBC
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=62605): Max retries exceeded with url: /session/4a75c6153bb52bb00d34600f04e229f2/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001D13880B9D0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 11:35:51 KST)" (scheduled at 2025-01-16 11:34:51.214435+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105365D50>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 11:35:57 KST)" (scheduled at 2025-01-16 11:34:57.755097+09:00)
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 11:35:57 KST)" (scheduled at 2025-01-16 11:34:57.756094+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105365930>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001D138825660>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4a75c6153bb52bb00d34600f04e229f2/url
WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: localhost. Connection pool size: 1
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001D138825780>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4a75c6153bb52bb00d34600f04e229f2/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105366FE0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001D1388258A0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4a75c6153bb52bb00d34600f04e229f2/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001D138825930>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4a75c6153bb52bb00d34600f04e229f2/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 11:35:51 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x00000221053659F0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=50002): Max retries exceeded with url: /session/d887fac72ff9a8f53556ebae5c04ee3b/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221053659F0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001D13880B7F0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4a75c6153bb52bb00d34600f04e229f2/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001D13880B0D0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4a75c6153bb52bb00d34600f04e229f2/url
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 11:35:57 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001D13880AF80>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawling_BBC
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=62605): Max retries exceeded with url: /session/4a75c6153bb52bb00d34600f04e229f2/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001D13880AF80>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: localhost. Connection pool size: 1
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 11:35:57 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001D13880AB60>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 447, in crawling_FOX
    load('https://www.foxnews.com/', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=62605): Max retries exceeded with url: /session/4a75c6153bb52bb00d34600f04e229f2/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001D13880AB60>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
INFO:werkzeug: * Detected change in 'C:\\kd\\ws_java\\team4_v2sbm3c\\src\\main\\python\\crawling.py', reloading
INFO:werkzeug: * Detected change in 'C:\\kd\\ws_java\\team4_v2sbm3c\\src\\main\\python\\crawling.py', reloading
INFO:werkzeug: * Detected change in 'C:\\kd\\ws_java\\team4_v2sbm3c\\src\\main\\python\\crawling.py', reloading
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawling_BBC" to job store "default"
INFO:apscheduler.scheduler:Added job "crawling_FOX" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 524-771-621
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 11:36:51 KST)" (scheduled at 2025-01-16 11:35:51.214435+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221053663B0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105367F70>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105366530>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 11:36:51 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000022105365BA0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=50002): Max retries exceeded with url: /session/d887fac72ff9a8f53556ebae5c04ee3b/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000022105365BA0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 11:36:47 KST)" (scheduled at 2025-01-16 11:36:47.284152+09:00)
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 11:36:47 KST)" (scheduled at 2025-01-16 11:36:47.284152+09:00)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 11:37:51 KST)" (scheduled at 2025-01-16 11:36:51.214435+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000223B2BCAA10>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/e8b0a139bf9cc533733d78479cb58051/url
WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: localhost. Connection pool size: 1
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000223B2BE8250>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/e8b0a139bf9cc533733d78479cb58051/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FD3F0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000223B2BE8520>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/e8b0a139bf9cc533733d78479cb58051/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000223B2BE8580>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/e8b0a139bf9cc533733d78479cb58051/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FE9B0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000223B2BE8910>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/e8b0a139bf9cc533733d78479cb58051/url
WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: localhost. Connection pool size: 1
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000223B2BCB940>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/e8b0a139bf9cc533733d78479cb58051/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FDFF0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: localhost. Connection pool size: 1
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 11:37:47 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x00000223B2BCB7C0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawling_BBC
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=62843): Max retries exceeded with url: /session/e8b0a139bf9cc533733d78479cb58051/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000223B2BCB7C0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 11:37:47 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x00000223B2BCB760>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 447, in crawling_FOX
    load('https://www.foxnews.com/', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=62843): Max retries exceeded with url: /session/e8b0a139bf9cc533733d78479cb58051/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000223B2BCB760>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 11:37:51 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x00000221052FE950>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=50002): Max retries exceeded with url: /session/d887fac72ff9a8f53556ebae5c04ee3b/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FE950>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 11:38:47 KST)" (scheduled at 2025-01-16 11:37:47.284152+09:00)
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 11:38:47 KST)" (scheduled at 2025-01-16 11:37:47.284152+09:00)
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 11:38:51 KST)" (scheduled at 2025-01-16 11:37:51.214435+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000223B2BE94E0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/e8b0a139bf9cc533733d78479cb58051/url
WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: localhost. Connection pool size: 1
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000223B2BE9600>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/e8b0a139bf9cc533733d78479cb58051/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FE140>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000223B2BE97B0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/e8b0a139bf9cc533733d78479cb58051/url
WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: localhost. Connection pool size: 1
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000223B2BE9720>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/e8b0a139bf9cc533733d78479cb58051/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FC3A0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000223B2BCAE60>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/e8b0a139bf9cc533733d78479cb58051/url
WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: localhost. Connection pool size: 1
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000223B2BCB850>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/e8b0a139bf9cc533733d78479cb58051/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FCE20>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/d887fac72ff9a8f53556ebae5c04ee3b/url
WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: localhost. Connection pool size: 1
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 11:38:47 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x00000223B2BCAC50>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawling_BBC
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=62843): Max retries exceeded with url: /session/e8b0a139bf9cc533733d78479cb58051/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000223B2BCAC50>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 11:38:47 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x00000223B2BCAE00>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 447, in crawling_FOX
    load('https://www.foxnews.com/', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=62843): Max retries exceeded with url: /session/e8b0a139bf9cc533733d78479cb58051/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000223B2BCAE00>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 11:38:51 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x00000221052FD120>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=50002): Max retries exceeded with url: /session/d887fac72ff9a8f53556ebae5c04ee3b/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000221052FD120>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
INFO:werkzeug: * Detected change in 'C:\\kd\\ws_java\\team4_v2sbm3c\\src\\main\\python\\crawling.py', reloading
INFO:werkzeug: * Detected change in 'C:\\kd\\ws_java\\team4_v2sbm3c\\src\\main\\python\\crawling.py', reloading
INFO:werkzeug: * Detected change in 'C:\\kd\\ws_java\\team4_v2sbm3c\\src\\main\\python\\crawling.py', reloading
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawling_BBC" to job store "default"
INFO:apscheduler.scheduler:Added job "crawling_FOX" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 524-771-621
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawling_BBC" to job store "default"
INFO:apscheduler.scheduler:Added job "crawling_FOX" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
INFO:werkzeug:[33mPress CTRL+C to quit[0m
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawling_BBC" to job store "default"
INFO:apscheduler.scheduler:Added job "crawling_FOX" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 524-771-621
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 11:40:06 KST)" (scheduled at 2025-01-16 11:40:06.334260+09:00)
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 11:40:06 KST)" (scheduled at 2025-01-16 11:40:06.335257+09:00)
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 11:41:06 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 102, in crawling_BBC
    time.sleep(5)
UnboundLocalError: local variable 'time' referenced before assignment
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 11:41:06 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 446, in crawling_FOX
    time.sleep(5)
UnboundLocalError: local variable 'time' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 11:40:16 KST)" (scheduled at 2025-01-16 11:40:16.462666+09:00)
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 11:40:16 KST)" (scheduled at 2025-01-16 11:40:16.463663+09:00)
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 11:41:16 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 102, in crawling_BBC
    time.sleep(5)
UnboundLocalError: local variable 'time' referenced before assignment
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 11:41:16 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 446, in crawling_FOX
    time.sleep(5)
UnboundLocalError: local variable 'time' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 11:42:06 KST)" (scheduled at 2025-01-16 11:41:06.334260+09:00)
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 11:42:06 KST)" (scheduled at 2025-01-16 11:41:06.335257+09:00)
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 11:42:06 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 102, in crawling_BBC
    time.sleep(5)
UnboundLocalError: local variable 'time' referenced before assignment
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 11:42:06 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 446, in crawling_FOX
    time.sleep(5)
UnboundLocalError: local variable 'time' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 11:42:16 KST)" (scheduled at 2025-01-16 11:41:16.462666+09:00)
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 11:42:16 KST)" (scheduled at 2025-01-16 11:41:16.463663+09:00)
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 11:42:16 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 102, in crawling_BBC
    time.sleep(5)
UnboundLocalError: local variable 'time' referenced before assignment
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 11:42:16 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 446, in crawling_FOX
    time.sleep(5)
UnboundLocalError: local variable 'time' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 11:43:06 KST)" (scheduled at 2025-01-16 11:42:06.334260+09:00)
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 11:43:06 KST)" (scheduled at 2025-01-16 11:42:06.335257+09:00)
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 11:43:06 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 102, in crawling_BBC
    time.sleep(5)
UnboundLocalError: local variable 'time' referenced before assignment
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 11:43:06 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 446, in crawling_FOX
    time.sleep(5)
UnboundLocalError: local variable 'time' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 11:43:16 KST)" (scheduled at 2025-01-16 11:42:16.462666+09:00)
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 11:43:16 KST)" (scheduled at 2025-01-16 11:42:16.463663+09:00)
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 11:43:16 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 102, in crawling_BBC
    time.sleep(5)
UnboundLocalError: local variable 'time' referenced before assignment
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 11:43:16 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 446, in crawling_FOX
    time.sleep(5)
UnboundLocalError: local variable 'time' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 11:44:06 KST)" (scheduled at 2025-01-16 11:43:06.334260+09:00)
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 11:44:06 KST)" (scheduled at 2025-01-16 11:43:06.335257+09:00)
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 11:44:06 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 102, in crawling_BBC
    time.sleep(5)
UnboundLocalError: local variable 'time' referenced before assignment
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 11:44:06 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 446, in crawling_FOX
    time.sleep(5)
UnboundLocalError: local variable 'time' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 11:44:16 KST)" (scheduled at 2025-01-16 11:43:16.462666+09:00)
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 11:44:16 KST)" (scheduled at 2025-01-16 11:43:16.463663+09:00)
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 11:44:16 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 102, in crawling_BBC
    time.sleep(5)
UnboundLocalError: local variable 'time' referenced before assignment
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 11:44:16 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 446, in crawling_FOX
    time.sleep(5)
UnboundLocalError: local variable 'time' referenced before assignment
INFO:werkzeug: * Detected change in 'C:\\ProgramData\\Anaconda3\\envs\\ai\\Lib\\runpy.py', reloading
INFO:werkzeug: * Detected change in 'C:\\ProgramData\\Anaconda3\\envs\\ai\\Lib\\site-packages\\ipykernel_launcher.py', reloading
INFO:werkzeug: * Detected change in 'C:\\ProgramData\\Anaconda3\\envs\\ai\\Lib\\site-packages\\traitlets\\config\\application.py', reloading
INFO:werkzeug: * Detected change in 'C:\\ProgramData\\Anaconda3\\envs\\ai\\Lib\\site-packages\\ipykernel\\kernelapp.py', reloading
INFO:werkzeug: * Detected change in 'C:\\ProgramData\\Anaconda3\\envs\\ai\\Lib\\site-packages\\zmq\\sugar\\socket.py', reloading
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawling_BBC" to job store "default"
INFO:apscheduler.scheduler:Added job "crawling_FOX" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 524-771-621
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 11:45:06 KST)" (scheduled at 2025-01-16 11:44:06.334260+09:00)
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 11:45:06 KST)" (scheduled at 2025-01-16 11:44:06.335257+09:00)
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 11:45:06 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 102, in crawling_BBC
    time.sleep(5)
UnboundLocalError: local variable 'time' referenced before assignment
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 11:45:06 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 446, in crawling_FOX
    time.sleep(5)
UnboundLocalError: local variable 'time' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 11:44:43 KST)" (scheduled at 2025-01-16 11:44:43.766799+09:00)
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 11:44:43 KST)" (scheduled at 2025-01-16 11:44:43.766799+09:00)
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 11:45:43 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 446, in crawling_FOX
    time.sleep(5)
UnboundLocalError: local variable 'time' referenced before assignment
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 11:45:43 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 102, in crawling_BBC
    time.sleep(5)
UnboundLocalError: local variable 'time' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 11:46:06 KST)" (scheduled at 2025-01-16 11:45:06.334260+09:00)
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 11:46:06 KST)" (scheduled at 2025-01-16 11:45:06.335257+09:00)
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 11:46:06 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 102, in crawling_BBC
    time.sleep(5)
UnboundLocalError: local variable 'time' referenced before assignment
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 11:46:06 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 446, in crawling_FOX
    time.sleep(5)
UnboundLocalError: local variable 'time' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 11:46:43 KST)" (scheduled at 2025-01-16 11:45:43.766799+09:00)
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 11:46:43 KST)" (scheduled at 2025-01-16 11:45:43.766799+09:00)
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 11:46:43 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 446, in crawling_FOX
    time.sleep(5)
UnboundLocalError: local variable 'time' referenced before assignment
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 11:46:43 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 102, in crawling_BBC
    time.sleep(5)
UnboundLocalError: local variable 'time' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 11:47:06 KST)" (scheduled at 2025-01-16 11:46:06.334260+09:00)
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 11:47:06 KST)" (scheduled at 2025-01-16 11:46:06.335257+09:00)
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 11:47:06 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 102, in crawling_BBC
    time.sleep(5)
UnboundLocalError: local variable 'time' referenced before assignment
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 11:47:06 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 446, in crawling_FOX
    time.sleep(5)
UnboundLocalError: local variable 'time' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 11:47:43 KST)" (scheduled at 2025-01-16 11:46:43.766799+09:00)
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 11:47:43 KST)" (scheduled at 2025-01-16 11:46:43.766799+09:00)
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 11:47:43 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 446, in crawling_FOX
    time.sleep(5)
UnboundLocalError: local variable 'time' referenced before assignment
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 11:47:43 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 102, in crawling_BBC
    time.sleep(5)
UnboundLocalError: local variable 'time' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 11:48:06 KST)" (scheduled at 2025-01-16 11:47:06.334260+09:00)
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 11:48:06 KST)" (scheduled at 2025-01-16 11:47:06.335257+09:00)
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 11:48:06 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 102, in crawling_BBC
    time.sleep(5)
UnboundLocalError: local variable 'time' referenced before assignment
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 11:48:06 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 446, in crawling_FOX
    time.sleep(5)
UnboundLocalError: local variable 'time' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 11:48:43 KST)" (scheduled at 2025-01-16 11:47:43.766799+09:00)
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 11:48:43 KST)" (scheduled at 2025-01-16 11:47:43.766799+09:00)
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 11:48:43 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 446, in crawling_FOX
    time.sleep(5)
UnboundLocalError: local variable 'time' referenced before assignment
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 11:48:43 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 102, in crawling_BBC
    time.sleep(5)
UnboundLocalError: local variable 'time' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 11:49:06 KST)" (scheduled at 2025-01-16 11:48:06.334260+09:00)
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 11:49:06 KST)" (scheduled at 2025-01-16 11:48:06.335257+09:00)
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 11:49:06 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 102, in crawling_BBC
    time.sleep(5)
UnboundLocalError: local variable 'time' referenced before assignment
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 11:49:06 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 446, in crawling_FOX
    time.sleep(5)
UnboundLocalError: local variable 'time' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 11:49:43 KST)" (scheduled at 2025-01-16 11:48:43.766799+09:00)
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 11:49:43 KST)" (scheduled at 2025-01-16 11:48:43.766799+09:00)
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 11:49:43 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 446, in crawling_FOX
    time.sleep(5)
UnboundLocalError: local variable 'time' referenced before assignment
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 11:49:43 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 102, in crawling_BBC
    time.sleep(5)
UnboundLocalError: local variable 'time' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 11:50:06 KST)" (scheduled at 2025-01-16 11:49:06.334260+09:00)
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 11:50:06 KST)" (scheduled at 2025-01-16 11:49:06.335257+09:00)
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 11:50:06 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 446, in crawling_FOX
    time.sleep(5)
UnboundLocalError: local variable 'time' referenced before assignment
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 11:50:06 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 102, in crawling_BBC
    time.sleep(5)
UnboundLocalError: local variable 'time' referenced before assignment
INFO:werkzeug: * Detected change in 'C:\\ProgramData\\Anaconda3\\envs\\ai\\Lib\\site-packages\\IPython\\core\\interactiveshell.py', reloading
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawling_BBC" to job store "default"
INFO:apscheduler.scheduler:Added job "crawling_FOX" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 524-771-621
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 11:51:06 KST)" (scheduled at 2025-01-16 11:50:06.334260+09:00)
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 11:51:06 KST)" (scheduled at 2025-01-16 11:50:06.335257+09:00)
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 11:51:06 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 102, in crawling_BBC
    time.sleep(5)
UnboundLocalError: local variable 'time' referenced before assignment
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 11:51:06 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 446, in crawling_FOX
    time.sleep(5)
UnboundLocalError: local variable 'time' referenced before assignment
INFO:werkzeug: * Detected change in 'C:\\Users\\soldesk\\AppData\\Roaming\\Python\\Python310\\site-packages\\selenium\\webdriver\\chrome\\webdriver.py', reloading
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawling_BBC" to job store "default"
INFO:apscheduler.scheduler:Added job "crawling_FOX" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 524-771-621
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 11:52:06 KST)" (scheduled at 2025-01-16 11:51:06.334260+09:00)
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 11:52:06 KST)" (scheduled at 2025-01-16 11:51:06.335257+09:00)
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 11:52:06 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 102, in crawling_BBC
    time.sleep(5)
UnboundLocalError: local variable 'time' referenced before assignment
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 11:52:06 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 446, in crawling_FOX
    time.sleep(5)
UnboundLocalError: local variable 'time' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 11:51:43 KST)" (scheduled at 2025-01-16 11:51:43.569300+09:00)
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 11:51:43 KST)" (scheduled at 2025-01-16 11:51:43.569300+09:00)
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 11:52:43 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 102, in crawling_BBC
    time.sleep(5)
UnboundLocalError: local variable 'time' referenced before assignment
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 11:52:43 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 446, in crawling_FOX
    time.sleep(5)
UnboundLocalError: local variable 'time' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 11:53:06 KST)" (scheduled at 2025-01-16 11:52:06.334260+09:00)
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 11:53:06 KST)" (scheduled at 2025-01-16 11:52:06.335257+09:00)
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 11:53:06 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 102, in crawling_BBC
    time.sleep(5)
UnboundLocalError: local variable 'time' referenced before assignment
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 11:53:06 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 446, in crawling_FOX
    time.sleep(5)
UnboundLocalError: local variable 'time' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 11:53:43 KST)" (scheduled at 2025-01-16 11:52:43.569300+09:00)
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 11:53:43 KST)" (scheduled at 2025-01-16 11:52:43.569300+09:00)
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 11:53:43 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 102, in crawling_BBC
    time.sleep(5)
UnboundLocalError: local variable 'time' referenced before assignment
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 11:53:43 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 446, in crawling_FOX
    time.sleep(5)
UnboundLocalError: local variable 'time' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 11:54:06 KST)" (scheduled at 2025-01-16 11:53:06.334260+09:00)
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 11:54:06 KST)" (scheduled at 2025-01-16 11:53:06.335257+09:00)
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 11:54:06 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 102, in crawling_BBC
    time.sleep(5)
UnboundLocalError: local variable 'time' referenced before assignment
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 11:54:06 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 446, in crawling_FOX
    time.sleep(5)
UnboundLocalError: local variable 'time' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 11:54:43 KST)" (scheduled at 2025-01-16 11:53:43.569300+09:00)
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 11:54:43 KST)" (scheduled at 2025-01-16 11:53:43.569300+09:00)
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 11:54:43 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 102, in crawling_BBC
    time.sleep(5)
UnboundLocalError: local variable 'time' referenced before assignment
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 11:54:43 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 446, in crawling_FOX
    time.sleep(5)
UnboundLocalError: local variable 'time' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 11:55:06 KST)" (scheduled at 2025-01-16 11:54:06.334260+09:00)
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 11:55:06 KST)" (scheduled at 2025-01-16 11:54:06.335257+09:00)
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 11:55:06 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 102, in crawling_BBC
    time.sleep(5)
UnboundLocalError: local variable 'time' referenced before assignment
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 11:55:06 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 446, in crawling_FOX
    time.sleep(5)
UnboundLocalError: local variable 'time' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 11:55:43 KST)" (scheduled at 2025-01-16 11:54:43.569300+09:00)
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 11:55:43 KST)" (scheduled at 2025-01-16 11:54:43.569300+09:00)
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 11:55:43 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 102, in crawling_BBC
    time.sleep(5)
UnboundLocalError: local variable 'time' referenced before assignment
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 11:55:43 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 446, in crawling_FOX
    time.sleep(5)
UnboundLocalError: local variable 'time' referenced before assignment
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawling_BBC" to job store "default"
INFO:apscheduler.scheduler:Added job "crawling_FOX" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
INFO:werkzeug:[33mPress CTRL+C to quit[0m
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawling_BBC" to job store "default"
INFO:apscheduler.scheduler:Added job "crawling_FOX" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 524-771-621
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 11:57:05 KST)" (scheduled at 2025-01-16 11:57:05.712048+09:00)
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 11:57:05 KST)" (scheduled at 2025-01-16 11:57:05.713045+09:00)
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 11:58:05 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 102, in crawling_BBC
    time.sleep(5)
UnboundLocalError: local variable 'time' referenced before assignment
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 11:58:05 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 446, in crawling_FOX
    time.sleep(5)
UnboundLocalError: local variable 'time' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 11:57:14 KST)" (scheduled at 2025-01-16 11:57:14.036746+09:00)
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 11:57:14 KST)" (scheduled at 2025-01-16 11:57:14.036746+09:00)
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 11:58:14 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 446, in crawling_FOX
    time.sleep(5)
UnboundLocalError: local variable 'time' referenced before assignment
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 11:58:14 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 102, in crawling_BBC
    time.sleep(5)
UnboundLocalError: local variable 'time' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 11:59:05 KST)" (scheduled at 2025-01-16 11:58:05.712048+09:00)
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 11:59:05 KST)" (scheduled at 2025-01-16 11:58:05.713045+09:00)
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 11:59:05 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 102, in crawling_BBC
    time.sleep(5)
UnboundLocalError: local variable 'time' referenced before assignment
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 11:59:05 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 446, in crawling_FOX
    time.sleep(5)
UnboundLocalError: local variable 'time' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 11:59:14 KST)" (scheduled at 2025-01-16 11:58:14.036746+09:00)
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 11:59:14 KST)" (scheduled at 2025-01-16 11:58:14.036746+09:00)
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 11:59:14 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 446, in crawling_FOX
    time.sleep(5)
UnboundLocalError: local variable 'time' referenced before assignment
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 11:59:14 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 102, in crawling_BBC
    time.sleep(5)
UnboundLocalError: local variable 'time' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:00:05 KST)" (scheduled at 2025-01-16 11:59:05.712048+09:00)
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:00:05 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 102, in crawling_BBC
    time.sleep(5)
UnboundLocalError: local variable 'time' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 12:00:05 KST)" (scheduled at 2025-01-16 11:59:05.713045+09:00)
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 12:00:05 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 446, in crawling_FOX
    time.sleep(5)
UnboundLocalError: local variable 'time' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 12:00:14 KST)" (scheduled at 2025-01-16 11:59:14.036746+09:00)
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:00:14 KST)" (scheduled at 2025-01-16 11:59:14.036746+09:00)
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 12:00:14 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 446, in crawling_FOX
    time.sleep(5)
UnboundLocalError: local variable 'time' referenced before assignment
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:00:14 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 102, in crawling_BBC
    time.sleep(5)
UnboundLocalError: local variable 'time' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:01:05 KST)" (scheduled at 2025-01-16 12:00:05.712048+09:00)
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 12:01:05 KST)" (scheduled at 2025-01-16 12:00:05.713045+09:00)
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:01:05 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 102, in crawling_BBC
    time.sleep(5)
UnboundLocalError: local variable 'time' referenced before assignment
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 12:01:05 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 446, in crawling_FOX
    time.sleep(5)
UnboundLocalError: local variable 'time' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 12:01:14 KST)" (scheduled at 2025-01-16 12:00:14.036746+09:00)
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:01:14 KST)" (scheduled at 2025-01-16 12:00:14.036746+09:00)
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 12:01:14 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 446, in crawling_FOX
    time.sleep(5)
UnboundLocalError: local variable 'time' referenced before assignment
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:01:14 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 102, in crawling_BBC
    time.sleep(5)
UnboundLocalError: local variable 'time' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:02:05 KST)" (scheduled at 2025-01-16 12:01:05.712048+09:00)
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 12:02:05 KST)" (scheduled at 2025-01-16 12:01:05.713045+09:00)
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:02:05 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 102, in crawling_BBC
    time.sleep(5)
UnboundLocalError: local variable 'time' referenced before assignment
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 12:02:05 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 446, in crawling_FOX
    time.sleep(5)
UnboundLocalError: local variable 'time' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 12:02:14 KST)" (scheduled at 2025-01-16 12:01:14.036746+09:00)
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:02:14 KST)" (scheduled at 2025-01-16 12:01:14.036746+09:00)
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 12:02:14 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 446, in crawling_FOX
    time.sleep(5)
UnboundLocalError: local variable 'time' referenced before assignment
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:02:14 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 102, in crawling_BBC
    time.sleep(5)
UnboundLocalError: local variable 'time' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:03:05 KST)" (scheduled at 2025-01-16 12:02:05.712048+09:00)
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 12:03:05 KST)" (scheduled at 2025-01-16 12:02:05.713045+09:00)
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:03:05 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 102, in crawling_BBC
    time.sleep(5)
UnboundLocalError: local variable 'time' referenced before assignment
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 12:03:05 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 446, in crawling_FOX
    time.sleep(5)
UnboundLocalError: local variable 'time' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 12:03:14 KST)" (scheduled at 2025-01-16 12:02:14.036746+09:00)
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:03:14 KST)" (scheduled at 2025-01-16 12:02:14.036746+09:00)
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 12:03:14 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 446, in crawling_FOX
    time.sleep(5)
UnboundLocalError: local variable 'time' referenced before assignment
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:03:14 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 102, in crawling_BBC
    time.sleep(5)
UnboundLocalError: local variable 'time' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:04:05 KST)" (scheduled at 2025-01-16 12:03:05.712048+09:00)
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 12:04:05 KST)" (scheduled at 2025-01-16 12:03:05.713045+09:00)
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:04:05 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 102, in crawling_BBC
    time.sleep(5)
UnboundLocalError: local variable 'time' referenced before assignment
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 12:04:05 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 446, in crawling_FOX
    time.sleep(5)
UnboundLocalError: local variable 'time' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 12:04:14 KST)" (scheduled at 2025-01-16 12:03:14.036746+09:00)
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:04:14 KST)" (scheduled at 2025-01-16 12:03:14.036746+09:00)
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 12:04:14 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 446, in crawling_FOX
    time.sleep(5)
UnboundLocalError: local variable 'time' referenced before assignment
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:04:14 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 102, in crawling_BBC
    time.sleep(5)
UnboundLocalError: local variable 'time' referenced before assignment
INFO:werkzeug: * Detected change in 'C:\\Users\\soldesk\\AppData\\Roaming\\Python\\Python310\\site-packages\\selenium\\webdriver\\chrome\\service.py', reloading
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawling_BBC" to job store "default"
INFO:apscheduler.scheduler:Added job "crawling_FOX" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 524-771-621
INFO:werkzeug: * Detected change in 'C:\\kd\\ws_java\\team4_v2sbm3c\\src\\main\\python\\crawling.py', reloading
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawling_BBC" to job store "default"
INFO:apscheduler.scheduler:Added job "crawling_FOX" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 524-771-621
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:05:05 KST)" (scheduled at 2025-01-16 12:04:05.712048+09:00)
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 12:05:05 KST)" (scheduled at 2025-01-16 12:04:05.713045+09:00)
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:05:05 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 102, in crawling_BBC
UnboundLocalError: local variable 'time' referenced before assignment
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 12:05:05 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 446, in crawling_FOX
    sysdate, '메인', :title, :content, :content2)
UnboundLocalError: local variable 'time' referenced before assignment
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawling_BBC" to job store "default"
INFO:apscheduler.scheduler:Added job "crawling_FOX" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
INFO:werkzeug:[33mPress CTRL+C to quit[0m
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawling_BBC" to job store "default"
INFO:apscheduler.scheduler:Added job "crawling_FOX" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 524-771-621
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:06:27 KST)" (scheduled at 2025-01-16 12:06:27.803988+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 12:06:27 KST)" (scheduled at 2025-01-16 12:06:27.803988+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 12:07:27 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 475, in crawling_FOX
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:07:27 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 114, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:06:36 KST)" (scheduled at 2025-01-16 12:06:36.095358+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 12:06:36 KST)" (scheduled at 2025-01-16 12:06:36.096348+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:07:36 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 114, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 12:07:36 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 475, in crawling_FOX
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:08:27 KST)" (scheduled at 2025-01-16 12:07:27.803988+09:00)
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 12:08:27 KST)" (scheduled at 2025-01-16 12:07:27.803988+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 12:08:27 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 475, in crawling_FOX
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:08:27 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 114, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:08:36 KST)" (scheduled at 2025-01-16 12:07:36.095358+09:00)
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 12:08:36 KST)" (scheduled at 2025-01-16 12:07:36.096348+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 12:08:36 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 475, in crawling_FOX
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:08:36 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 114, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:09:27 KST)" (scheduled at 2025-01-16 12:08:27.803988+09:00)
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 12:09:27 KST)" (scheduled at 2025-01-16 12:08:27.803988+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:09:27 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 114, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 12:09:27 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 475, in crawling_FOX
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:09:36 KST)" (scheduled at 2025-01-16 12:08:36.095358+09:00)
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 12:09:36 KST)" (scheduled at 2025-01-16 12:08:36.096348+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 12:09:36 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 475, in crawling_FOX
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:09:36 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 114, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:10:27 KST)" (scheduled at 2025-01-16 12:09:27.803988+09:00)
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 12:10:27 KST)" (scheduled at 2025-01-16 12:09:27.803988+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:10:27 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 114, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 12:10:27 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 475, in crawling_FOX
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:10:36 KST)" (scheduled at 2025-01-16 12:09:36.095358+09:00)
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 12:10:36 KST)" (scheduled at 2025-01-16 12:09:36.096348+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:10:36 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 114, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 12:10:36 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 475, in crawling_FOX
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:11:27 KST)" (scheduled at 2025-01-16 12:10:27.803988+09:00)
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 12:11:27 KST)" (scheduled at 2025-01-16 12:10:27.803988+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:11:27 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 114, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 12:11:27 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 475, in crawling_FOX
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:11:36 KST)" (scheduled at 2025-01-16 12:10:36.095358+09:00)
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 12:11:36 KST)" (scheduled at 2025-01-16 12:10:36.096348+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:11:36 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 114, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 12:11:36 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 475, in crawling_FOX
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:12:27 KST)" (scheduled at 2025-01-16 12:11:27.803988+09:00)
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 12:12:27 KST)" (scheduled at 2025-01-16 12:11:27.803988+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:12:27 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 114, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 12:12:27 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 475, in crawling_FOX
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:12:36 KST)" (scheduled at 2025-01-16 12:11:36.095358+09:00)
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 12:12:36 KST)" (scheduled at 2025-01-16 12:11:36.096348+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 12:12:36 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 475, in crawling_FOX
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:12:36 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 114, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:13:27 KST)" (scheduled at 2025-01-16 12:12:27.803988+09:00)
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 12:13:27 KST)" (scheduled at 2025-01-16 12:12:27.803988+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:13:27 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 114, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 12:13:27 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 475, in crawling_FOX
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:13:36 KST)" (scheduled at 2025-01-16 12:12:36.095358+09:00)
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 12:13:36 KST)" (scheduled at 2025-01-16 12:12:36.096348+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:13:36 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 114, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 12:13:36 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 475, in crawling_FOX
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:14:27 KST)" (scheduled at 2025-01-16 12:13:27.803988+09:00)
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 12:14:27 KST)" (scheduled at 2025-01-16 12:13:27.803988+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 12:14:27 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 475, in crawling_FOX
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:14:27 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 114, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:14:36 KST)" (scheduled at 2025-01-16 12:13:36.095358+09:00)
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 12:14:36 KST)" (scheduled at 2025-01-16 12:13:36.096348+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 12:14:36 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 475, in crawling_FOX
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:14:36 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 114, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:15:27 KST)" (scheduled at 2025-01-16 12:14:27.803988+09:00)
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 12:15:27 KST)" (scheduled at 2025-01-16 12:14:27.803988+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:15:27 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 114, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 12:15:27 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 475, in crawling_FOX
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:15:36 KST)" (scheduled at 2025-01-16 12:14:36.095358+09:00)
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 12:15:36 KST)" (scheduled at 2025-01-16 12:14:36.096348+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:15:36 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 114, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 12:15:36 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 475, in crawling_FOX
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:16:27 KST)" (scheduled at 2025-01-16 12:15:27.803988+09:00)
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 12:16:27 KST)" (scheduled at 2025-01-16 12:15:27.803988+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 12:16:27 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 475, in crawling_FOX
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:16:27 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 114, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:16:36 KST)" (scheduled at 2025-01-16 12:15:36.095358+09:00)
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 12:16:36 KST)" (scheduled at 2025-01-16 12:15:36.096348+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:16:36 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 114, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 12:16:36 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 475, in crawling_FOX
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:17:27 KST)" (scheduled at 2025-01-16 12:16:27.803988+09:00)
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 12:17:27 KST)" (scheduled at 2025-01-16 12:16:27.803988+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 12:17:27 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 475, in crawling_FOX
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:17:27 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 114, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:17:36 KST)" (scheduled at 2025-01-16 12:16:36.095358+09:00)
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 12:17:36 KST)" (scheduled at 2025-01-16 12:16:36.096348+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 12:17:36 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 475, in crawling_FOX
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:17:36 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 114, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:18:27 KST)" (scheduled at 2025-01-16 12:17:27.803988+09:00)
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 12:18:27 KST)" (scheduled at 2025-01-16 12:17:27.803988+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:18:27 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 114, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 12:18:27 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 475, in crawling_FOX
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:18:36 KST)" (scheduled at 2025-01-16 12:17:36.095358+09:00)
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 12:18:36 KST)" (scheduled at 2025-01-16 12:17:36.096348+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 12:18:36 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 475, in crawling_FOX
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:18:36 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 114, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:19:27 KST)" (scheduled at 2025-01-16 12:18:27.803988+09:00)
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 12:19:27 KST)" (scheduled at 2025-01-16 12:18:27.803988+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:WDM:Get LATEST chromedriver version for google-chrome
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 12:19:27 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 475, in crawling_FOX
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:19:27 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 114, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:19:36 KST)" (scheduled at 2025-01-16 12:18:36.095358+09:00)
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 12:19:36 KST)" (scheduled at 2025-01-16 12:18:36.096348+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 12:19:36 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 475, in crawling_FOX
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:19:36 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 114, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:20:27 KST)" (scheduled at 2025-01-16 12:19:27.803988+09:00)
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 12:20:27 KST)" (scheduled at 2025-01-16 12:19:27.803988+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 12:20:27 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 475, in crawling_FOX
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:20:27 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 114, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:20:36 KST)" (scheduled at 2025-01-16 12:19:36.095358+09:00)
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 12:20:36 KST)" (scheduled at 2025-01-16 12:19:36.096348+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 12:20:36 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 475, in crawling_FOX
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:20:36 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 114, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:21:27 KST)" (scheduled at 2025-01-16 12:20:27.803988+09:00)
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 12:21:27 KST)" (scheduled at 2025-01-16 12:20:27.803988+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 12:21:27 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 475, in crawling_FOX
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:21:27 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 114, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:21:36 KST)" (scheduled at 2025-01-16 12:20:36.095358+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 12:21:36 KST)" (scheduled at 2025-01-16 12:20:36.096348+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 12:21:36 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 475, in crawling_FOX
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:21:36 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 114, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:22:27 KST)" (scheduled at 2025-01-16 12:21:27.803988+09:00)
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 12:22:27 KST)" (scheduled at 2025-01-16 12:21:27.803988+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 12:22:27 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 475, in crawling_FOX
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:22:27 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 114, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:22:36 KST)" (scheduled at 2025-01-16 12:21:36.095358+09:00)
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 12:22:36 KST)" (scheduled at 2025-01-16 12:21:36.096348+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:22:36 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 114, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 12:22:36 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 475, in crawling_FOX
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:23:27 KST)" (scheduled at 2025-01-16 12:22:27.803988+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 12:23:27 KST)" (scheduled at 2025-01-16 12:22:27.803988+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 12:23:27 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 475, in crawling_FOX
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:23:27 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 114, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:23:36 KST)" (scheduled at 2025-01-16 12:22:36.095358+09:00)
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 12:23:36 KST)" (scheduled at 2025-01-16 12:22:36.096348+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 12:23:36 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 475, in crawling_FOX
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:23:36 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 114, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:24:27 KST)" (scheduled at 2025-01-16 12:23:27.803988+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 12:24:27 KST)" (scheduled at 2025-01-16 12:23:27.803988+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 12:24:27 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 475, in crawling_FOX
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:24:27 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 114, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:24:36 KST)" (scheduled at 2025-01-16 12:23:36.095358+09:00)
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 12:24:36 KST)" (scheduled at 2025-01-16 12:23:36.096348+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:werkzeug: * Detected change in 'C:\\Users\\soldesk\\AppData\\Roaming\\Python\\Python310\\site-packages\\webdriver_manager\\chrome.py', reloading
INFO:werkzeug: * Detected change in 'C:\\Users\\soldesk\\AppData\\Roaming\\Python\\Python310\\site-packages\\webdriver_manager\\core\\manager.py', reloading
INFO:werkzeug: * Detected change in 'C:\\Users\\soldesk\\AppData\\Roaming\\Python\\Python310\\site-packages\\webdriver_manager\\core\\driver_cache.py', reloading
INFO:werkzeug: * Detected change in 'C:\\Users\\soldesk\\AppData\\Roaming\\Python\\Python310\\site-packages\\webdriver_manager\\core\\driver.py', reloading
INFO:werkzeug: * Detected change in 'C:\\Users\\soldesk\\AppData\\Roaming\\Python\\Python310\\site-packages\\webdriver_manager\\drivers\\chrome.py', reloading
INFO:WDM:Get LATEST chromedriver version for google-chrome
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:24:36 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 72, in create_connection
    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):
  File "C:\ProgramData\Anaconda3\lib\socket.py", line 955, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 386, in _make_request
    self._validate_conn(conn)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 1042, in _validate_conn
    conn.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 358, in connect
    self.sock = conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPSConnection object at 0x00000266A70670D0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\requests\adapters.py", line 489, in send
    resp = conn.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='googlechromelabs.github.io', port=443): Max retries exceeded with url: /chrome-for-testing/latest-patch-versions-per-build.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x00000266A70670D0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\webdriver_manager\core\http.py", line 32, in get
    resp = requests.get(
  File "C:\ProgramData\Anaconda3\lib\site-packages\requests\api.py", line 73, in get
    return request("get", url, params=params, **kwargs)
  File "C:\ProgramData\Anaconda3\lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
  File "C:\ProgramData\Anaconda3\lib\site-packages\requests\sessions.py", line 587, in request
    resp = self.send(prep, **send_kwargs)
  File "C:\ProgramData\Anaconda3\lib\site-packages\requests\sessions.py", line 701, in send
    r = adapter.send(request, **kwargs)
  File "C:\ProgramData\Anaconda3\lib\site-packages\requests\adapters.py", line 565, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPSConnectionPool(host='googlechromelabs.github.io', port=443): Max retries exceeded with url: /chrome-for-testing/latest-patch-versions-per-build.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x00000266A70670D0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 113, in crawling_BBC
    driver_path = ChromeDriverManager().install()
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\webdriver_manager\chrome.py", line 40, in install
    driver_path = self._get_driver_binary_path(self.driver)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\webdriver_manager\core\manager.py", line 35, in _get_driver_binary_path
    binary_path = self._cache_manager.find_driver(driver)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\webdriver_manager\core\driver_cache.py", line 105, in find_driver
    driver_version = self.get_cache_key_driver_version(driver)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\webdriver_manager\core\driver_cache.py", line 152, in get_cache_key_driver_version
    return driver.get_driver_version_to_download()
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\webdriver_manager\core\driver.py", line 48, in get_driver_version_to_download
    return self.get_latest_release_version()
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\webdriver_manager\drivers\chrome.py", line 59, in get_latest_release_version
    response = self._http_client.get(url)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\webdriver_manager\core\http.py", line 35, in get
    raise exceptions.ConnectionError(f"Could not reach host. Are you offline?")
requests.exceptions.ConnectionError: Could not reach host. Are you offline?
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 12:24:36 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 72, in create_connection
    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):
  File "C:\ProgramData\Anaconda3\lib\socket.py", line 955, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 386, in _make_request
    self._validate_conn(conn)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 1042, in _validate_conn
    conn.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 358, in connect
    self.sock = conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPSConnection object at 0x00000266A7067970>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\requests\adapters.py", line 489, in send
    resp = conn.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='googlechromelabs.github.io', port=443): Max retries exceeded with url: /chrome-for-testing/latest-patch-versions-per-build.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x00000266A7067970>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\webdriver_manager\core\http.py", line 32, in get
    resp = requests.get(
  File "C:\ProgramData\Anaconda3\lib\site-packages\requests\api.py", line 73, in get
    return request("get", url, params=params, **kwargs)
  File "C:\ProgramData\Anaconda3\lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
  File "C:\ProgramData\Anaconda3\lib\site-packages\requests\sessions.py", line 587, in request
    resp = self.send(prep, **send_kwargs)
  File "C:\ProgramData\Anaconda3\lib\site-packages\requests\sessions.py", line 701, in send
    r = adapter.send(request, **kwargs)
  File "C:\ProgramData\Anaconda3\lib\site-packages\requests\adapters.py", line 565, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPSConnectionPool(host='googlechromelabs.github.io', port=443): Max retries exceeded with url: /chrome-for-testing/latest-patch-versions-per-build.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x00000266A7067970>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 474, in crawling_FOX
    driver_path = ChromeDriverManager().install()
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\webdriver_manager\chrome.py", line 40, in install
    driver_path = self._get_driver_binary_path(self.driver)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\webdriver_manager\core\manager.py", line 35, in _get_driver_binary_path
    binary_path = self._cache_manager.find_driver(driver)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\webdriver_manager\core\driver_cache.py", line 105, in find_driver
    driver_version = self.get_cache_key_driver_version(driver)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\webdriver_manager\core\driver_cache.py", line 152, in get_cache_key_driver_version
    return driver.get_driver_version_to_download()
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\webdriver_manager\core\driver.py", line 48, in get_driver_version_to_download
    return self.get_latest_release_version()
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\webdriver_manager\drivers\chrome.py", line 59, in get_latest_release_version
    response = self._http_client.get(url)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\webdriver_manager\core\http.py", line 35, in get
    raise exceptions.ConnectionError(f"Could not reach host. Are you offline?")
requests.exceptions.ConnectionError: Could not reach host. Are you offline?
INFO:werkzeug: * Detected change in 'C:\\Users\\soldesk\\AppData\\Roaming\\Python\\Python310\\site-packages\\webdriver_manager\\core\\http.py', reloading
INFO:werkzeug: * Detected change in 'C:\\ProgramData\\Anaconda3\\Lib\\site-packages\\requests\\api.py', reloading
INFO:werkzeug: * Detected change in 'C:\\ProgramData\\Anaconda3\\Lib\\site-packages\\requests\\sessions.py', reloading
INFO:werkzeug: * Detected change in 'C:\\ProgramData\\Anaconda3\\Lib\\site-packages\\requests\\adapters.py', reloading
INFO:werkzeug: * Detected change in 'C:\\ProgramData\\Anaconda3\\Lib\\socket.py', reloading
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawling_BBC" to job store "default"
INFO:apscheduler.scheduler:Added job "crawling_FOX" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 524-771-621
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:25:27 KST)" (scheduled at 2025-01-16 12:24:27.803988+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 12:25:27 KST)" (scheduled at 2025-01-16 12:24:27.803988+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 12:25:27 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 475, in crawling_FOX
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:25:27 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 114, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:24:53 KST)" (scheduled at 2025-01-16 12:24:53.178488+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 12:24:53 KST)" (scheduled at 2025-01-16 12:24:53.178488+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 12:25:53 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 475, in crawling_FOX
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:25:53 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 114, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:26:27 KST)" (scheduled at 2025-01-16 12:25:27.803988+09:00)
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 12:26:27 KST)" (scheduled at 2025-01-16 12:25:27.803988+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 12:26:27 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 475, in crawling_FOX
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:26:27 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 114, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:26:53 KST)" (scheduled at 2025-01-16 12:25:53.178488+09:00)
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 12:26:53 KST)" (scheduled at 2025-01-16 12:25:53.178488+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:26:53 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 114, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 12:26:53 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 475, in crawling_FOX
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:27:27 KST)" (scheduled at 2025-01-16 12:26:27.803988+09:00)
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 12:27:27 KST)" (scheduled at 2025-01-16 12:26:27.803988+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 12:27:27 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 475, in crawling_FOX
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:27:27 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 114, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:27:53 KST)" (scheduled at 2025-01-16 12:26:53.178488+09:00)
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 12:27:53 KST)" (scheduled at 2025-01-16 12:26:53.178488+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:WDM:Get LATEST chromedriver version for google-chrome
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 12:27:53 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 475, in crawling_FOX
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:27:53 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 114, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:28:27 KST)" (scheduled at 2025-01-16 12:27:27.803988+09:00)
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 12:28:27 KST)" (scheduled at 2025-01-16 12:27:27.803988+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 12:28:27 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 475, in crawling_FOX
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:28:27 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 114, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawling_BBC" to job store "default"
INFO:apscheduler.scheduler:Added job "crawling_FOX" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
INFO:werkzeug:[33mPress CTRL+C to quit[0m
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawling_BBC" to job store "default"
INFO:apscheduler.scheduler:Added job "crawling_FOX" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 524-771-621
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:29:09 KST)" (scheduled at 2025-01-16 12:29:09.947182+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 12:30:09 KST)" (scheduled at 2025-01-16 12:29:09.948181+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 12:30:09 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 475, in crawling_FOX
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:30:09 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 114, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 12:29:17 KST)" (scheduled at 2025-01-16 12:29:17.741872+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:30:17 KST)" (scheduled at 2025-01-16 12:29:17.741872+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:30:17 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 114, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 12:30:17 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 475, in crawling_FOX
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:31:09 KST)" (scheduled at 2025-01-16 12:30:09.947182+09:00)
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 12:31:09 KST)" (scheduled at 2025-01-16 12:30:09.948181+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 12:31:09 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 475, in crawling_FOX
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:31:09 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 114, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 12:31:17 KST)" (scheduled at 2025-01-16 12:30:17.741872+09:00)
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:31:17 KST)" (scheduled at 2025-01-16 12:30:17.741872+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 12:31:17 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 475, in crawling_FOX
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:31:17 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 114, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:32:09 KST)" (scheduled at 2025-01-16 12:31:09.947182+09:00)
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 12:32:09 KST)" (scheduled at 2025-01-16 12:31:09.948181+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:32:09 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 114, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 12:32:09 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 475, in crawling_FOX
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 12:32:17 KST)" (scheduled at 2025-01-16 12:31:17.741872+09:00)
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:32:17 KST)" (scheduled at 2025-01-16 12:31:17.741872+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:32:17 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 114, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 12:32:17 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 475, in crawling_FOX
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:33:09 KST)" (scheduled at 2025-01-16 12:32:09.947182+09:00)
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 12:33:09 KST)" (scheduled at 2025-01-16 12:32:09.948181+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:33:09 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 114, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 12:33:09 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 475, in crawling_FOX
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 12:33:17 KST)" (scheduled at 2025-01-16 12:32:17.741872+09:00)
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:33:17 KST)" (scheduled at 2025-01-16 12:32:17.741872+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 12:33:17 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 475, in crawling_FOX
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:33:17 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 114, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:34:09 KST)" (scheduled at 2025-01-16 12:33:09.947182+09:00)
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 12:34:09 KST)" (scheduled at 2025-01-16 12:33:09.948181+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:34:09 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 114, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 12:34:09 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 475, in crawling_FOX
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 12:34:17 KST)" (scheduled at 2025-01-16 12:33:17.741872+09:00)
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:34:17 KST)" (scheduled at 2025-01-16 12:33:17.741872+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:34:17 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 114, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 12:34:17 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 475, in crawling_FOX
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:35:09 KST)" (scheduled at 2025-01-16 12:34:09.947182+09:00)
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 12:35:09 KST)" (scheduled at 2025-01-16 12:34:09.948181+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:35:09 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 114, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 12:35:09 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 475, in crawling_FOX
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 12:35:17 KST)" (scheduled at 2025-01-16 12:34:17.741872+09:00)
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:35:17 KST)" (scheduled at 2025-01-16 12:34:17.741872+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 12:35:17 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 475, in crawling_FOX
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:35:17 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 114, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:36:09 KST)" (scheduled at 2025-01-16 12:35:09.947182+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 12:36:09 KST)" (scheduled at 2025-01-16 12:35:09.948181+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:36:09 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 114, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 12:36:09 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 475, in crawling_FOX
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 12:36:17 KST)" (scheduled at 2025-01-16 12:35:17.741872+09:00)
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:36:17 KST)" (scheduled at 2025-01-16 12:35:17.741872+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 12:36:17 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 475, in crawling_FOX
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:36:17 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 114, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:37:09 KST)" (scheduled at 2025-01-16 12:36:09.947182+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 12:37:09 KST)" (scheduled at 2025-01-16 12:36:09.948181+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 12:37:09 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 475, in crawling_FOX
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:37:09 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 114, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 12:37:17 KST)" (scheduled at 2025-01-16 12:36:17.741872+09:00)
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:37:17 KST)" (scheduled at 2025-01-16 12:36:17.741872+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:37:17 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 114, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 12:37:17 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 475, in crawling_FOX
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:38:09 KST)" (scheduled at 2025-01-16 12:37:09.947182+09:00)
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 12:38:09 KST)" (scheduled at 2025-01-16 12:37:09.948181+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:38:09 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 114, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 12:38:09 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 475, in crawling_FOX
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 12:38:17 KST)" (scheduled at 2025-01-16 12:37:17.741872+09:00)
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:38:17 KST)" (scheduled at 2025-01-16 12:37:17.741872+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:38:17 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 114, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 12:38:17 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 475, in crawling_FOX
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:werkzeug: * Detected change in 'C:\\kd\\ws_java\\team4_v2sbm3c\\src\\main\\python\\crawling.py', reloading
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawling_BBC" to job store "default"
INFO:apscheduler.scheduler:Added job "crawling_FOX" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 524-771-621
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:39:09 KST)" (scheduled at 2025-01-16 12:38:09.947182+09:00)
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 12:39:09 KST)" (scheduled at 2025-01-16 12:38:09.948181+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 12:39:09 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 475, in crawling_FOX
    #         try:
UnboundLocalError: local variable 'os' referenced before assignment
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:39:09 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 114, in crawling_BBC
    time.sleep(5)
UnboundLocalError: local variable 'os' referenced before assignment
INFO:werkzeug: * Detected change in 'C:\\kd\\ws_java\\team4_v2sbm3c\\src\\main\\python\\crawling.py', reloading
INFO:werkzeug: * Detected change in 'C:\\kd\\ws_java\\team4_v2sbm3c\\src\\main\\python\\crawling.py', reloading
INFO:werkzeug: * Detected change in 'C:\\kd\\ws_java\\team4_v2sbm3c\\src\\main\\python\\crawling.py', reloading
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawling_BBC" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 524-771-621
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawling_BBC" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
INFO:werkzeug:[33mPress CTRL+C to quit[0m
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawling_BBC" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 524-771-621
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:40:42 KST)" (scheduled at 2025-01-16 12:40:42.529274+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:40:45 KST)" (scheduled at 2025-01-16 12:40:45.395804+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:41:42 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:werkzeug: * Detected change in 'C:\\Users\\soldesk\\AppData\\Roaming\\Python\\Python310\\site-packages\\apscheduler\\executors\\base.py', reloading
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:41:45 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawling_BBC" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 524-771-621
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:42:42 KST)" (scheduled at 2025-01-16 12:41:42.529274+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:42:42 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:41:52 KST)" (scheduled at 2025-01-16 12:41:52.815207+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:42:52 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:43:42 KST)" (scheduled at 2025-01-16 12:42:42.529274+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:43:42 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:43:52 KST)" (scheduled at 2025-01-16 12:42:52.815207+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:43:52 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:44:42 KST)" (scheduled at 2025-01-16 12:43:42.529274+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:44:42 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:44:52 KST)" (scheduled at 2025-01-16 12:43:52.815207+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:44:52 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:45:42 KST)" (scheduled at 2025-01-16 12:44:42.529274+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:45:42 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:45:52 KST)" (scheduled at 2025-01-16 12:44:52.815207+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:45:52 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:46:42 KST)" (scheduled at 2025-01-16 12:45:42.529274+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:46:42 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:46:52 KST)" (scheduled at 2025-01-16 12:45:52.815207+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:46:52 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:47:42 KST)" (scheduled at 2025-01-16 12:46:42.529274+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:47:42 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:47:52 KST)" (scheduled at 2025-01-16 12:46:52.815207+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:47:52 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:48:42 KST)" (scheduled at 2025-01-16 12:47:42.529274+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:48:42 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:48:52 KST)" (scheduled at 2025-01-16 12:47:52.815207+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:48:52 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:49:42 KST)" (scheduled at 2025-01-16 12:48:42.529274+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:49:42 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:49:52 KST)" (scheduled at 2025-01-16 12:48:52.815207+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:49:52 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:50:42 KST)" (scheduled at 2025-01-16 12:49:42.529274+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:50:42 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:50:52 KST)" (scheduled at 2025-01-16 12:49:52.815207+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:50:52 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:51:42 KST)" (scheduled at 2025-01-16 12:50:42.529274+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:51:42 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:51:52 KST)" (scheduled at 2025-01-16 12:50:52.815207+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:51:52 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:52:42 KST)" (scheduled at 2025-01-16 12:51:42.529274+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:52:42 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:52:52 KST)" (scheduled at 2025-01-16 12:51:52.815207+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:52:52 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:53:42 KST)" (scheduled at 2025-01-16 12:52:42.529274+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:53:42 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:53:52 KST)" (scheduled at 2025-01-16 12:52:52.815207+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:53:52 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:54:42 KST)" (scheduled at 2025-01-16 12:53:42.529274+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:54:42 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:54:52 KST)" (scheduled at 2025-01-16 12:53:52.815207+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:54:52 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:55:42 KST)" (scheduled at 2025-01-16 12:54:42.529274+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:55:42 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:55:52 KST)" (scheduled at 2025-01-16 12:54:52.815207+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:55:52 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:56:42 KST)" (scheduled at 2025-01-16 12:55:42.529274+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:56:42 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:56:52 KST)" (scheduled at 2025-01-16 12:55:52.815207+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:56:52 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:57:42 KST)" (scheduled at 2025-01-16 12:56:42.529274+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:57:42 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:57:52 KST)" (scheduled at 2025-01-16 12:56:52.815207+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:57:52 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:58:42 KST)" (scheduled at 2025-01-16 12:57:42.529274+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:58:42 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:58:52 KST)" (scheduled at 2025-01-16 12:57:52.815207+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:58:52 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:59:42 KST)" (scheduled at 2025-01-16 12:58:42.529274+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:59:42 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:59:52 KST)" (scheduled at 2025-01-16 12:58:52.815207+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 12:59:52 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:00:42 KST)" (scheduled at 2025-01-16 12:59:42.529274+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:00:42 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:00:52 KST)" (scheduled at 2025-01-16 12:59:52.815207+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:00:52 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:01:42 KST)" (scheduled at 2025-01-16 13:00:42.529274+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:01:42 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:01:52 KST)" (scheduled at 2025-01-16 13:00:52.815207+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:01:52 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:02:42 KST)" (scheduled at 2025-01-16 13:01:42.529274+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:02:42 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:02:52 KST)" (scheduled at 2025-01-16 13:01:52.815207+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:02:52 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawling_BBC" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
INFO:werkzeug:[33mPress CTRL+C to quit[0m
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawling_BBC" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 524-771-621
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:02:00], next run at: 2025-01-16 13:04:39 KST)" (scheduled at 2025-01-16 13:04:39.119194+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:02:00], next run at: 2025-01-16 13:04:42 KST)" (scheduled at 2025-01-16 13:04:42.579802+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:02:00], next run at: 2025-01-16 13:06:39 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:02:00], next run at: 2025-01-16 13:06:42 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:02:00], next run at: 2025-01-16 13:08:39 KST)" (scheduled at 2025-01-16 13:06:39.119194+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:02:00], next run at: 2025-01-16 13:08:42 KST)" (scheduled at 2025-01-16 13:06:42.579802+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:02:00], next run at: 2025-01-16 13:08:39 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:02:00], next run at: 2025-01-16 13:08:42 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:02:00], next run at: 2025-01-16 13:10:39 KST)" (scheduled at 2025-01-16 13:08:39.119194+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:02:00], next run at: 2025-01-16 13:10:42 KST)" (scheduled at 2025-01-16 13:08:42.579802+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:02:00], next run at: 2025-01-16 13:10:39 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:02:00], next run at: 2025-01-16 13:10:42 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:02:00], next run at: 2025-01-16 13:12:39 KST)" (scheduled at 2025-01-16 13:10:39.119194+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:02:00], next run at: 2025-01-16 13:12:42 KST)" (scheduled at 2025-01-16 13:10:42.579802+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:02:00], next run at: 2025-01-16 13:12:39 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:02:00], next run at: 2025-01-16 13:12:42 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:werkzeug: * Detected change in 'C:\\kd\\ws_java\\team4_v2sbm3c\\src\\main\\python\\crawling.py', reloading
INFO:werkzeug: * Detected change in 'C:\\kd\\ws_java\\team4_v2sbm3c\\src\\main\\python\\crawling.py', reloading
INFO:werkzeug: * Detected change in 'C:\\kd\\ws_java\\team4_v2sbm3c\\src\\main\\python\\crawling.py', reloading
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawling_BBC" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 524-771-621
INFO:werkzeug: * Detected change in 'C:\\Users\\soldesk\\AppData\\Roaming\\Python\\Python310\\site-packages\\openai\\_version.py', reloading
INFO:werkzeug: * Detected change in 'C:\\Users\\soldesk\\AppData\\Roaming\\Python\\Python310\\site-packages\\openai\\_response.py', reloading
INFO:werkzeug: * Detected change in 'C:\\Users\\soldesk\\AppData\\Roaming\\Python\\Python310\\site-packages\\openai\\_exceptions.py', reloading
INFO:werkzeug: * Detected change in 'C:\\Users\\soldesk\\AppData\\Roaming\\Python\\Python310\\site-packages\\openai\\lib\\__init__.py', reloading
INFO:werkzeug: * Detected change in 'C:\\Users\\soldesk\\AppData\\Roaming\\Python\\Python310\\site-packages\\openai\\lib\\_tools.py', reloading
INFO:werkzeug: * Detected change in 'C:\\Users\\soldesk\\AppData\\Roaming\\Python\\Python310\\site-packages\\openai\\version.py', reloading
INFO:werkzeug: * Detected change in 'C:\\Users\\soldesk\\AppData\\Roaming\\Python\\Python310\\site-packages\\openai\\lib\\azure.py', reloading
INFO:werkzeug: * Detected change in 'C:\\Users\\soldesk\\AppData\\Roaming\\Python\\Python310\\site-packages\\openai\\lib\\streaming\\__init__.py', reloading
INFO:werkzeug: * Detected change in 'C:\\Users\\soldesk\\AppData\\Roaming\\Python\\Python310\\site-packages\\openai\\lib\\streaming\\_assistants.py', reloading
INFO:werkzeug: * Detected change in 'C:\\Users\\soldesk\\AppData\\Roaming\\Python\\Python310\\site-packages\\openai\\_module_client.py', reloading
INFO:werkzeug: * Detected change in 'C:\\Users\\soldesk\\AppData\\Roaming\\Python\\Python310\\site-packages\\tzlocal\\utils.py', reloading
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:02:00], next run at: 2025-01-16 13:14:39 KST)" (scheduled at 2025-01-16 13:12:39.119194+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:02:00], next run at: 2025-01-16 13:14:39 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawling_BBC" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 524-771-621
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawling_BBC" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
INFO:werkzeug:[33mPress CTRL+C to quit[0m
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawling_BBC" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 524-771-621
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:14:46 KST)" (scheduled at 2025-01-16 13:14:46.735358+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:14:49 KST)" (scheduled at 2025-01-16 13:14:49.563618+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:15:46 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:15:49 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:16:46 KST)" (scheduled at 2025-01-16 13:15:46.735358+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:16:49 KST)" (scheduled at 2025-01-16 13:15:49.563618+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:16:46 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:16:49 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:17:46 KST)" (scheduled at 2025-01-16 13:16:46.735358+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:17:49 KST)" (scheduled at 2025-01-16 13:16:49.563618+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:17:46 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:17:49 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:18:46 KST)" (scheduled at 2025-01-16 13:17:46.735358+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:18:49 KST)" (scheduled at 2025-01-16 13:17:49.563618+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:18:46 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:18:49 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:19:46 KST)" (scheduled at 2025-01-16 13:18:46.735358+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:19:49 KST)" (scheduled at 2025-01-16 13:18:49.563618+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:19:46 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:19:49 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:20:46 KST)" (scheduled at 2025-01-16 13:19:46.735358+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:20:49 KST)" (scheduled at 2025-01-16 13:19:49.563618+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:20:46 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:20:49 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:21:46 KST)" (scheduled at 2025-01-16 13:20:46.735358+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:21:49 KST)" (scheduled at 2025-01-16 13:20:49.563618+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:21:46 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:21:49 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:22:46 KST)" (scheduled at 2025-01-16 13:21:46.735358+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:22:49 KST)" (scheduled at 2025-01-16 13:21:49.563618+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:22:46 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:22:49 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:23:46 KST)" (scheduled at 2025-01-16 13:22:46.735358+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:23:49 KST)" (scheduled at 2025-01-16 13:22:49.563618+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:23:46 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:23:49 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:24:46 KST)" (scheduled at 2025-01-16 13:23:46.735358+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:24:49 KST)" (scheduled at 2025-01-16 13:23:49.563618+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:24:46 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:24:49 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:25:46 KST)" (scheduled at 2025-01-16 13:24:46.735358+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:25:49 KST)" (scheduled at 2025-01-16 13:24:49.563618+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:25:46 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:25:49 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:26:46 KST)" (scheduled at 2025-01-16 13:25:46.735358+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:26:49 KST)" (scheduled at 2025-01-16 13:25:49.563618+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:26:46 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:26:49 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:27:46 KST)" (scheduled at 2025-01-16 13:26:46.735358+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:27:49 KST)" (scheduled at 2025-01-16 13:26:49.563618+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:27:46 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:27:49 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:28:46 KST)" (scheduled at 2025-01-16 13:27:46.735358+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:28:49 KST)" (scheduled at 2025-01-16 13:27:49.563618+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:28:46 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:28:49 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:29:46 KST)" (scheduled at 2025-01-16 13:28:46.735358+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:29:49 KST)" (scheduled at 2025-01-16 13:28:49.563618+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:29:46 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:29:49 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:30:46 KST)" (scheduled at 2025-01-16 13:29:46.735358+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:30:49 KST)" (scheduled at 2025-01-16 13:29:49.563618+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:30:46 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:30:49 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:31:46 KST)" (scheduled at 2025-01-16 13:30:46.735358+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:31:49 KST)" (scheduled at 2025-01-16 13:30:49.563618+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:31:46 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:31:49 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:32:46 KST)" (scheduled at 2025-01-16 13:31:46.735358+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:32:49 KST)" (scheduled at 2025-01-16 13:31:49.563618+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:32:46 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:32:49 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:33:46 KST)" (scheduled at 2025-01-16 13:32:46.735358+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:33:49 KST)" (scheduled at 2025-01-16 13:32:49.563618+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:33:46 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:33:49 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:34:46 KST)" (scheduled at 2025-01-16 13:33:46.735358+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:34:49 KST)" (scheduled at 2025-01-16 13:33:49.563618+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:34:46 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:34:49 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:35:46 KST)" (scheduled at 2025-01-16 13:34:46.735358+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:35:49 KST)" (scheduled at 2025-01-16 13:34:49.563618+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:35:46 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:35:49 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:36:46 KST)" (scheduled at 2025-01-16 13:35:46.735358+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:36:49 KST)" (scheduled at 2025-01-16 13:35:49.563618+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:36:46 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:36:49 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:37:46 KST)" (scheduled at 2025-01-16 13:36:46.735358+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:37:49 KST)" (scheduled at 2025-01-16 13:36:49.563618+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:37:46 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:37:49 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:38:46 KST)" (scheduled at 2025-01-16 13:37:46.735358+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:38:49 KST)" (scheduled at 2025-01-16 13:37:49.563618+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:38:46 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:38:49 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:39:46 KST)" (scheduled at 2025-01-16 13:38:46.735358+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:39:49 KST)" (scheduled at 2025-01-16 13:38:49.563618+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:39:46 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:39:49 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:40:46 KST)" (scheduled at 2025-01-16 13:39:46.735358+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:40:49 KST)" (scheduled at 2025-01-16 13:39:49.563618+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:40:46 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:40:49 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:41:46 KST)" (scheduled at 2025-01-16 13:40:46.735358+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:41:49 KST)" (scheduled at 2025-01-16 13:40:49.563618+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:41:46 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:41:49 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:42:46 KST)" (scheduled at 2025-01-16 13:41:46.735358+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:42:49 KST)" (scheduled at 2025-01-16 13:41:49.563618+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:42:46 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:42:49 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:43:46 KST)" (scheduled at 2025-01-16 13:42:46.735358+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:43:49 KST)" (scheduled at 2025-01-16 13:42:49.563618+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:43:46 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:43:49 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:44:46 KST)" (scheduled at 2025-01-16 13:43:46.735358+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:44:49 KST)" (scheduled at 2025-01-16 13:43:49.563618+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:44:46 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:44:49 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:45:46 KST)" (scheduled at 2025-01-16 13:44:46.735358+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:45:49 KST)" (scheduled at 2025-01-16 13:44:49.563618+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:45:46 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:45:49 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:46:46 KST)" (scheduled at 2025-01-16 13:45:46.735358+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:46:49 KST)" (scheduled at 2025-01-16 13:45:49.563618+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:46:46 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:46:49 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:47:46 KST)" (scheduled at 2025-01-16 13:46:46.735358+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:47:49 KST)" (scheduled at 2025-01-16 13:46:49.563618+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:47:46 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:47:49 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:48:46 KST)" (scheduled at 2025-01-16 13:47:46.735358+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:48:49 KST)" (scheduled at 2025-01-16 13:47:49.563618+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:48:46 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:48:49 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:49:46 KST)" (scheduled at 2025-01-16 13:48:46.735358+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:49:49 KST)" (scheduled at 2025-01-16 13:48:49.563618+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:49:46 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:49:49 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:50:46 KST)" (scheduled at 2025-01-16 13:49:46.735358+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:50:49 KST)" (scheduled at 2025-01-16 13:49:49.563618+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:50:46 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:50:49 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:51:46 KST)" (scheduled at 2025-01-16 13:50:46.735358+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:51:49 KST)" (scheduled at 2025-01-16 13:50:49.563618+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:51:46 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:51:49 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:52:46 KST)" (scheduled at 2025-01-16 13:51:46.735358+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:52:49 KST)" (scheduled at 2025-01-16 13:51:49.563618+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:52:46 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:52:49 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:53:46 KST)" (scheduled at 2025-01-16 13:52:46.735358+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:53:49 KST)" (scheduled at 2025-01-16 13:52:49.563618+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:53:46 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:53:49 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:54:46 KST)" (scheduled at 2025-01-16 13:53:46.735358+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:54:49 KST)" (scheduled at 2025-01-16 13:53:49.563618+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:54:46 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:54:49 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:55:46 KST)" (scheduled at 2025-01-16 13:54:46.735358+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:55:49 KST)" (scheduled at 2025-01-16 13:54:49.563618+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:55:46 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:55:49 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:56:46 KST)" (scheduled at 2025-01-16 13:55:46.735358+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:56:49 KST)" (scheduled at 2025-01-16 13:55:49.563618+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:56:46 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:56:49 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:57:46 KST)" (scheduled at 2025-01-16 13:56:46.735358+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:57:49 KST)" (scheduled at 2025-01-16 13:56:49.563618+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:57:46 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:57:49 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:58:46 KST)" (scheduled at 2025-01-16 13:57:46.735358+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:58:49 KST)" (scheduled at 2025-01-16 13:57:49.563618+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:58:46 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:58:49 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:59:46 KST)" (scheduled at 2025-01-16 13:58:46.735358+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:59:49 KST)" (scheduled at 2025-01-16 13:58:49.563618+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:59:46 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 13:59:49 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 14:00:46 KST)" (scheduled at 2025-01-16 13:59:46.735358+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 14:00:49 KST)" (scheduled at 2025-01-16 13:59:49.563618+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 14:00:46 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 14:00:49 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 14:01:46 KST)" (scheduled at 2025-01-16 14:00:46.735358+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 14:01:49 KST)" (scheduled at 2025-01-16 14:00:49.563618+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 14:01:46 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 14:01:49 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 14:02:46 KST)" (scheduled at 2025-01-16 14:01:46.735358+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 14:02:49 KST)" (scheduled at 2025-01-16 14:01:49.563618+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 14:02:46 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 14:02:49 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 14:03:46 KST)" (scheduled at 2025-01-16 14:02:46.735358+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 14:03:49 KST)" (scheduled at 2025-01-16 14:02:49.563618+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 14:03:46 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 14:03:49 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 14:04:46 KST)" (scheduled at 2025-01-16 14:03:46.735358+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 14:04:49 KST)" (scheduled at 2025-01-16 14:03:49.563618+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 14:04:46 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 14:04:49 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 14:05:46 KST)" (scheduled at 2025-01-16 14:04:46.735358+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:werkzeug: * Detected change in 'C:\\ProgramData\\Anaconda3\\Lib\\site-packages\\numpy\\_typing\\_extended_precision.py', reloading
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 14:05:46 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawling_BBC" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 524-771-621
INFO:werkzeug: * Detected change in 'C:\\Users\\soldesk\\AppData\\Roaming\\Python\\Python310\\site-packages\\openai\\types\\chat\\chat_completion_role.py', reloading
INFO:werkzeug: * Detected change in 'C:\\Users\\soldesk\\AppData\\Roaming\\Python\\Python310\\site-packages\\openai\\types\\chat\\parsed_chat_completion.py', reloading
INFO:werkzeug: * Detected change in 'C:\\Users\\soldesk\\AppData\\Roaming\\Python\\Python310\\site-packages\\openai\\types\\chat\\parsed_function_tool_call.py', reloading
INFO:werkzeug: * Detected change in 'C:\\Users\\soldesk\\AppData\\Roaming\\Python\\Python310\\site-packages\\openai\\types\\chat\\chat_completion_token_logprob.py', reloading
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawling_BBC" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 524-771-621
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 14:06:46 KST)" (scheduled at 2025-01-16 14:05:46.735358+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 14:06:46 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
    correct_driver_path = os.path.join(os.path.dirname(driver_path), "chromedriver.exe")
UnboundLocalError: local variable 'os' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 14:05:59 KST)" (scheduled at 2025-01-16 14:05:59.271699+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:werkzeug: * Detected change in 'C:\\kd\\ws_java\\team4_v2sbm3c\\src\\main\\python\\crawling.py', reloading
INFO:werkzeug: * Detected change in 'C:\\kd\\ws_java\\team4_v2sbm3c\\src\\main\\python\\crawling.py', reloading
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 14:06:59 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
UnboundLocalError: local variable 'os' referenced before assignment
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawling_BBC" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 524-771-621
INFO:werkzeug: * Detected change in 'C:\\kd\\ws_java\\team4_v2sbm3c\\src\\main\\python\\crawling.py', reloading
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawling_BBC" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 524-771-621
INFO:werkzeug: * Detected change in 'C:\\ProgramData\\Anaconda3\\Lib\\ntpath.py', reloading
INFO:werkzeug: * Detected change in 'C:\\kd\\ws_java\\team4_v2sbm3c\\src\\main\\python\\crawling.py', reloading
INFO:werkzeug: * Detected change in 'C:\\kd\\ws_java\\team4_v2sbm3c\\src\\main\\python\\crawling.py', reloading
INFO:werkzeug: * Detected change in 'C:\\kd\\ws_java\\team4_v2sbm3c\\src\\main\\python\\crawling.py', reloading
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 14:07:46 KST)" (scheduled at 2025-01-16 14:06:46.735358+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 14:07:46 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 91, in crawling_BBC
UnboundLocalError: local variable 'os' referenced before assignment
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawling_BBC" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 524-771-621
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawling_BBC" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
INFO:werkzeug:[33mPress CTRL+C to quit[0m
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawling_BBC" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 524-771-621
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 14:08:14 KST)" (scheduled at 2025-01-16 14:08:14.843477+09:00)
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 14:08:22 KST)" (scheduled at 2025-01-16 14:08:22.657877+09:00)
INFO:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 14:09:22 KST)" executed successfully
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
INFO:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 14:09:14 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 14:10:14 KST)" (scheduled at 2025-01-16 14:09:14.843477+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001F1D8421A50>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4df2ceb09789e82b35908f3977f9a409/url
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 14:10:22 KST)" (scheduled at 2025-01-16 14:09:22.657877+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001F1D7D29360>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4df2ceb09789e82b35908f3977f9a409/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001F1DA76D030>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4df2ceb09789e82b35908f3977f9a409/url
INFO:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 14:10:22 KST)" executed successfully
INFO:werkzeug: * Detected change in 'C:\\Users\\soldesk\\AppData\\Roaming\\Python\\Python310\\site-packages\\selenium\\webdriver\\remote\\webdriver.py', reloading
INFO:werkzeug: * Detected change in 'C:\\Users\\soldesk\\AppData\\Roaming\\Python\\Python310\\site-packages\\selenium\\webdriver\\remote\\remote_connection.py', reloading
INFO:werkzeug: * Detected change in 'C:\\ProgramData\\Anaconda3\\Lib\\site-packages\\urllib3\\request.py', reloading
INFO:werkzeug: * Detected change in 'C:\\ProgramData\\Anaconda3\\Lib\\site-packages\\urllib3\\poolmanager.py', reloading
INFO:werkzeug: * Detected change in 'C:\\ProgramData\\Anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py', reloading
INFO:werkzeug: * Detected change in 'C:\\ProgramData\\Anaconda3\\Lib\\site-packages\\urllib3\\util\\retry.py', reloading
INFO:werkzeug: * Detected change in 'C:\\ProgramData\\Anaconda3\\Lib\\site-packages\\urllib3\\connection.py', reloading
INFO:werkzeug: * Detected change in 'C:\\ProgramData\\Anaconda3\\Lib\\http\\client.py', reloading
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 14:10:14 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001F1DA733F70>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawling_BBC
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=56446): Max retries exceeded with url: /session/4df2ceb09789e82b35908f3977f9a409/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001F1DA733F70>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
INFO:werkzeug: * Detected change in 'C:\\ProgramData\\Anaconda3\\Lib\\site-packages\\urllib3\\util\\connection.py', reloading
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawling_BBC" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 524-771-621
INFO:werkzeug: * Detected change in 'C:\\kd\\ws_java\\team4_v2sbm3c\\src\\main\\python\\crawling.py', reloading
INFO:werkzeug: * Detected change in 'C:\\kd\\ws_java\\team4_v2sbm3c\\src\\main\\python\\crawling_BBC.py', reloading
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawling_BBC" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
INFO:werkzeug:[33mPress CTRL+C to quit[0m
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawling_BBC" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 524-771-621
INFO:werkzeug: * Detected change in 'C:\\kd\\ws_java\\team4_v2sbm3c\\src\\main\\python\\crawling_FOX.py', reloading
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 14:11:07 KST)" (scheduled at 2025-01-16 14:11:07.435466+09:00)
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawling_BBC" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 524-771-621
INFO:werkzeug: * Detected change in 'C:\\ProgramData\\Anaconda3\\Lib\\urllib\\parse.py', reloading
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
WARNING:apscheduler.scheduler:Execution of job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 14:12:07 KST)" skipped: maximum number of running instances reached (1)
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 14:13:07 KST)" executed successfully
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawling_BBC" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 524-771-621
INFO:werkzeug: * Detected change in 'C:\\kd\\ws_java\\team4_v2sbm3c\\src\\main\\python\\crawling_FOX.py', reloading
INFO:werkzeug: * Detected change in 'C:\\kd\\ws_java\\team4_v2sbm3c\\src\\main\\python\\crawling_FOX.py', reloading
INFO:werkzeug: * Detected change in 'C:\\kd\\ws_java\\team4_v2sbm3c\\src\\main\\python\\crawling_FOX.py', reloading
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawling_BBC" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 524-771-621
INFO:werkzeug: * Detected change in 'C:\\Users\\soldesk\\AppData\\Roaming\\Python\\Python310\\site-packages\\selenium\\webdriver\\common\\action_chains.py', reloading
INFO:werkzeug: * Detected change in 'C:\\Users\\soldesk\\AppData\\Roaming\\Python\\Python310\\site-packages\\selenium\\webdriver\\common\\desired_capabilities.py', reloading
INFO:werkzeug: * Detected change in 'C:\\Users\\soldesk\\AppData\\Roaming\\Python\\Python310\\site-packages\\selenium\\webdriver\\common\\keys.py', reloading
INFO:werkzeug: * Detected change in 'C:\\Users\\soldesk\\AppData\\Roaming\\Python\\Python310\\site-packages\\selenium\\webdriver\\common\\proxy.py', reloading
INFO:werkzeug: * Detected change in 'C:\\Users\\soldesk\\AppData\\Roaming\\Python\\Python310\\site-packages\\selenium\\webdriver\\edge\\options.py', reloading
INFO:werkzeug: * Detected change in 'C:\\Users\\soldesk\\AppData\\Roaming\\Python\\Python310\\site-packages\\selenium\\webdriver\\edge\\service.py', reloading
INFO:werkzeug: * Detected change in 'C:\\Users\\soldesk\\AppData\\Roaming\\Python\\Python310\\site-packages\\selenium\\webdriver\\edge\\webdriver.py', reloading
INFO:werkzeug: * Detected change in 'C:\\Users\\soldesk\\AppData\\Roaming\\Python\\Python310\\site-packages\\selenium\\webdriver\\firefox\\firefox_profile.py', reloading
INFO:werkzeug: * Detected change in 'C:\\Users\\soldesk\\AppData\\Roaming\\Python\\Python310\\site-packages\\selenium\\webdriver\\firefox\\options.py', reloading
INFO:werkzeug: * Detected change in 'C:\\Users\\soldesk\\AppData\\Roaming\\Python\\Python310\\site-packages\\selenium\\webdriver\\firefox\\service.py', reloading
INFO:werkzeug: * Detected change in 'C:\\Users\\soldesk\\AppData\\Roaming\\Python\\Python310\\site-packages\\selenium\\webdriver\\firefox\\webdriver.py', reloading
INFO:werkzeug: * Detected change in 'C:\\Users\\soldesk\\AppData\\Roaming\\Python\\Python310\\site-packages\\selenium\\webdriver\\ie\\options.py', reloading
INFO:werkzeug: * Detected change in 'C:\\Users\\soldesk\\AppData\\Roaming\\Python\\Python310\\site-packages\\selenium\\webdriver\\ie\\service.py', reloading
INFO:werkzeug: * Detected change in 'C:\\Users\\soldesk\\AppData\\Roaming\\Python\\Python310\\site-packages\\selenium\\webdriver\\ie\\webdriver.py', reloading
INFO:werkzeug: * Detected change in 'C:\\Users\\soldesk\\AppData\\Roaming\\Python\\Python310\\site-packages\\selenium\\webdriver\\safari\\options.py', reloading
INFO:werkzeug: * Detected change in 'C:\\Users\\soldesk\\AppData\\Roaming\\Python\\Python310\\site-packages\\selenium\\webdriver\\safari\\service.py', reloading
INFO:werkzeug: * Detected change in 'C:\\Users\\soldesk\\AppData\\Roaming\\Python\\Python310\\site-packages\\selenium\\webdriver\\safari\\webdriver.py', reloading
INFO:werkzeug: * Detected change in 'C:\\Users\\soldesk\\AppData\\Roaming\\Python\\Python310\\site-packages\\selenium\\webdriver\\webkitgtk\\options.py', reloading
INFO:werkzeug: * Detected change in 'C:\\Users\\soldesk\\AppData\\Roaming\\Python\\Python310\\site-packages\\selenium\\webdriver\\webkitgtk\\service.py', reloading
INFO:werkzeug: * Detected change in 'C:\\Users\\soldesk\\AppData\\Roaming\\Python\\Python310\\site-packages\\selenium\\webdriver\\webkitgtk\\webdriver.py', reloading
INFO:werkzeug: * Detected change in 'C:\\Users\\soldesk\\AppData\\Roaming\\Python\\Python310\\site-packages\\selenium\\webdriver\\wpewebkit\\options.py', reloading
INFO:werkzeug: * Detected change in 'C:\\Users\\soldesk\\AppData\\Roaming\\Python\\Python310\\site-packages\\selenium\\webdriver\\wpewebkit\\service.py', reloading
INFO:werkzeug: * Detected change in 'C:\\Users\\soldesk\\AppData\\Roaming\\Python\\Python310\\site-packages\\selenium\\webdriver\\wpewebkit\\webdriver.py', reloading
INFO:werkzeug: * Detected change in 'C:\\ProgramData\\Anaconda3\\Lib\\site-packages\\flask\\wrappers.py', reloading
INFO:werkzeug: * Detected change in 'C:\\ProgramData\\Anaconda3\\Lib\\site-packages\\flask\\blueprints.py', reloading
INFO:werkzeug: * Detected change in 'C:\\ProgramData\\Anaconda3\\Lib\\site-packages\\flask\\ctx.py', reloading
INFO:werkzeug: * Detected change in 'C:\\ProgramData\\Anaconda3\\Lib\\site-packages\\flask\\globals.py', reloading
INFO:werkzeug: * Detected change in 'C:\\ProgramData\\Anaconda3\\Lib\\site-packages\\flask\\helpers.py', reloading
INFO:werkzeug: * Detected change in 'C:\\ProgramData\\Anaconda3\\Lib\\site-packages\\flask\\json\\__init__.py', reloading
INFO:werkzeug: * Detected change in 'C:\\ProgramData\\Anaconda3\\Lib\\site-packages\\flask\\signals.py', reloading
INFO:werkzeug: * Detected change in 'C:\\ProgramData\\Anaconda3\\Lib\\site-packages\\flask\\templating.py', reloading
INFO:werkzeug: * Detected change in 'C:\\Users\\soldesk\\AppData\\Roaming\\Python\\Python310\\site-packages\\tzlocal\\__init__.py', reloading
INFO:werkzeug: * Detected change in 'C:\\Users\\soldesk\\AppData\\Roaming\\Python\\Python310\\site-packages\\tzlocal\\win32.py', reloading
INFO:werkzeug: * Detected change in 'C:\\Users\\soldesk\\AppData\\Roaming\\Python\\Python310\\site-packages\\apscheduler\\schedulers\\__init__.py', reloading
INFO:werkzeug: * Detected change in 'C:\\Users\\soldesk\\AppData\\Roaming\\Python\\Python310\\site-packages\\tzlocal\\utils.py', reloading
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawling_BBC" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 524-771-621
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 14:14:07 KST)" (scheduled at 2025-01-16 14:13:07.435466+09:00)
INFO:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 14:14:07 KST)" executed successfully
INFO:werkzeug: * Detected change in 'C:\\kd\\ws_java\\team4_v2sbm3c\\src\\main\\python\\crawling_FOX.py', reloading
INFO:werkzeug: * Detected change in 'C:\\kd\\ws_java\\team4_v2sbm3c\\src\\main\\python\\crawling_FOX.py', reloading
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawling_BBC" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 524-771-621
INFO:WDM:====== WebDriver manager ======
INFO:werkzeug: * Detected change in 'C:\\ProgramData\\Anaconda3\\Lib\\site-packages\\pandas\\io\\sql.py', reloading
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawling_BBC" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
INFO:werkzeug:[33mPress CTRL+C to quit[0m
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawling_BBC" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 524-771-621
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawling_BBC" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 524-771-621
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 14:15:07 KST)" (scheduled at 2025-01-16 14:14:07.435466+09:00)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawling_BBC" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
INFO:werkzeug:[33mPress CTRL+C to quit[0m
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawling_BBC" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
INFO:werkzeug:[33mPress CTRL+C to quit[0m
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawling_BBC" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 524-771-621
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 14:16:51 KST)" (scheduled at 2025-01-16 14:16:51.558217+09:00)
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 14:16:59 KST)" (scheduled at 2025-01-16 14:16:59.833487+09:00)
INFO:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 14:17:59 KST)" executed successfully
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
INFO:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 14:17:51 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 14:18:51 KST)" (scheduled at 2025-01-16 14:17:51.558217+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000002465123B5B0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/774e5d2635d15b474477f789ee4dbaa7/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000024650B6FCA0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/774e5d2635d15b474477f789ee4dbaa7/url
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 14:18:59 KST)" (scheduled at 2025-01-16 14:17:59.833487+09:00)
INFO:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 14:18:59 KST)" executed successfully
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000024653646CB0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/774e5d2635d15b474477f789ee4dbaa7/url
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 14:18:51 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x00000246535E3AF0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling_BBC.py", line 105, in crawling_BBC
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling_BBC.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=58875): Max retries exceeded with url: /session/774e5d2635d15b474477f789ee4dbaa7/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000246535E3AF0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 14:19:51 KST)" (scheduled at 2025-01-16 14:18:51.558217+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000246535E3940>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/774e5d2635d15b474477f789ee4dbaa7/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000246535E38B0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/774e5d2635d15b474477f789ee4dbaa7/url
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 14:19:59 KST)" (scheduled at 2025-01-16 14:18:59.833487+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000246535E37F0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/774e5d2635d15b474477f789ee4dbaa7/url
INFO:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 14:19:59 KST)" executed successfully
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 14:19:51 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x00000246535E3730>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling_BBC.py", line 105, in crawling_BBC
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling_BBC.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=58875): Max retries exceeded with url: /session/774e5d2635d15b474477f789ee4dbaa7/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000246535E3730>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 14:20:51 KST)" (scheduled at 2025-01-16 14:19:51.558217+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000246535E2350>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/774e5d2635d15b474477f789ee4dbaa7/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000246535E24A0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/774e5d2635d15b474477f789ee4dbaa7/url
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 14:20:59 KST)" (scheduled at 2025-01-16 14:19:59.833487+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000246535E21A0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/774e5d2635d15b474477f789ee4dbaa7/url
INFO:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 14:20:59 KST)" executed successfully
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 14:20:51 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x00000246535E2500>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling_BBC.py", line 105, in crawling_BBC
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling_BBC.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=58875): Max retries exceeded with url: /session/774e5d2635d15b474477f789ee4dbaa7/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000246535E2500>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 14:21:51 KST)" (scheduled at 2025-01-16 14:20:51.558217+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000246535E1FC0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/774e5d2635d15b474477f789ee4dbaa7/url
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawling_FOX" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
INFO:werkzeug:[33mPress CTRL+C to quit[0m
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawling_FOX" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 524-771-621
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 14:22:13 KST)" (scheduled at 2025-01-16 14:22:13.082653+09:00)
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 14:23:13 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling_FOX.py", line 103, in crawling_FOX
    time.sleep(5)
UnboundLocalError: local variable 'time' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 14:22:21 KST)" (scheduled at 2025-01-16 14:22:21.090889+09:00)
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 14:23:21 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling_FOX.py", line 103, in crawling_FOX
    time.sleep(5)
UnboundLocalError: local variable 'time' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 14:24:13 KST)" (scheduled at 2025-01-16 14:23:13.082653+09:00)
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 14:24:13 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling_FOX.py", line 103, in crawling_FOX
    time.sleep(5)
UnboundLocalError: local variable 'time' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 14:24:21 KST)" (scheduled at 2025-01-16 14:23:21.090889+09:00)
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 14:24:21 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling_FOX.py", line 103, in crawling_FOX
    time.sleep(5)
UnboundLocalError: local variable 'time' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 14:25:13 KST)" (scheduled at 2025-01-16 14:24:13.082653+09:00)
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 14:25:13 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling_FOX.py", line 103, in crawling_FOX
    time.sleep(5)
UnboundLocalError: local variable 'time' referenced before assignment
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 14:25:21 KST)" (scheduled at 2025-01-16 14:24:21.090889+09:00)
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 14:25:21 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling_FOX.py", line 103, in crawling_FOX
    time.sleep(5)
UnboundLocalError: local variable 'time' referenced before assignment
INFO:werkzeug: * Detected change in 'C:\\ProgramData\\Anaconda3\\Lib\\urllib\\request.py', reloading
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 14:26:13 KST)" (scheduled at 2025-01-16 14:25:13.082653+09:00)
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 14:26:13 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling_FOX.py", line 103, in crawling_FOX
    time.sleep(5)
UnboundLocalError: local variable 'time' referenced before assignment
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawling_FOX" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 524-771-621
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawling_FOX" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
INFO:werkzeug:[33mPress CTRL+C to quit[0m
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawling_FOX" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 524-771-621
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 14:42:25 KST)" (scheduled at 2025-01-16 14:42:25.985987+09:00)
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 14:43:25 KST)" raised an exception
Traceback (most recent call last):
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling_FOX.py", line 107, in crawling_FOX
    driver.find_element(By.CSS_SELECTOR, '#wrapper > div.page > div.region-content-sidebar > main > div.big-top > div > article > div.info > header > h3 > a').click()
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 741, in find_element
    return self.execute(Command.FIND_ELEMENT, {"using": by, "value": value})["value"]
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchWindowException: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x010FFD53+23747]
	(No symbol) [0x01087D54]
	(No symbol) [0x00F5BE53]
	(No symbol) [0x00F3D91B]
	(No symbol) [0x00FC7EFF]
	(No symbol) [0x00FDAD49]
	(No symbol) [0x00FC1B96]
	(No symbol) [0x00F93F3C]
	(No symbol) [0x00F94EBD]
	GetHandleVerifier [0x013DAC73+3017699]
	GetHandleVerifier [0x013EB93B+3086507]
	GetHandleVerifier [0x013E40F2+3055714]
	GetHandleVerifier [0x01195AF0+637536]
	(No symbol) [0x01090A5D]
	(No symbol) [0x0108DA28]
	(No symbol) [0x0108DBC5]
	(No symbol) [0x010807F0]
	BaseThreadInitThunk [0x75AFFCC9+25]
	RtlGetAppContainerNamedObjectPath [0x777B809E+286]
	RtlGetAppContainerNamedObjectPath [0x777B806E+238]


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling_FOX.py", line 109, in crawling_FOX
    driver.find_element(By.CSS_SELECTOR, '#wrapper > div.page > div.region-content-sidebar > main > div.thumbs-2-7 > article.article.story-1 > div.info > header > h3 > a').click()
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 741, in find_element
    return self.execute(Command.FIND_ELEMENT, {"using": by, "value": value})["value"]
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchWindowException: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x010FFD53+23747]
	(No symbol) [0x01087D54]
	(No symbol) [0x00F5BE53]
	(No symbol) [0x00F3D91B]
	(No symbol) [0x00FC7EFF]
	(No symbol) [0x00FDAD49]
	(No symbol) [0x00FC1B96]
	(No symbol) [0x00F93F3C]
	(No symbol) [0x00F94EBD]
	GetHandleVerifier [0x013DAC73+3017699]
	GetHandleVerifier [0x013EB93B+3086507]
	GetHandleVerifier [0x013E40F2+3055714]
	GetHandleVerifier [0x01195AF0+637536]
	(No symbol) [0x01090A5D]
	(No symbol) [0x0108DA28]
	(No symbol) [0x0108DBC5]
	(No symbol) [0x010807F0]
	BaseThreadInitThunk [0x75AFFCC9+25]
	RtlGetAppContainerNamedObjectPath [0x777B809E+286]
	RtlGetAppContainerNamedObjectPath [0x777B806E+238]

INFO:werkzeug: * Detected change in 'C:\\Users\\soldesk\\AppData\\Roaming\\Python\\Python310\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py', reloading
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawling_FOX" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 524-771-621
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawling_FOX" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
INFO:werkzeug:[33mPress CTRL+C to quit[0m
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawling_FOX" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 524-771-621
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawling_FOX" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
INFO:werkzeug:[33mPress CTRL+C to quit[0m
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawling_FOX" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 524-771-621
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 16:44:30 KST)" (scheduled at 2025-01-16 16:44:30.386322+09:00)
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 16:44:40 KST)" (scheduled at 2025-01-16 16:44:40.455090+09:00)
INFO:werkzeug: * Detected change in 'C:\\Users\\soldesk\\AppData\\Roaming\\Python\\Python310\\site-packages\\apscheduler\\executors\\base.py', reloading
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 16:45:30 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling_FOX.py", line 167, in crawling_FOX
    print(content_text)
UnicodeEncodeError: 'cp949' codec can't encode character '\xa0' in position 646: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 16:46:30 KST)" (scheduled at 2025-01-16 16:45:30.386322+09:00)
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 16:45:40 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling_FOX.py", line 167, in crawling_FOX
    print(content_text)
UnicodeEncodeError: 'cp949' codec can't encode character '\xa0' in position 646: illegal multibyte sequence
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 16:46:30 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling_FOX.py", line 167, in crawling_FOX
    print(content_text)
UnicodeEncodeError: 'cp949' codec can't encode character '\xa0' in position 646: illegal multibyte sequence
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawling_FOX" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 524-771-621
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 16:47:30 KST)" (scheduled at 2025-01-16 16:46:30.386322+09:00)
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 16:46:53 KST)" (scheduled at 2025-01-16 16:46:53.873791+09:00)
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 16:47:30 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling_FOX.py", line 167, in crawling_FOX
    print(content_text)
UnicodeEncodeError: 'cp949' codec can't encode character '\xa0' in position 646: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 16:48:30 KST)" (scheduled at 2025-01-16 16:47:30.386322+09:00)
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 16:47:53 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling_FOX.py", line 167, in crawling_FOX
    print(content_text)
UnicodeEncodeError: 'cp949' codec can't encode character '\xa0' in position 646: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 16:48:53 KST)" (scheduled at 2025-01-16 16:47:53.873791+09:00)
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 16:48:30 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling_FOX.py", line 167, in crawling_FOX
    print(content_text)
UnicodeEncodeError: 'cp949' codec can't encode character '\xa0' in position 646: illegal multibyte sequence
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 16:48:53 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling_FOX.py", line 167, in crawling_FOX
    print(content_text)
UnicodeEncodeError: 'cp949' codec can't encode character '\xa0' in position 646: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 16:49:30 KST)" (scheduled at 2025-01-16 16:48:30.386322+09:00)
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 16:49:30 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling_FOX.py", line 167, in crawling_FOX
    print(content_text)
UnicodeEncodeError: 'cp949' codec can't encode character '\xa0' in position 646: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 16:49:53 KST)" (scheduled at 2025-01-16 16:48:53.873791+09:00)
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 16:49:53 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling_FOX.py", line 167, in crawling_FOX
    print(content_text)
UnicodeEncodeError: 'cp949' codec can't encode character '\xa0' in position 646: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 16:50:30 KST)" (scheduled at 2025-01-16 16:49:30.386322+09:00)
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 16:50:30 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling_FOX.py", line 107, in crawling_FOX
    driver.find_element(By.CSS_SELECTOR, '#wrapper > div.page > div.region-content-sidebar > main > div.big-top > div > article > div.m > a > picture > img').click()
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webelement.py", line 94, in click
    self._execute(Command.CLICK_ELEMENT)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webelement.py", line 395, in _execute
    return self._parent.execute(command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.ElementClickInterceptedException: Message: element click intercepted: Element <img src="//a57.foxnews.com/prod-hp.foxnews.com/images/2025/01/720/405/c6d0148b34fd0055b8b8e542ee53e31d.jpg?tl=1&amp;ve=1" width="720" height="405" alt="IDF general reveals 'big change' that helped close the cease-fire deal after 15 months of war - Fox News" pinger-seen="true"> is not clickable at point (433, 602). Other element would receive the click: <div class="ad-container tablet ad-h-90 ad-w-728 sticky-ads">...</div>
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x010FFD53+23747]
	(No symbol) [0x01087D54]
	(No symbol) [0x00F5BE53]
	(No symbol) [0x00FA5C57]
	(No symbol) [0x00FA40C3]
	(No symbol) [0x00FA1CCD]
	(No symbol) [0x00FA1034]
	(No symbol) [0x00F95F57]
	(No symbol) [0x00FC1DFC]
	(No symbol) [0x00F959A4]
	(No symbol) [0x00FC2094]
	(No symbol) [0x00FDB41E]
	(No symbol) [0x00FC1B96]
	(No symbol) [0x00F93F3C]
	(No symbol) [0x00F94EBD]
	GetHandleVerifier [0x013DAC73+3017699]
	GetHandleVerifier [0x013EB93B+3086507]
	GetHandleVerifier [0x013E40F2+3055714]
	GetHandleVerifier [0x01195AF0+637536]
	(No symbol) [0x01090A5D]
	(No symbol) [0x0108DA28]
	(No symbol) [0x0108DBC5]
	(No symbol) [0x010807F0]
	BaseThreadInitThunk [0x75AFFCC9+25]
	RtlGetAppContainerNamedObjectPath [0x777B809E+286]
	RtlGetAppContainerNamedObjectPath [0x777B806E+238]

INFO:werkzeug: * Detected change in 'C:\\Users\\soldesk\\AppData\\Roaming\\Python\\Python310\\site-packages\\selenium\\webdriver\\remote\\webdriver.py', reloading
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawling_FOX" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 524-771-621
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 16:51:30 KST)" (scheduled at 2025-01-16 16:50:30.386322+09:00)
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 16:51:30 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling_FOX.py", line 167, in crawling_FOX
    print(content_text)
UnicodeEncodeError: 'cp949' codec can't encode character '\xa0' in position 646: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 16:50:48 KST)" (scheduled at 2025-01-16 16:50:48.895063+09:00)
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 16:52:30 KST)" (scheduled at 2025-01-16 16:51:30.386322+09:00)
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 16:51:48 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling_FOX.py", line 167, in crawling_FOX
    print(content_text)
UnicodeEncodeError: 'cp949' codec can't encode character '\xa0' in position 646: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 16:52:48 KST)" (scheduled at 2025-01-16 16:51:48.895063+09:00)
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 16:52:48 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling_FOX.py", line 167, in crawling_FOX
    print(content_text)
UnicodeEncodeError: 'cp949' codec can't encode character '\xa0' in position 646: illegal multibyte sequence
WARNING:apscheduler.scheduler:Execution of job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 16:52:30 KST)" skipped: maximum number of running instances reached (1)
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 16:53:30 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling_FOX.py", line 167, in crawling_FOX
    print(content_text)
UnicodeEncodeError: 'cp949' codec can't encode character '\xa0' in position 646: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 16:53:48 KST)" (scheduled at 2025-01-16 16:52:48.895063+09:00)
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 16:53:48 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling_FOX.py", line 167, in crawling_FOX
    print(content_text)
UnicodeEncodeError: 'cp949' codec can't encode character '\xa0' in position 646: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 16:54:30 KST)" (scheduled at 2025-01-16 16:53:30.386322+09:00)
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 16:54:30 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling_FOX.py", line 167, in crawling_FOX
    print(content_text)
UnicodeEncodeError: 'cp949' codec can't encode character '\xa0' in position 646: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 16:54:48 KST)" (scheduled at 2025-01-16 16:53:48.895063+09:00)
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 16:54:48 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling_FOX.py", line 167, in crawling_FOX
    print(content_text)
UnicodeEncodeError: 'cp949' codec can't encode character '\xa0' in position 646: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 16:55:30 KST)" (scheduled at 2025-01-16 16:54:30.386322+09:00)
INFO:werkzeug: * Detected change in 'C:\\kd\\ws_java\\team4_v2sbm3c\\src\\main\\python\\crawling_FOX.py', reloading
INFO:werkzeug: * Detected change in 'C:\\kd\\ws_java\\team4_v2sbm3c\\src\\main\\python\\crawling_FOX.py', reloading
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:00], next run at: 2025-01-16 16:55:30 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling_FOX.py", line 167, in crawling_FOX
    print(content_text)
UnicodeEncodeError: 'cp949' codec can't encode character '\xa0' in position 646: illegal multibyte sequence
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawling_FOX" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 524-771-621
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawling_FOX" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
INFO:werkzeug:[33mPress CTRL+C to quit[0m
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawling_FOX" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 524-771-621
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:40], next run at: 2025-01-16 16:56:57 KST)" (scheduled at 2025-01-16 16:56:57.010597+09:00)
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:40], next run at: 2025-01-16 16:57:05 KST)" (scheduled at 2025-01-16 16:57:05.366264+09:00)
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:40], next run at: 2025-01-16 16:58:37 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling_FOX.py", line 167, in crawling_FOX
    print(content_text)
UnicodeEncodeError: 'cp949' codec can't encode character '\xa0' in position 646: illegal multibyte sequence
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:40], next run at: 2025-01-16 16:58:45 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling_FOX.py", line 167, in crawling_FOX
    print(content_text)
UnicodeEncodeError: 'cp949' codec can't encode character '\xa0' in position 646: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:40], next run at: 2025-01-16 17:00:17 KST)" (scheduled at 2025-01-16 16:58:37.010597+09:00)
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:40], next run at: 2025-01-16 17:00:25 KST)" (scheduled at 2025-01-16 16:58:45.366264+09:00)
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:40], next run at: 2025-01-16 17:00:25 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling_FOX.py", line 167, in crawling_FOX
    print(content_text)
UnicodeEncodeError: 'cp949' codec can't encode character '\xa0' in position 646: illegal multibyte sequence
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:40], next run at: 2025-01-16 17:00:17 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling_FOX.py", line 167, in crawling_FOX
    print(content_text)
UnicodeEncodeError: 'cp949' codec can't encode character '\xa0' in position 646: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:40], next run at: 2025-01-16 17:01:57 KST)" (scheduled at 2025-01-16 17:00:17.010597+09:00)
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:40], next run at: 2025-01-16 17:02:05 KST)" (scheduled at 2025-01-16 17:00:25.366264+09:00)
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:40], next run at: 2025-01-16 17:01:57 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling_FOX.py", line 167, in crawling_FOX
    print(content_text)
UnicodeEncodeError: 'cp949' codec can't encode character '\xa0' in position 646: illegal multibyte sequence
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:40], next run at: 2025-01-16 17:02:05 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling_FOX.py", line 167, in crawling_FOX
    print(content_text)
UnicodeEncodeError: 'cp949' codec can't encode character '\xa0' in position 646: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:40], next run at: 2025-01-16 17:03:37 KST)" (scheduled at 2025-01-16 17:01:57.010597+09:00)
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:40], next run at: 2025-01-16 17:03:45 KST)" (scheduled at 2025-01-16 17:02:05.366264+09:00)
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:40], next run at: 2025-01-16 17:03:37 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling_FOX.py", line 167, in crawling_FOX
    print(content_text)
UnicodeEncodeError: 'cp949' codec can't encode character '\xa0' in position 646: illegal multibyte sequence
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:40], next run at: 2025-01-16 17:03:45 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling_FOX.py", line 167, in crawling_FOX
    print(content_text)
UnicodeEncodeError: 'cp949' codec can't encode character '\xa0' in position 646: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:40], next run at: 2025-01-16 17:05:17 KST)" (scheduled at 2025-01-16 17:03:37.010597+09:00)
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:40], next run at: 2025-01-16 17:05:25 KST)" (scheduled at 2025-01-16 17:03:45.366264+09:00)
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:40], next run at: 2025-01-16 17:05:25 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling_FOX.py", line 167, in crawling_FOX
    print(content_text)
UnicodeEncodeError: 'cp949' codec can't encode character '\xa0' in position 646: illegal multibyte sequence
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:40], next run at: 2025-01-16 17:05:17 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling_FOX.py", line 167, in crawling_FOX
    print(content_text)
UnicodeEncodeError: 'cp949' codec can't encode character '\xa0' in position 646: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:40], next run at: 2025-01-16 17:06:57 KST)" (scheduled at 2025-01-16 17:05:17.010597+09:00)
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:40], next run at: 2025-01-16 17:06:57 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling_FOX.py", line 107, in crawling_FOX
    driver.find_element(By.CSS_SELECTOR, '#wrapper > div.page > div.region-content-sidebar > main > div.big-top > div > article > div.m > a > picture > img').click()
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webelement.py", line 94, in click
    self._execute(Command.CLICK_ELEMENT)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webelement.py", line 395, in _execute
    return self._parent.execute(command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.ElementClickInterceptedException: Message: element click intercepted: Element <img src="//a57.foxnews.com/prod-hp.foxnews.com/images/2025/01/720/405/c6d0148b34fd0055b8b8e542ee53e31d.jpg?tl=1&amp;ve=1" width="720" height="405" alt="IDF general reveals 'big change' that helped close the cease-fire deal after 15 months of war - Fox News" pinger-seen="true"> is not clickable at point (433, 602). Other element would receive the click: <div class="ad-container tablet ad-h-90 ad-w-728 sticky-ads">...</div>
  (Session info: chrome=131.0.6778.265)
Stacktrace:
	GetHandleVerifier [0x010FFD53+23747]
	(No symbol) [0x01087D54]
	(No symbol) [0x00F5BE53]
	(No symbol) [0x00FA5C57]
	(No symbol) [0x00FA40C3]
	(No symbol) [0x00FA1CCD]
	(No symbol) [0x00FA1034]
	(No symbol) [0x00F95F57]
	(No symbol) [0x00FC1DFC]
	(No symbol) [0x00F959A4]
	(No symbol) [0x00FC2094]
	(No symbol) [0x00FDB41E]
	(No symbol) [0x00FC1B96]
	(No symbol) [0x00F93F3C]
	(No symbol) [0x00F94EBD]
	GetHandleVerifier [0x013DAC73+3017699]
	GetHandleVerifier [0x013EB93B+3086507]
	GetHandleVerifier [0x013E40F2+3055714]
	GetHandleVerifier [0x01195AF0+637536]
	(No symbol) [0x01090A5D]
	(No symbol) [0x0108DA28]
	(No symbol) [0x0108DBC5]
	(No symbol) [0x010807F0]
	BaseThreadInitThunk [0x75AFFCC9+25]
	RtlGetAppContainerNamedObjectPath [0x777B809E+286]
	RtlGetAppContainerNamedObjectPath [0x777B806E+238]

INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:40], next run at: 2025-01-16 17:07:05 KST)" (scheduled at 2025-01-16 17:05:25.366264+09:00)
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:40], next run at: 2025-01-16 17:07:05 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling_FOX.py", line 167, in crawling_FOX
    print(content_text)
UnicodeEncodeError: 'cp949' codec can't encode character '\xa0' in position 646: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:40], next run at: 2025-01-16 17:08:37 KST)" (scheduled at 2025-01-16 17:06:57.010597+09:00)
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:40], next run at: 2025-01-16 17:08:45 KST)" (scheduled at 2025-01-16 17:07:05.366264+09:00)
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:40], next run at: 2025-01-16 17:08:37 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling_FOX.py", line 167, in crawling_FOX
    print(content_text)
UnicodeEncodeError: 'cp949' codec can't encode character '\xa0' in position 646: illegal multibyte sequence
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:40], next run at: 2025-01-16 17:08:45 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling_FOX.py", line 167, in crawling_FOX
    print(content_text)
UnicodeEncodeError: 'cp949' codec can't encode character '\xa0' in position 646: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:40], next run at: 2025-01-16 17:10:17 KST)" (scheduled at 2025-01-16 17:08:37.010597+09:00)
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:40], next run at: 2025-01-16 17:10:25 KST)" (scheduled at 2025-01-16 17:08:45.366264+09:00)
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:40], next run at: 2025-01-16 17:10:17 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling_FOX.py", line 167, in crawling_FOX
    print(content_text)
UnicodeEncodeError: 'cp949' codec can't encode character '\xa0' in position 646: illegal multibyte sequence
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:40], next run at: 2025-01-16 17:10:25 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling_FOX.py", line 167, in crawling_FOX
    print(content_text)
UnicodeEncodeError: 'cp949' codec can't encode character '\xa0' in position 646: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:40], next run at: 2025-01-16 17:11:57 KST)" (scheduled at 2025-01-16 17:10:17.010597+09:00)
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:40], next run at: 2025-01-16 17:12:05 KST)" (scheduled at 2025-01-16 17:10:25.366264+09:00)
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:40], next run at: 2025-01-16 17:11:57 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling_FOX.py", line 167, in crawling_FOX
    print(content_text)
UnicodeEncodeError: 'cp949' codec can't encode character '\xa0' in position 646: illegal multibyte sequence
INFO:werkzeug: * Detected change in 'C:\\kd\\ws_java\\team4_v2sbm3c\\src\\main\\python\\pernews.py', reloading
INFO:werkzeug: * Detected change in 'C:\\kd\\ws_java\\team4_v2sbm3c\\src\\main\\python\\pernews.py', reloading
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:40], next run at: 2025-01-16 17:12:05 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling_FOX.py", line 167, in crawling_FOX
    print(content_text)
UnicodeEncodeError: 'cp949' codec can't encode character '\xa0' in position 646: illegal multibyte sequence
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawling_FOX" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 524-771-621
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:40], next run at: 2025-01-16 17:13:37 KST)" (scheduled at 2025-01-16 17:11:57.010597+09:00)
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:40], next run at: 2025-01-16 17:13:37 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling_FOX.py", line 167, in crawling_FOX
    print(content_text)
UnicodeEncodeError: 'cp949' codec can't encode character '\xa0' in position 646: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:40], next run at: 2025-01-16 17:12:39 KST)" (scheduled at 2025-01-16 17:12:39.985657+09:00)
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:40], next run at: 2025-01-16 17:14:19 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling_FOX.py", line 167, in crawling_FOX
    print(content_text)
UnicodeEncodeError: 'cp949' codec can't encode character '\xa0' in position 646: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:40], next run at: 2025-01-16 17:15:17 KST)" (scheduled at 2025-01-16 17:13:37.010597+09:00)
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:40], next run at: 2025-01-16 17:15:17 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling_FOX.py", line 167, in crawling_FOX
    print(content_text)
UnicodeEncodeError: 'cp949' codec can't encode character '\xa0' in position 646: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:40], next run at: 2025-01-16 17:15:59 KST)" (scheduled at 2025-01-16 17:14:19.985657+09:00)
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:40], next run at: 2025-01-16 17:15:59 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling_FOX.py", line 167, in crawling_FOX
    print(content_text)
UnicodeEncodeError: 'cp949' codec can't encode character '\xa0' in position 646: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:40], next run at: 2025-01-16 17:16:57 KST)" (scheduled at 2025-01-16 17:15:17.010597+09:00)
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:40], next run at: 2025-01-16 17:16:57 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling_FOX.py", line 167, in crawling_FOX
    print(content_text)
UnicodeEncodeError: 'cp949' codec can't encode character '\xa0' in position 646: illegal multibyte sequence
INFO:apscheduler.executors.default:Running job "crawling_FOX (trigger: interval[0:01:40], next run at: 2025-01-16 17:17:39 KST)" (scheduled at 2025-01-16 17:15:59.985657+09:00)
ERROR:apscheduler.executors.default:Job "crawling_FOX (trigger: interval[0:01:40], next run at: 2025-01-16 17:17:39 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling_FOX.py", line 104, in crawling_FOX
    load('https://www.foxnews.com/', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling_FOX.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
=======
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
=======
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawl_and_insert_data" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 569-178-434
INFO:apscheduler.executors.default:Running job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 17:08:43 KST)" (scheduled at 2025-01-16 17:07:43.292697+09:00)
ERROR:apscheduler.executors.default:Job "crawl_and_insert_data (trigger: interval[0:01:00], next run at: 2025-01-16 17:08:43 KST)" raised an exception
Traceback (most recent call last):
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 105, in crawl_and_insert_data
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 347, in execute
    self.error_handler.check_response(response)
  File "C:\Users\i\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\errorhandler.py", line 229, in check_response
>>>>>>> 70cbf001f92143f5260acd37cf263acd45c5af0f
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchWindowException: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=131.0.6778.265)
Stacktrace:
<<<<<<< HEAD
	GetHandleVerifier [0x010FFD53+23747]
	(No symbol) [0x01087D54]
	(No symbol) [0x00F5BE53]
	(No symbol) [0x00F3D91B]
	(No symbol) [0x00FC7EFF]
	(No symbol) [0x00FDAD49]
	(No symbol) [0x00FC1B96]
	(No symbol) [0x00F93F3C]
	(No symbol) [0x00F94EBD]
	GetHandleVerifier [0x013DAC73+3017699]
	GetHandleVerifier [0x013EB93B+3086507]
	GetHandleVerifier [0x013E40F2+3055714]
	GetHandleVerifier [0x01195AF0+637536]
	(No symbol) [0x01090A5D]
	(No symbol) [0x0108DA28]
	(No symbol) [0x0108DBC5]
	(No symbol) [0x010807F0]
	BaseThreadInitThunk [0x75AFFCC9+25]
	RtlGetAppContainerNamedObjectPath [0x777B809E+286]
	RtlGetAppContainerNamedObjectPath [0x777B806E+238]

INFO:werkzeug: * Detected change in 'C:\\Users\\soldesk\\AppData\\Roaming\\Python\\Python310\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py', reloading
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawling_FOX" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 524-771-621
=======
	GetHandleVerifier [0x00B4FD53+23747]
	(No symbol) [0x00AD7D54]
	(No symbol) [0x009ABE53]
	(No symbol) [0x0098D91B]
	(No symbol) [0x00A17EFF]
	(No symbol) [0x00A2AD49]
	(No symbol) [0x00A11B96]
	(No symbol) [0x009E3F3C]
	(No symbol) [0x009E4EBD]
	GetHandleVerifier [0x00E2AC73+3017699]
	GetHandleVerifier [0x00E3B93B+3086507]
	GetHandleVerifier [0x00E340F2+3055714]
	GetHandleVerifier [0x00BE5AF0+637536]
	(No symbol) [0x00AE0A5D]
	(No symbol) [0x00ADDA28]
	(No symbol) [0x00ADDBC5]
	(No symbol) [0x00AD07F0]
	BaseThreadInitThunk [0x771BFCC9+25]
	RtlGetAppContainerNamedObjectPath [0x77DD809E+286]
	RtlGetAppContainerNamedObjectPath [0x77DD806E+238]

>>>>>>> a01dd0bec39176df87f2905695ac31e11eae375d
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
>>>>>>> 70cbf001f92143f5260acd37cf263acd45c5af0f
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawling_BBC" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
INFO:werkzeug:[33mPress CTRL+C to quit[0m
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawling_BBC" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 524-771-621
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 17:39:40 KST)" (scheduled at 2025-01-16 17:39:40.660572+09:00)
INFO:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 17:40:40 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 17:39:48 KST)" (scheduled at 2025-01-16 17:39:48.406209+09:00)
INFO:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 17:40:48 KST)" executed successfully
INFO:werkzeug: * Detected change in 'C:\\ProgramData\\Anaconda3\\Lib\\site-packages\\_pytest\\cacheprovider.py', reloading
INFO:werkzeug: * Detected change in 'C:\\ProgramData\\Anaconda3\\Lib\\site-packages\\_pytest\\fixtures.py', reloading
INFO:werkzeug: * Detected change in 'C:\\ProgramData\\Anaconda3\\Lib\\site-packages\\_pytest\\config\\__init__.py', reloading
INFO:werkzeug: * Detected change in 'C:\\ProgramData\\Anaconda3\\Lib\\site-packages\\_pytest\\capture.py', reloading
INFO:werkzeug: * Detected change in 'C:\\ProgramData\\Anaconda3\\Lib\\site-packages\\_pytest\\doctest.py', reloading
INFO:werkzeug: * Detected change in 'C:\\ProgramData\\Anaconda3\\Lib\\site-packages\\_pytest\\junitxml.py', reloading
INFO:werkzeug: * Detected change in 'C:\\ProgramData\\Anaconda3\\Lib\\site-packages\\_pytest\\legacypath.py', reloading
INFO:werkzeug: * Detected change in 'C:\\ProgramData\\Anaconda3\\Lib\\site-packages\\_pytest\\logging.py', reloading
INFO:werkzeug: * Detected change in 'C:\\ProgramData\\Anaconda3\\Lib\\site-packages\\_pytest\\monkeypatch.py', reloading
INFO:werkzeug: * Detected change in 'C:\\ProgramData\\Anaconda3\\Lib\\site-packages\\_pytest\\recwarn.py', reloading
INFO:werkzeug: * Detected change in 'C:\\ProgramData\\Anaconda3\\Lib\\site-packages\\_pytest\\tmpdir.py', reloading
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 17:41:40 KST)" (scheduled at 2025-01-16 17:40:40.660572+09:00)
INFO:WDM:====== WebDriver manager ======
INFO:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 17:41:40 KST)" executed successfully
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawling_BBC" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 524-771-621
INFO:werkzeug: * Detected change in 'C:\\kd\\ws_java\\team4_v2sbm3c\\src\\main\\python\\crawling_FOX.py', reloading
INFO:werkzeug: * Detected change in 'C:\\kd\\ws_java\\team4_v2sbm3c\\src\\main\\python\\crawling_FOX.py', reloading
INFO:werkzeug: * Detected change in 'C:\\kd\\ws_java\\team4_v2sbm3c\\src\\main\\python\\crawling_FOX.py', reloading
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawling_BBC" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 524-771-621
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 17:42:40 KST)" (scheduled at 2025-01-16 17:41:40.660572+09:00)
INFO:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 17:42:40 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 17:42:20 KST)" (scheduled at 2025-01-16 17:42:20.742495+09:00)
INFO:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 17:43:20 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 17:43:40 KST)" (scheduled at 2025-01-16 17:42:40.660572+09:00)
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
INFO:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 17:43:40 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 17:44:20 KST)" (scheduled at 2025-01-16 17:43:20.742495+09:00)
INFO:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 17:44:20 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 17:44:40 KST)" (scheduled at 2025-01-16 17:43:40.660572+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001FDB8842260>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/118215a1e90a078100de17708499115a/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001FDB8841840>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/118215a1e90a078100de17708499115a/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001FDBAB5DAE0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/118215a1e90a078100de17708499115a/url
INFO:werkzeug: * Detected change in 'C:\\Users\\soldesk\\AppData\\Roaming\\Python\\Python310\\site-packages\\selenium\\webdriver\\remote\\remote_connection.py', reloading
INFO:werkzeug: * Detected change in 'C:\\ProgramData\\Anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py', reloading
INFO:werkzeug: * Detected change in 'C:\\ProgramData\\Anaconda3\\Lib\\site-packages\\urllib3\\util\\retry.py', reloading
INFO:werkzeug: * Detected change in 'C:\\ProgramData\\Anaconda3\\Lib\\site-packages\\urllib3\\connection.py', reloading
INFO:werkzeug: * Detected change in 'C:\\ProgramData\\Anaconda3\\Lib\\http\\client.py', reloading
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 17:44:40 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001FDBAAE3E50>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling_BBC.py", line 105, in crawling_BBC
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling_BBC.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=62092): Max retries exceeded with url: /session/118215a1e90a078100de17708499115a/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001FDBAAE3E50>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
INFO:werkzeug: * Detected change in 'C:\\ProgramData\\Anaconda3\\Lib\\site-packages\\urllib3\\util\\connection.py', reloading
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawling_BBC" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 524-771-621
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 17:45:40 KST)" (scheduled at 2025-01-16 17:44:40.660572+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001FDBAAE28C0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/118215a1e90a078100de17708499115a/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001FDBAAE35B0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/118215a1e90a078100de17708499115a/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001FDBAAE06A0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/118215a1e90a078100de17708499115a/url
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 17:45:40 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001FDBAAE3820>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling_BBC.py", line 105, in crawling_BBC
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling_BBC.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=62092): Max retries exceeded with url: /session/118215a1e90a078100de17708499115a/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001FDBAAE3820>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 17:45:08 KST)" (scheduled at 2025-01-16 17:45:08.411442+09:00)
INFO:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 17:46:08 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 17:46:40 KST)" (scheduled at 2025-01-16 17:45:40.660572+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001FDBAAE3B50>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/118215a1e90a078100de17708499115a/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001FDBAB0E8F0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/118215a1e90a078100de17708499115a/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001FDBAB0EAD0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/118215a1e90a078100de17708499115a/url
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 17:46:40 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001FDBAB0E7D0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling_BBC.py", line 105, in crawling_BBC
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling_BBC.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=62092): Max retries exceeded with url: /session/118215a1e90a078100de17708499115a/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001FDBAB0E7D0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 17:47:08 KST)" (scheduled at 2025-01-16 17:46:08.411442+09:00)
INFO:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 17:47:08 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 17:47:40 KST)" (scheduled at 2025-01-16 17:46:40.660572+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001FDBAB0E650>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/118215a1e90a078100de17708499115a/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001FDBAB0D090>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/118215a1e90a078100de17708499115a/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001FDBAB0D0C0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/118215a1e90a078100de17708499115a/url
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 17:47:40 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001FDBAB0D240>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling_BBC.py", line 105, in crawling_BBC
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling_BBC.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=62092): Max retries exceeded with url: /session/118215a1e90a078100de17708499115a/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001FDBAB0D240>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 17:48:08 KST)" (scheduled at 2025-01-16 17:47:08.411442+09:00)
INFO:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 17:48:08 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 17:48:40 KST)" (scheduled at 2025-01-16 17:47:40.660572+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001FDBAAE3430>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/118215a1e90a078100de17708499115a/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001FDBAAE28F0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/118215a1e90a078100de17708499115a/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001FDBAAE35E0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/118215a1e90a078100de17708499115a/url
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 17:48:40 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001FDBAAE0670>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling_BBC.py", line 105, in crawling_BBC
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling_BBC.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=62092): Max retries exceeded with url: /session/118215a1e90a078100de17708499115a/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001FDBAAE0670>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 17:49:08 KST)" (scheduled at 2025-01-16 17:48:08.411442+09:00)
INFO:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 17:49:08 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 17:49:40 KST)" (scheduled at 2025-01-16 17:48:40.660572+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001FDB8841750>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/118215a1e90a078100de17708499115a/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001FDBAB0D030>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/118215a1e90a078100de17708499115a/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001FDBAB0CF70>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/118215a1e90a078100de17708499115a/url
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 17:49:40 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001FDBAB0E7D0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling_BBC.py", line 105, in crawling_BBC
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling_BBC.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=62092): Max retries exceeded with url: /session/118215a1e90a078100de17708499115a/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001FDBAB0E7D0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 17:50:08 KST)" (scheduled at 2025-01-16 17:49:08.411442+09:00)
INFO:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 17:50:08 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 17:50:40 KST)" (scheduled at 2025-01-16 17:49:40.660572+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001FDBAB0E980>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/118215a1e90a078100de17708499115a/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001FDBAB0CF10>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/118215a1e90a078100de17708499115a/url
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawling_BBC" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
INFO:werkzeug:[33mPress CTRL+C to quit[0m
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawling_BBC" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 524-771-621
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 18:04:31 KST)" (scheduled at 2025-01-16 18:04:31.596457+09:00)
INFO:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 18:05:31 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 18:04:39 KST)" (scheduled at 2025-01-16 18:04:39.121040+09:00)
INFO:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 18:05:39 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 18:06:31 KST)" (scheduled at 2025-01-16 18:05:31.596457+09:00)
INFO:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 18:06:31 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 18:06:39 KST)" (scheduled at 2025-01-16 18:05:39.121040+09:00)
INFO:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 18:06:39 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 18:07:31 KST)" (scheduled at 2025-01-16 18:06:31.596457+09:00)
INFO:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 18:07:31 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 18:07:39 KST)" (scheduled at 2025-01-16 18:06:39.121040+09:00)
INFO:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 18:07:39 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 18:08:31 KST)" (scheduled at 2025-01-16 18:07:31.596457+09:00)
INFO:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 18:08:31 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 18:08:39 KST)" (scheduled at 2025-01-16 18:07:39.121040+09:00)
INFO:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 18:08:39 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 18:09:31 KST)" (scheduled at 2025-01-16 18:08:31.596457+09:00)
INFO:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 18:09:31 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 18:09:39 KST)" (scheduled at 2025-01-16 18:08:39.121040+09:00)
INFO:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 18:09:39 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 18:10:31 KST)" (scheduled at 2025-01-16 18:09:31.596457+09:00)
INFO:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 18:10:31 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 18:10:39 KST)" (scheduled at 2025-01-16 18:09:39.121040+09:00)
INFO:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 18:10:39 KST)" executed successfully
INFO:werkzeug: * Detected change in 'C:\\ProgramData\\Anaconda3\\Scripts\\conda-script.py', reloading
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 18:11:31 KST)" (scheduled at 2025-01-16 18:10:31.596457+09:00)
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawling_BBC" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 524-771-621
INFO:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 18:11:31 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 18:12:31 KST)" (scheduled at 2025-01-16 18:11:31.596457+09:00)
INFO:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 18:12:31 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 18:11:43 KST)" (scheduled at 2025-01-16 18:11:43.786599+09:00)
INFO:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 18:12:43 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 18:13:31 KST)" (scheduled at 2025-01-16 18:12:31.596457+09:00)
INFO:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 18:13:31 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 18:13:43 KST)" (scheduled at 2025-01-16 18:12:43.786599+09:00)
INFO:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 18:13:43 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 18:14:31 KST)" (scheduled at 2025-01-16 18:13:31.596457+09:00)
INFO:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 18:14:31 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 18:14:43 KST)" (scheduled at 2025-01-16 18:13:43.786599+09:00)
INFO:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 18:14:43 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 18:15:31 KST)" (scheduled at 2025-01-16 18:14:31.596457+09:00)
INFO:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 18:15:31 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 18:15:43 KST)" (scheduled at 2025-01-16 18:14:43.786599+09:00)
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
INFO:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 18:15:43 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 18:16:31 KST)" (scheduled at 2025-01-16 18:15:31.596457+09:00)
INFO:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 18:16:31 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 18:16:43 KST)" (scheduled at 2025-01-16 18:15:43.786599+09:00)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000216187F7580>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/fa550165b422b07c501c6df3d607515a/url
INFO:werkzeug: * Detected change in 'C:\\kd\\ws_java\\team4_v2sbm3c\\src\\main\\python\\crawling_BBC.py', reloading
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000216187F7670>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/fa550165b422b07c501c6df3d607515a/url
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawling_BBC" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
INFO:werkzeug:[33mPress CTRL+C to quit[0m
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000216164406A0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/fa550165b422b07c501c6df3d607515a/url
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawling_BBC" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
INFO:werkzeug:[31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
INFO:werkzeug:[33mPress CTRL+C to quit[0m
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawling_BBC" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 524-771-621
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 18:17:14 KST)" (scheduled at 2025-01-16 18:17:14.255418+09:00)
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 18:17:22 KST)" (scheduled at 2025-01-16 18:17:22.516825+09:00)
INFO:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 18:18:22 KST)" executed successfully
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
INFO:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 18:18:14 KST)" executed successfully
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 18:19:14 KST)" (scheduled at 2025-01-16 18:18:14.255418+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B5025D1AB0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/fccb5323c7391549854478eaa35ecce9/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B501F09150>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/fccb5323c7391549854478eaa35ecce9/url
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 18:19:22 KST)" (scheduled at 2025-01-16 18:18:22.516825+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B5048F9AE0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/fccb5323c7391549854478eaa35ecce9/url
INFO:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 18:19:22 KST)" executed successfully
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 18:19:14 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001B504883670>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling_BBC.py", line 105, in crawling_BBC
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling_BBC.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=65005): Max retries exceeded with url: /session/fccb5323c7391549854478eaa35ecce9/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B504883670>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
INFO:werkzeug: * Detected change in 'C:\\kd\\ws_java\\team4_v2sbm3c\\src\\main\\python\\exc_2.py', reloading
INFO:werkzeug: * Restarting with watchdog (windowsapi)
INFO:numexpr.utils:NumExpr defaulting to 4 threads.
INFO:WDM:====== WebDriver manager ======
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Get LATEST chromedriver version for google-chrome
INFO:WDM:Driver [C:\Users\soldesk\.wdm\drivers\chromedriver\win64\131.0.6778.264\chromedriver-win32/THIRD_PARTY_NOTICES.chromedriver] found in cache
INFO:apscheduler.scheduler:Adding job tentatively -- it will be properly scheduled when the scheduler starts
INFO:apscheduler.scheduler:Added job "crawling_BBC" to job store "default"
INFO:apscheduler.scheduler:Scheduler started
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 524-771-621
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 18:20:14 KST)" (scheduled at 2025-01-16 18:19:14.255418+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B5048834F0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/fccb5323c7391549854478eaa35ecce9/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B504882920>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/fccb5323c7391549854478eaa35ecce9/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B504883460>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/fccb5323c7391549854478eaa35ecce9/url
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 18:20:14 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001B504883790>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling_BBC.py", line 105, in crawling_BBC
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling_BBC.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=65005): Max retries exceeded with url: /session/fccb5323c7391549854478eaa35ecce9/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B504883790>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 18:19:53 KST)" (scheduled at 2025-01-16 18:19:53.248724+09:00)
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 18:21:14 KST)" (scheduled at 2025-01-16 18:20:14.255418+09:00)
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B5048837F0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/fccb5323c7391549854478eaa35ecce9/url
INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
INFO:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 18:20:53 KST)" executed successfully
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B5048AA920>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/fccb5323c7391549854478eaa35ecce9/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B5048ABA30>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/fccb5323c7391549854478eaa35ecce9/url
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 18:21:14 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001B5048A9F00>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling_BBC.py", line 105, in crawling_BBC
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling_BBC.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=65005): Max retries exceeded with url: /session/fccb5323c7391549854478eaa35ecce9/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B5048A9F00>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
INFO:apscheduler.executors.default:Running job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 18:21:53 KST)" (scheduled at 2025-01-16 18:20:53.248724+09:00)
WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000027F3F04A1D0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4d5ee4e60b6e6cc9c9615a6b4d7cd881/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000027F3F04A2C0>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4d5ee4e60b6e6cc9c9615a6b4d7cd881/url
WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000027F3F04A530>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다')': /session/4d5ee4e60b6e6cc9c9615a6b4d7cd881/url
ERROR:apscheduler.executors.default:Job "crawling_BBC (trigger: interval[0:01:00], next run at: 2025-01-16 18:21:53 KST)" raised an exception
Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\ProgramData\Anaconda3\lib\http\client.py", line 975, in send
    self.connect()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000027F3F04A800>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\apscheduler\executors\base.py", line 131, in run_job
    retval = job.func(*job.args, **job.kwargs)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling_BBC.py", line 105, in crawling_BBC
    load('https://www.bbc.com//', 1)
  File "C:\kd\ws_java\team4_v2sbm3c\src\main\python\crawling_BBC.py", line 37, in load
    driver.get(url) # url 접속
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 356, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\webdriver.py", line 345, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 302, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\soldesk\AppData\Roaming\Python\Python310\site-packages\selenium\webdriver\remote\remote_connection.py", line 322, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 78, in request
    return self.request_encode_body(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 815, in urlopen
    return self.urlopen(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    retries = retries.increment(
  File "C:\ProgramData\Anaconda3\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=65456): Max retries exceeded with url: /session/4d5ee4e60b6e6cc9c9615a6b4d7cd881/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000027F3F04A800>: Failed to establish a new connection: [WinError 10061] 대상 컴퓨터에서 연결을 거부했으므로 연결하지 못했습니다'))
